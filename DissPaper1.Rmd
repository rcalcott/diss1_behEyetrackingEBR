---
title             : "When does spontaneous eye blink rate predict flexible working memory updating?"
shorttitle        : "Eye blink rate and WM updating across contexts"

author: 
  - name          : "Rebecca D. Calcott"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Universitätsstraße 31, 93053 Regensburg, Germany"
    email         : "rdcalcott@gmail.com"
  - name          : "Elliot T. Berkman"
    affiliation   : "2"

affiliation:
  - id            : "1"
    institution   : "University of Regensburg"
  - id            : "2"
    institution   : "University of Oregon"

author_note: |
  Rebecca Calcott, Department of Experimental Psychology, University of Regensburg.  
  
  Elliot Berkman, Department of Psychology, Center for Translational Neuroscience, University of Oregon.
  
  RDC received support from an NSERC Postgraduate Scholarship and an APA Dissertation Research Award. ETB received support from NIH grants R21 CA175241 and R01 CA211224.

abstract: |
  Tonic striatal dopamine (DA) modulates the relative ease of flexible updating versus stable maintenance of working memory (WM)    representations. An open question concerns the relevance of striatal dopamine when WM updating requires disengagement from a previously-relevant WM representation, in contrast to when updating requires only the activation of a new representation. The present experiments investigated this question using an attention shifting task, in which the updating context was manipulated. On Perseveration-Inhibition blocks, the target and distractor colours changed roles at each switch point, so successful performance required disengagement from an old attentional set. On Pure Updating blocks, both target and distractor colours were completely novel at each switch point, so failure to disengage from a previous attentional set could not interfere with performance. Spontaneous eye blink rate (sEBR) was used as an index of striatal DA activity, recognizing that the precise physiological basis of this relationship is not yet established. Behaviorally, attentional shifts on Perseveration-Inhibition blocks were more costly, as indexed by a greater number of errors on Incongruent trials as well as a more gradual reduction in reaction time (RT) across trials. Higher EBR predicted slower RTs on Perseveration-Inhibition blocks compared to Pure Updating blocks. These findings underscore the importance of considering updating context and potential for interference in models of striatal DA and WM updating. 
  
keywords          : "working memory updating, attentional flexibility, eye blink rate"
wordcount         : "X"

bibliography      : ["r-references.bib"]

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : yes
mask              : no

class             : "man"
output            : papaja::apa6_pdf
---

```{r load_packages, include = FALSE}
library(papaja)
library(bibtex)
#library(itrackR)
#library(edfR)
library(plyr)
library(dplyr)
library(dtplyr)
library(ggplot2)
library(lme4)
library(haven)
library(lmerTest)
library(effects)
library(psych)
library(knitr)
library(sjPlot)
library(tidyr)
library(weights)
library(reshape2)
```

```{r analysis_preferences}
# Seed for random number generation
set.seed(42)
```

```{r data setup, include=FALSE}
# Hard-coded file pathways and experiment numbers (data paths must correspond to expNums)
genericDataPathMac <- '~/Dropbox/Studies/Dissertation/output/Study'
genericDataPathWindows <- 'C:/Users/LocalAdmin/Dropbox/Studies/Dissertation/output/Study'
figPath <- '~/Dropbox/Studies/Dissertation/Drafts/Writeup2/figures/'

# edit depending on whether using Mac (1) or Windows (2)
opSys <- 1

if (opSys==1) {
  genericDataPath <- genericDataPathMac
} else if (opSys==2) {
  genericDataPath <- genericDataPathWindows
}

expNums <- c(1,2,4) #list only those with eye data
noEyeDataExp <- 3 # need to make changes below if more than one experiment with no eye data

# Establish absolute performance cutoffs for inclusion
excludeRTMax <- 1500
excludeRTMin <- 100
excludeRTMaxSDs <- 3
excludeMaxErrorRateSDs <- 3
winsorizeErrorsSD <- 3
excludeSaccLatency <- 750
targetHitThresh <- .75 # below this threshold, exclude subjects for not fixating the target on enough trials.
keepingTrials <- 4


# function to load, re-name, and merge data
loadData <- function(expNum, genericDataPath) {
  assign('dataPath', paste(genericDataPath, expNum, '/', sep=''))
  
  load(paste(dataPath, 'cleanDataBehAnalyses.Rda', sep='')) 
  load(paste(dataPath, 'eyetrackingData_byTrial.Rda', sep='')) 
  load(paste(dataPath, 'blinksNAlg.Rda', sep='')) 

  allData <- merge(cleanData_behAnalyses, allEyes, by=c('ID','Block','Set','Trial'), all.x=TRUE, all.y=FALSE)
  allData <- merge(allData, blinksNAlg, by='ID', all.x=TRUE, all.y=FALSE)

  
  allData$firstTarSacc_tar[is.na(allData$firstTarSacc_tar)] <- 0
  allData$firstDistSacc_dist[is.na(allData$firstDistSacc_dist)] <- 0
  allData$firstNeutSacc_neut[is.na(allData$firstNeutSacc_neut)] <- 0
  allData$firstTarFix_tar[is.na(allData$firstTarFix_tar)] <- 0
  allData$firstDistFix_dist[is.na(allData$firstDistFix_dist)] <- 0
  allData$firstNeutFix_neut[is.na(allData$firstNeutFix_neut)] <- 0
  
  assign(paste('allData',expNum, sep=''), allData)
}

list <- sapply(expNums, loadData, genericDataPath=genericDataPath, USE.NAMES=TRUE)
list2env(setNames(list, paste('allData',expNums,sep='')), envir=.GlobalEnv)

#load data for experiment with no eye data:
load(paste(genericDataPath, noEyeDataExp, '/cleanDataBehAnalyses.Rda', sep=''))
assign(paste('allData',noEyeDataExp, sep=''), cleanData_behAnalyses)

```

Effective goal-driven behavior requires, in addition to stable maintenance of task-relevant working memory (WM) representations, the ability to update these representations when they are no longer relevant [@Cools_2015]. Critically, this updating must be selective, allowing for only newly-relevant representations to gain access to WM, rather than indiscriminately allowing any new stimulus to be represented [@HazyEtAl_2007]. For example, a cyclist moving from a city street to a forest trail must shift from prioritizing attention towards cars and traffic lights to animals and stray branches while still ignoring other objects that are irrelevant for her safety or interest. This selective updating ability has been linked with striatal dopamine (DA) function [@CoolsDEsposito_2011]. The effectiveness of this selective updating depends also on task-specific characteristics, such as the presence of salient distractors. Our cyclist may have a more difficult time looking out for animals if she were to see an old parked car beside the trail, given its prior relevance to her safety on the city street. The present research examines how the presence of potentially-interfering distraction affects WM updating ability, and its relationship with spontaneous eye blink rate (EBR), an index of striatal DA, with the goal of clarifying the conditions under which striatal DA is most relevant to updating ability.

## Working memory updating: The role of disengagement
Across a range of tasks (e.g., task switching, attentional set-shifting), the need to update WM representations consistently incurs a performance cost in both speed and accuracy [@RogersMonsell_1995; @DreisbachGoschke_2004]. However, not all WM updates are equivalently costly - specific task factors modulate the degree to which performance suffers during a switch.  
Relevant to the current investigation, switching is more costly when participants must ignore a previously-relevant stimulus that is presented at the same time as the target [@RogersMonsell_1995]. Furthermore, inhibition of no-longer-relevant representations appears to be automatically triggered during WM updating [@MayrKeele_2000], indicating that updating involves not only the activation of the newly-relevant representations, but also active inhibition of those that are no longer relevant. The upshot of this inhibition is that switching back to a representation that was previously inhibited incurs a cost because individuals must overcome the inhibition to re-activate the particular representation. This process of actively disengaging from no-longer relevant representations plays a key role in a recent model of cognitive control more generally, and may explain variability in WM capacity, or the ability to hold items in WM [@ShipsteadEtAl_2016]. Thus, in situations in which individuals must update WM by repeatedly switching within the same set of representations, costs may arise both via perseveration on an old representation, as well as the need to overcome inhibition of a previously-irrelevant representation.  

## Neural mechanisms of WM updating and the role of striatal dopamine
WM updating is implemented by frontostriatal circuitry in the brain. The prefrontal cortex (PFC) is involved in the stabilization and active maintenance of WM representations, whereas the striatum is involved in the rapid and selective gating of new information into PFC based on prior learning [@HazyEtAl_2007; @FrankEtAl_2001; @CoolsDEsposito_2011; @WestbrookBraver_2016]. In particular, striatal DA signals acting on two receptor subtypes (D1- and D2-Type) regulate this selective gating process. Phasic increases in DA in response to reward-predicting, task-relevant stimuli activate a D1 receptor-mediated pathway, which has the the downstream effect of lifting inhibition of PFC, and triggering gating of the reward-relevant stimuli into WM. When striatal DA levels dip, the D2 receptor-mediated pathway becomes uninhibited, which has the effect of preventing the gating of new representations into PFC [@FrankEtAl_2001]. Thus, whether or not WM updating occurs depends on the relative activation of the D1 and D2 pathways. 

In addition to phasic signals, tonic DA level in striatum also influences the relative ease of WM updating, primarily via its effects on the D2 pathway [@MaiaFrank_2011]. When tonic DA is high, the D2 pathway is less active and thus the threshold required for a phasic DA signal to trigger updating is lowered and WM updating should be facilitated. On the other hand, when tonic DA is low, the D2 pathway is more active, resulting in greater inhibition of gating and thus a higher threshold for WM udpdating. Empirical studies support this link between tonic DA levels, D2 pathway activation, and WM updating. Higher striatal D2 receptor density predicted improved reversal learning, which requires the ability to update WM representations [@GromanEtAl_2014]. Furthermore, a D2 receptor agnonist improved updating performance in subjects with low tonic DA [@vanHolsteinEtAl_2011]. Additionally, subjects with greater drug-induced DA release in striatum showed greater improvements in flexibility [@SamanezLarkinEtAl_2013]

The involvement of tonic DA in flexible updating is clear; however an open question is how tonic DA function affects WM updating across different task contexts, and in particular, in cases where WM updating requires one to ignore familiar, previously-relevant stimuli. On the one hand, higher tonic DA should bias the system towards updating by lowering the threshold phasic signal required to gate a new representation into WM. In addition to improved flexible updating, high tonic DA would also increase the likelihood that task-irrelevant stimuli will be gated into WM. However, it is not yet clear how tonic striatal dopamine activity affects the gating of previously-relevant versus novel task-irrelevant stimuli.

## Spontaneous eye blink rate (EBR) and WM updating 
The above question has been addressed by studies using spontaneous eye blink rate (EBR), an index of tonic striatal DA function [@JongkeesColzato_2016, see below for further discussion], which have found that the direction of the EBR-flexibility relationship depends on the specific properties of targets and distractors used in the task. @DreisbachEtAl_2005 used an attention set-shifting task with two updating conditions: In the Perseveration condition, updating involved shifting attention to an unfamiliar target color and ignoring a previously-relevant colour, whereas in the Learned Irrelevance condition, participants updated by shifting attention to a previously-ignored colour and ignoring a novel colour. Higher EBR predicted faster updating in the Perseveration condition, but slower updating in the Learned Irrelevance condition, and this finding has since been replicated [@MuellerEtAl_2007]. This work indicates that EBR does not simply predict the ease of WM updating in an indiscriminate manner; rather, the effects are selective and depend on specific task factors, such as whether the new target and distractor are novel or familiar, and their previous role in the task. However, it is not yet clear which factors drive these results. On the one hand, it is possible that higher EBR predicts improved ability to inhibit no-longer relevant representations, which would improve performance in the Perseveration condition but may harm performance in the Learned Irrelevance condition, because it may be more difficult to overcome the stronger backwards inhibition to activate a particular task set. On the other hand, it is also possible that high EBR predicts a novelty bias, making it easier to gate novel stimuli into WM, but also more difficult to ignore novel stimuli when they are task-irrelevant. 

In our own pilot study (*N*=61), participants performed a similar set-shifting task, which cued participants to shift their attention among 3 potential colors, all of which were present, either as distractors or target, on all trials. Thus, at each switch point, participants had to update their attentional set to attend a color that was previously a distractor and ignore a colour that was previously a target. Under these conditions, higher EBR predicted slower updating (*r*=.28, *p*=.03). Because there were no novel targets in this task, and in light of previous findings showing that higher EBR predicts less perseveration [@DreisbachEtAl_2005; @MuellerEtAl_2007], this finding suggested that perhaps participants with higher EBR had more difficulty overcoming inhibition of previously-irrelevant representations. Other work using the Stroop task has indeed shown that participants with higher EBR were better at ignoring irrelevant stimulus dimensions [@ZhangEtAl_2015]. Thus, it is possible that participants with high EBR also inhibit irrelevant task sets more strongly, which makes it more difficult to overcome to attend a target that has previously been a distractor. Absent the need to re-activate a previously-irrelevant representation, one might expect that if EBR does indeed reflect striatal DA tone, higher EBR would facilitate updating, by lowering the threshold required to gate new task representations into the PFC.  

## EBR as an index of tonic striatal DA function
EBR has long been linked with DA and DA-linked cognitive functions [for a comprehensive review, see @JongkeesColzato_2016]. Human populations with altered DA function exhibit characteristic changes in EBR - patients with Parkinson's Disease, in which striatal DA neurons are lost, have lower EBR [e.g., @DeuschlGoddemeier_1998], whereas individuals with schizophrenia, which is characterized by a hyperdopaminergic state, exhibit higher EBR [e.g., @MackertEtAl_1991]. EBR is correlated predictably with treatment success and symptom severity in these populations [e.g., @AksoyEtAl_2014; @OwensEtAl_1994] . Furthermore, drugs that increase DA levels and act on DA receptors often result in EBR changes in both humans and animals [@JongkeesColzato_2016]. 

However, the specific aspect of DA function that is linked with EBR is not yet well-understood. A prominent hypothesis is that EBR is related to tonic DA levels in the striatum, given its link with non-specific DA drugs and disease states with altered baseline DA. However, a recent study indicated that EBR was not positively correlated with DA synthesis capacity in the striatum, which would have been expected if EBR reflects tonic striatal DA [@SescousseEtAl_2017]. Another possibility is that spontaneous EBR predicts D2 receptor function. In monkeys, EBR predicted D2 receptor density (assessed ex vivo) and availability (assessed via PET), and was selectively responsive to a D2 receptor agonist [@GromanEtAl_2014]. In humans, however, this link between EBR and striatal D2 receptor availability was not replicated [@DangEtAl_2017]. Other work suggests that that the effects of D2 receptor drugs on EBR in humans are baseline-dependent [@CavanaghEtAl_2014]. In spite of these inconsistencies, there is still much evidence supporting a link between EBR and DA, as well as between EBR and DA-linked cognitive functions, such as WM updating ability [@JongkeesColzato_2016; @DreisbachEtAl_2005; @MuellerEtAl_2007], and ongoing work aims to more fully characterize the variance in DA function that can be explained by EBR [@SescousseEtAl_2017]. 

## The present studies
Using an attention shifting task, the present studies examined how the effectiveness of WM updating varies, depending on whether individuals must inhibit interference from previously-relevant task sets. Additionally, we compared the relationship between EBR and WM updating across these different task contexts with the aim of determining the conditions under which striatal DA function is relevant for WM updating.

In a series of 4 experiments, participants completed a cued attentional shifting task consisting of two updating conditions: Perseveration-Inhibition and Pure Updating. In the Perseveration-Inhibition condition, updating involved shifting the focus of attention away from a current target colour to instead attend a colour that was previously the distractor. Thus, both target and distractor were familiar to subjects, and switch costs may be, in part, attributable to both perseveration on the old target color as well as the need to overcome backwards inhibition of the new target. In the Pure Updating condition, updating involved shifting attention to a novel target and ignoring a novel distractor, and thus switch costs cannot be attributable to interference from a previous attentional set.  

Based on the results of our pilot study, we expected that in the Perseveration-Inhibition condition, higher EBR would again predict slower WM updating. If EBR is indeed an index of tonic striatal DA levels, we would additionally expect that higher EBR would predict faster WM updating in the Pure Updating condition. This latter prediction follows because higher DA levels should bias the fronto-striatal network towards updating by lowering the threshold required for a phasic DA signal to trigger updating [@MaiaFrank_2011].  

It is important to note, however, that although there is much evidence for a link between striatal DA and EBR (e.g., @JongkeesColzato_2016), the specific nature of this relationship is still unknown, and as outlined above, is likely to be more complicated than a straightforward index of striatal DA levels. Thus, for the present paper, we are using EBR to test the conditions in which striatal DA function is relevant to WM updating; however we will not be able to draw any directional conclusions about the relationship between striatal DA tone and WM updating. 

The present studies also had the exploratory aim of determining the temporal dynamics of updating across different task contexts (Perseveration-Inhibition vs. Pure Updating), by examining performance as a function of the number of trials from an update, and additionally how these temporal measures are related to EBR. For the sake of transparency, we note that we did not initially intend to analyze the data in this way; however the data indicated that performance in this task did not immediately reach baseline levels one trial following a task set update, but rather asymptoted more gradually over the course of several trials, and this is consistent with other work in which the timing of WM updating is unpredictable [@MonsellEtAl_2003].  

An additional advantage of the present study is that participants' eye movements were tracked, which made it possible to examine the gaze patterns underlying variability in performance across conditions. 

# Experiment 1
Experiment 1 addresses how the time scale of WM updating varies depending on whether the task requires inhibition of a prior attentional set, and whether these measures are related to EBR.

# Method

```{r pull info for method of Study 1, include=FALSE}
# Excluded Subjects - have been removed prior to data processing
# does not meet eligbility criteria (age, colourblindness, etc.): 216, 279, 291, 307, 316
# did not finish task: 217, 253, 263, 266, 268
# technical issues with task: 211, 232, 275
# couldn't track eye: 321
# Note: ID #312 was never assigned/got skipped

# demographic info
getDemographicInfo <- function(data){
  demogData <- data[!duplicated(data[,'ID']),]
  output <- list()
  output$meanAge <- mean(demogData$age)
  output$sdAge <- sd(demogData$age)
  output$numFemales <-  sum(demogData$gender=='Female')
  output$numMales <-  sum(demogData$gender=='Male')
  output$numOther <-  sum(demogData$gender=='Other')
  return(output)
}
demog1 <- getDemographicInfo(allData1)

# get error/trial removal info
getOmittedInfo1 <- function(data){
  omittedInfo <- list()
  #detach(package:plyr)
  # subjects excluded by errors
  errors <- dplyr::group_by(data, ID) %>%
    summarise(errorRate=mean(Error, na.rm=TRUE))
  omittedInfo$meanErrors <- mean(errors$errorRate, na.rm=TRUE)
  omittedInfo$sdErrors <- sd(errors$errorRate, na.rm=TRUE)
  omittedInfo$maxErrors <- omittedInfo$meanErrors + omittedInfo$sdErrors*3
  tooManyErrors <- filter(errors, errorRate>omittedInfo$maxErrors)
  omittedInfo$numExclErrors <- length(unique(tooManyErrors$ID))
  omittedInfo$tooManyErrors <- unique(tooManyErrors$ID)
  
  # trials excluded from RT analyses
  data$lnRT <- log(data$RT)
  dataTrialsOfInterest <- data[!(data$Trial==1 & data$Set==1),]
  dataTrialsOfInterest <- filter(dataTrialsOfInterest, Trial>4)
  findOutliers <- group_by(dataTrialsOfInterest, ID, Trial, Congruent, Blocktype) %>%
    summarise(meanlnRT=mean(lnRT, na.rm=TRUE),
              sdlnRT=sd(lnRT, na.rm=TRUE))
  findOutliers$exclude <- findOutliers$meanlnRT + excludeRTMaxSDs*findOutliers$sdlnRT
  findOutliers$excludeMin <- findOutliers$meanlnRT - excludeRTMaxSDs*findOutliers$sdlnRT
  dataTrialsOfInterest <- merge(dataTrialsOfInterest, findOutliers, by=c('ID', 'Trial','Congruent','Blocktype'), sort=FALSE)
  dataTrialsOfInterest$outlierMax <- dataTrialsOfInterest$exclude-dataTrialsOfInterest$lnRT
  dataTrialsOfInterest$outlierMin <- dataTrialsOfInterest$excludeMin-dataTrialsOfInterest$lnRT
  
  cleanData <- filter(dataTrialsOfInterest, RT>=excludeRTMin & RT<=excludeRTMax & outlierMax>0 & outlierMin<0)
  omittedInfo$removedTrials <- 1-(nrow(cleanData)/nrow(dataTrialsOfInterest))
  
  return(omittedInfo)
}

omittedInfo1 <- getOmittedInfo1(allData1)

# get info about eye blinks
# Participants with no EBR or eyetracking data because of corrupted .edf file: 265,306
getBlinkInfo <- function(data) {
  blinkInfo <- list()
  blinkData <- data[!duplicated(data[,'ID']),]
  blinkInfo$meanEBR <- mean(blinkData$ebr, na.rm=TRUE)
  blinkInfo$sdEBR <- sd(blinkData$ebr, na.rm=TRUE)
  blinkInfo$numExcluded <- sum(is.na(blinkData$ebr))
  exclude <- subset(data, is.na(ebr))
  blinkInfo$excludedSubs <- unique(exclude$ID)
  
  return(blinkInfo)
}

blinkInfo1 <- getBlinkInfo(allData1)

# get info about eye tracking
getGazeInfo <- function(data){
  gazeInfo <- list()
  data <- filter(data, Error==0, Blocktype>2, 
                 !(ID %in% blinkInfo1$excludedSubs),
                 !(ID %in% omittedInfo1$tooManyErrors))
  tarFixPct <- group_by(data, ID) %>%
    summarise(tarFixPct=mean(firstTarFix_tar, na.rm=TRUE))
  tooFewTarFixes <- filter(tarFixPct, tarFixPct<targetHitThresh)
  gazeInfo$excludeTarPct <- unique(tooFewTarFixes$ID)
  getNeutPct <- filter(data, !(ID %in% gazeInfo$excludeTarPct)) %>%
    group_by(ID) %>%
    summarise(neutPct=mean(firstNeutFix_neut, na.rm=TRUE))
  gazeInfo$meanNeutPct <- mean(getNeutPct$neutPct, na.rm=TRUE)
  
  return(gazeInfo)
}

gazeInfo1 <- getGazeInfo(allData1)

# Remove subjects with too many errors
allData1 <- filter(allData1, !(ID %in% omittedInfo1$tooManyErrors))
# get N for behavioral results
Nbeh1 <- length(unique(allData1$ID))
allEBRSubs <- subset(allData1, !is.na(ebr))
Nebr1 <- length(unique(allEBRSubs$ID))
allEBRSubsGen <- filter(allEBRSubs, (gender %in% c('Male','Female')))
Ngen1 <- length(unique(allEBRSubsGen$ID))
Ngaze1 <- Nebr1 - length(gazeInfo1$excludeTarPct)
```
## Participants
A power analysis based on our pilot study indicated that data from 100 participants were necessary in order to obtain statistical power of 0.8 with an alpha of .05 for the relationship between EBR and switch cost (*r*=.28). Thus, 124 students at the University of Oregon participated in this experiment for partial course credit. Eligible participants were between 18-30 years old and reported having normal or corrected-to-normal color vision. Data from 14 participants were excluded prior to analyses because of task presentation failure (3), participant withdrawal or lack of time to finish task (5), inability to track eye (1), and not meeting the eligibility criteria (5). The remaining 110 participants had a mean age of `r demog1$meanAge` (*SD*=`r demog1$sdAge`) and included `r demog1$numFemales` females, `r demog1$numMales` males, and `r demog1$numOther` individual who did not report being male or female. All procedures were approved by the Committee for the Protection of Human Subjects at the University of Oregon.   


## Procedure
After providing informed consent, participants completed a demographic questionnaire. Participants then received instructions for the attention shifting task and completed 3 brief practice blocks (8-12 trials each). Prior to the beginning of the experiment, the eye tracker was calibrated to ensure accurate measurement of eye gaze, and this calibration was repeated after every 2 blocks of the task, for a total of 4 calibrations. After the first calibration and following the final task block, participants completed the EBR baseline period. When the task was completed, participants responded to several questionnaires, and were then debriefed about the purpose of the experiment. The entire procedure lasted approximately 1 hour.  

(ref:capSchematic) Schematic of attention shifting task. On each trial, participants indicated whether the target letter was a consonant or a vowel, and the color of the target letter shifted every 4-6 trials. On Perseveration-Inhibition blocks (left), the target color and distractor color alternated roles at each switch point. On Pure Updating blocks (right), both target and distractor color were novel at each switch point.


```{r getSchematic, echo=FALSE, out.width='100%', fig.cap='(ref:capSchematic)'}

knitr::include_graphics('taskSchematic.png')

```

## Materials and Apparatus  
**Attention shifting task.** The attention shifting task was designed to measure participants' ability to update their attentional set, and shield their attentional set from distraction. To this end, participants were instructed to attend and respond about whether a letter in a target color is a consonant or a vowel, while ignoring a distractor letter in an irrelevant color. Periodically, the target color shifted, and performance following this shift was used to measure updating performance.  

Each set of trials began with the presentation of one of 6 possible color words (BLUE, RED, YELLOW, GREEN, ORANGE, PURPLE) for 2000ms in black text on a grey background, to indicate the target color on the upcoming set of trials (Figure\ \@ref(fig:getSchematic)). A fixation cross then appeared for 4000ms, after which the first trial of the set began. The fixation cross disappeared 100ms prior to the stimulus array, in order to encourage eye movements. The stimulus array consisted of three characters: the target letter, the distractor letter, and an irrelevant symbol in a third color. The irrelevant symbol was included to obtain an eye tracking index of general distractibility; however fixation of these stimuli was very rare. Characters were positioned at 3 evenly-spaced locations of 12 possible locations at a distance of 4.45 degrees from the center of the screen. The positions of the letters were never repeated on back-to-back trials. Letter stimuli were randomly selected from 5 consonants (D, F, H, L, V) and 5 vowels (A, E, I, O, U), and symbols were one of 5 non-letter characters (&, %, ?, #, @). The color of the non-letter symbol was selected from a different set of 6 colours to avoid overlap with the letter stimuli.   

On a given trial, there was a 50% chance that the distractor letter would be in the same category as the target (Congruent trials, e.g., both vowels), and a 50% that the distractor would be in the opposite category (Incongruent trials, i.e. one consonant, one vowel). Target and distractor letters were never identical on a given trial.  
As quickly as possible, participants indicated with a key press whether the target letter was a consonant or a vowel. The stimulus array remained on the screen until participant response, and then was replaced by a fixation cross for a 3500ms inter-trial interval (ITI). This longer ITI was chosen because we were also measuring pupillary responses and thus wanted to allow sufficient time for the pupil to return to baseline following each trial. Pupillometry data will not be reported here.  

Each set consisted of a randomized number of between 4-6 trials, to reduce predictability of WM updating. Participants completed sets of trials within each of 3 Block Types: Perseveration-Inhibition, Pure Updating, and Non-Switch. During Perseveration-Inhibition blocks, the target and distractor colours traded roles at each shift point, with the former target color becoming the new distractor and vice-versa. On Pure Updating blocks, both target and distractor colors in the new set were different from the two colors in the previous set for task schematic. Participants completed 3 blocks of 12 sets for both Perseveration-Inhibition and Pure Updating tasks in a randomized alternating order (i.e. either ABABAB or BABABA). On Non-Switch blocks, the target and distractor colors remained the same from set to set in order to examine the global effects of Switch on performance; however data from Non-Switch blocks will not be discussed further here. Non-Switch blocks each contained only 6 sets and took place at the beginning and end of the experiment. Thus, in total participants completed 8 blocks of the attention shifting task, containing approximately 420 trials.

**EBR Baseline.** EBR baseline periods took place immediately after the first calibration and following the final task block. Participants were instructed to relax and look at a fixation cross in the center of the screen for 2 minutes.

```{r check caffeine and sleep - Study 1, include=FALSE}
winsorizeEBR <- function(cleanData, blinkInfo) {
  maxEBR <- blinkInfo$meanEBR + (winsorizeErrorsSD*blinkInfo$sdEBR)
  findNextSmallestEBR <- filter(cleanData, ebr<maxEBR)
  winsValEBR <- max(findNextSmallestEBR$ebr)
  cleanData$ebr[cleanData$ebr>maxEBR] <- winsValEBR
  
  return(cleanData)
} 

cleanData1_EBR <- winsorizeEBR(allData1, blinkInfo1)
cleanData1_EBR <- group_by(cleanData1_EBR, ID, caffeine) %>%
  summarise(meanSleep=mean(sleep, na.rm=TRUE),
            ebr=mean(ebr, na.rm=TRUE))

getFormattedResults_lm <- function(LMresults){
  colnames(LMresults) <- c('beta','se','tval','pval')
  if (LMresults$beta<.001) {
    LMresults$beta=formatC(LMresults$beta, format='e',digits=2)
    } else {LMresults$beta <- round(LMresults$beta, digits=2)}
  if (LMresults$se<.001) {
    LMresults$se=formatC(LMresults$se, format='e',digits=2)
    } else {LMresults$se <- round(LMresults$se, digits=2)}
 if (LMresults$tval<.001) {
    LMresults$tval=formatC(LMresults$tval, format='e',digits=2)
    } else {LMresults$tval <- round(LMresults$tval, digits=2)}
  LMresults$pval <- round(LMresults$pval, digits=2)
  LMresults$pval <- rd(LMresults$pval, digits=2)
  LMresults$pval[LMresults$pval=='.000000'] <- '<.001'
  
  return(LMresults)
  
}

model0.1.6 <- lm(ebr ~ caffeine,
                 data=cleanData1_EBR,
                 na.action=na.exclude)

model0.1.7 <- lm(ebr ~ meanSleep,
                 data=cleanData1_EBR,
                 na.action=na.exclude)

results0.1.6 <- as.data.frame(coef(summary(model0.1.6)))
results0.1.6 <- getFormattedResults_lm(results0.1.6)

results0.1.7 <- as.data.frame(coef(summary(model0.1.7)))
results0.1.7 <- getFormattedResults_lm(results0.1.7)
```

**Questionnaire Measures.** Prior to the task, participants provided their demographic information. Following the task, participants completed the Behavioral Activation and Inhibition Scales (BIS/BAS; @CarverWhite_1994), Sensitivity to Punishment and Sensitivity to Reward Questionnaire (SPSRQ; @TorrubiaEtAl_2001), and the Barratt Impulsivity Scale [@PattonEtAl_1995]. These measures were chosen because of the relevance of behavioral activation, reward sensitivity, and impulsivity to dopamine function [@CoolsEtAl_2007] for the purposes of future exploratory analysis, and are not discussed further here. Finally, participants responded about their caffeine consumption for the day and the number of hours of sleep during the previous night, because of their potential relationship to EBR. The relationship between caffeine consumption and EBR did not reach significance (*B* = `r results0.1.6$beta[2]`, *SE*=`r results0.1.6$se[2]`, *t*(`r model0.1.6$df`)=`r results0.1.6$tval[2]` *p*=`r results0.1.6$pval[2]`); however participants with fewer hours of sleep had greater EBR (*B* = `r results0.1.7$beta[2]`, *SE*=`r results0.1.7$se[2]`, *t*(`r model0.1.7$df[2]`)=`r results0.1.7$tval[2]` *p*=`r results0.1.7$pval[2]`).

**Apparatus.** The attention shifting task was run with Psychophysics Toolbox in MATLAB [@Brainard_1997]. Stimuli were presented using a Mac Mini computer and an 18'' monitor with a resolution of 1024 x 768 pixels. Participants made responses using the left and right arrow keys on a standard QWERTY keyboard.  

Participants completed the task while their eyes were tracked using an Eyelink CL infrared eyetracker and using Eyelink 1000 software (Version 4.56; SR Research, Missisauga, Ontario, Canada) with a sampling rate of 1000 Hz. Participants' heads were stabilized using a chin rest located 50 cm from the eyetracker.

## Data Processing and Analysis
**Behavioral Data.** Participants performed the task with an overall error rate of `r omittedInfo1$meanErrors*100`% (*SD* = `r omittedInfo1$sdErrors*100`%). Data from `r omittedInfo1$numExclErrors` participants were removed because of an error rate greater than `r excludeMaxErrorRateSDs` standard deviations from the group mean, leaving a sample of `r 110-omittedInfo1$numExclErrors` for the behavioral analyses. The first trial of each block, as well as the fifth and sixth trials of each set were excluded from all analyses. To correct for non-normality, data were transformed using the natural log (lnRT). All RTs less than `r excludeRTMin` ms, greater than `r excludeRTMax` ms, or more than `r excludeRTMaxSDs` standard deviations from the participant's mean lnRT were removed from RT analyses (`r omittedInfo1$removedTrials*100`% of trials). Error trials were excluded from RT analyses. For error rate analyses, in cases where a participant's error rate in a particular condition was greater than `r winsorizeErrorsSD` standard deviations from the group mean, the value was winsorized to the next largest value within `r winsorizeErrorsSD` standard deviations from the group mean.  

**Eye Tracking Data.** All eye tracking and eye blink data were processed in R [@R-base] using the itrackR [@R-itrackR] and edfR packages [@R-edfR]. Prior to eye tracking analysis, elliptical regions of interest (ROIs) were defined, centered on each of the 12 potential target locations, with an x radius of 45 and a y radius of 90 pixels. Additionally, a circular ROI (radius = 65 pixels) was defined in the center of the screen, to denote the location of the central fixation cross, which disappears at trial onset. Data were then drift-corrected by block, using itrackR's drift_correct function with a threshold of 15 pixels. All fixations and saccades occurring while the target array was visible were classified according to whether they were directed towards the ROIs containing the target, distractor, or non-letter object.

Prior to hypothesis-driven analyses of eye tracking data, there were additional quality-control checks performed, to ensure the validity of fixation and saccade data as an index of participants' underlying mental processes. First, `r length(gazeInfo1$excludeTarPct)` participants who fixated on the target on fewer than `r targetHitThresh*100`% of trials were excluded from hypothesis-driven eye tracking analyses, so that analyses were performed only on subjects who were routinely making saccades to the target and not using an alternative strategy (e.g. covert attention). Data from an additional `r blinkInfo1$numExcluded` participants were excluded because of corrupted eye tracking data. Additionally, it was possible that as participants became more accustomed to the task, they adopted a more efficient covert attention strategy, and thus we first checked whether the tendency to fixate on the target changed over the course of the experiment. A second possibility was that high performers might have used a covert attention strategy, rather than fixating the target on each trial, so we additionally tested the relationship between target fixation probability and overall performance indices (RT, error rate).  

Analyses of interest examined the tendency for participants to fixate on the distractor before the target, and also the time of participants' first saccade towards the target. The former measure was used as an explicit index of distractibility by the irrelevant target, because it indicates that participants looked first at the distractor rather than the target. The proportion of trials on which participants fixated on the distractor ROI prior to the target ROI was calculated for each experimental condition, and error trials were included in these analyses. We additionally examined participants' tendency to fixate the always-irrelevant non-letter character ROI; however this measure did not differ across conditions, perhaps because of a very low fixation rate overall (`r round(gazeInfo1$meanNeutPct, digits=2)*100`%), and thus are not reported further here. The latter measure, timing of participants' first saccade to the target, was used as a more implicit index of participants' hesitation to move their eyes towards the target, and was examined only for correct trials in which participants fixated the target prior to the distractor. Saccade time was defined as the time from stimulus onset at which participants initiated a their first saccade to the target. 

**EBR Data.** Blinks were identified in the pupillometry data using the noise-based algorithm described in @HershmanEtAl_2018. Events in which the pupil size was reduced to 0 were counted as blinks when they were at least 100ms removed from other blink events [@HershmanEtAl_2018] and had a duration between 50-500ms. Although other studies [@AartsEtAl_2012; @PasEtAl_2014] have used a higher minimum blink duration (100 ms), manual inspection of recorded pupillometry data prior to statistical analyses demonstrated that with the equipment used to collect this dataset, a large number of blinks are between 50-100 ms in duration. Additionally, other work has estimated that 50 ms is the lower limit for the duration that eyelids are closed during a blink [@SternEtAl_1984]. EBR was then calculated by dividing the number of blinks by 2, to obtain a measure of the average number of blinks per minute. In order to keep as many participants as possible for between-subjects analyses while limiting the influence of outliers, values of EBR that were `r winsorizeErrorsSD` standard deviations from the group mean (*Mean*=`r blinkInfo1$meanEBR`, *SD*=`r blinkInfo1$sdEBR`) were winsorised. As noted above, eye tracking data from `r blinkInfo1$numExcluded` participants were corrupted, and thus these participants were not included in EBR analyses.  

**Statistical analyses.** Statistical analyses used linear mixed models (LMMs) to control for random subject-level variability.  In RT analyses, observations were single trials, whereas in error rate analyses observations were aggregated performance within each condition. Observations were nested within subjects, which were modeled with fixed slopes and random intercepts. All analyses were run in R using the lmer package to compute LMMs [@R-lme4] and lmer.test package to compute statistical significance [@R-lmerTest].  

Dependent variables were lnRT and error rate, and additionally probability of distractor fixation and the target saccade time for eye tracking analyses. Independent variables were Trial (1-4), Congruence (Congruent, Incongruent), Block Type (Perseveration-Inhibition, Pure Updating), and EBR. Because participants' gender has been known to influence the relationship between EBR and cognitive control, we additionally entered Gender as an additional independent variable in EBR analyses. All continuous predictor variables (Trial, EBR) were centered prior to analyses. As noted above, outliers at the single-trial level (i.e. RTs) were removed from analyses, whereas outliers were at the level of Subject (i.e. EBR) or condition (i.e. error rate) were winsorized, in order to minimize the effects of outliers on the models while also retaining as many subjects as possible in the analyses.  

# Results
## Behavioral Results (*N*=`r Nbeh1`)
```{r Study 1 behavioral results, include=FALSE}
# remove trials excluded from RT analyes
getCleanDataRT_Study1 <- function(allData) {
  # remove trials excluded from RT analyses
  cleanDataRT <- filter(allData, Error==0, Blocktype>2, Trial<5, !(Trial==1 & Set==1))
  
  # log transform RTs and find outliers
cleanDataRT$lnRT <- log(cleanDataRT$RT)
findOutliers <- group_by(cleanDataRT, ID, Trial, Blocktype, Congruent) %>%
  summarise(meanlnRT=mean(lnRT, na.rm=TRUE),
            sdlnRT=sd(lnRT, na.rm=TRUE))
findOutliers$exclude <- findOutliers$meanlnRT + excludeRTMaxSDs*findOutliers$sdlnRT
findOutliers$excludeMin <- findOutliers$meanlnRT - excludeRTMaxSDs*findOutliers$sdlnRT
cleanDataRT <- merge(cleanDataRT, findOutliers, by=c('ID', 'Trial','Blocktype','Congruent'), sort=FALSE)
cleanDataRT$outlierMax <- cleanDataRT$exclude-cleanDataRT$lnRT
cleanDataRT$outlierMin <- cleanDataRT$excludeMin-cleanDataRT$lnRT

# remove outliers
cleanDataRT <- filter(cleanDataRT, 
                                    RT>=excludeRTMin & RT<=excludeRTMax & outlierMax>0 & outlierMin<0)

}

cleanData1_RT <- getCleanDataRT_Study1(allData1)

# create factors and center continuous variables
getFactors_Study1 <- function(cleanData){
  cleanData$Congruent <- factor(cleanData$Congruent,
                              levels=c(1,2),
                              labels=c('Congruent','Incongruent'))
  cleanData$Blocktype <- factor(cleanData$Blocktype,
                              levels=c(3,4),
                              labels=c('Pure Updating','Perseveration-Inhibition'))
  cleanData$ID <- factor(cleanData$ID)
  
  
  trials <- unique(cleanData$Trial)
  meanTrial <- mean(trials)
  cleanData$Trial_Ctr <- cleanData$Trial - meanTrial
  
  return(cleanData)
}

cleanData1_RT <-getFactors_Study1(cleanData1_RT)

# legend for naming models:
# first number - number of analysis in experiment
# second number - experiment
# third number - error rate vs. RT as DV (1 for RT, 2 for error rate)

# test null model and compute ICC for RTs:
model0.1.1 <- lmer(lnRT ~ 1 +
                 (1|ID),
               data=cleanData1_RT,
               na.action=na.exclude)

varcom <- as.data.frame(VarCorr(model0.1.1))
L2var <- varcom$vcov[1]
L1var <- varcom$vcov[2]
icc0.1.1 <- round((L2var/(L2var+L1var)), digits=2)

# RT model with predictors:
model1.1.1 <- lmer(lnRT ~ Trial_Ctr*Blocktype*Congruent +
                     (1|ID),
                   data=cleanData1_RT,
                   na.action=na.exclude)

results1.1.1 <- as.data.frame(coef(summary(model1.1.1)))

getFormattedResults <- function(LMMresults){
  colnames(LMMresults) <- c('beta','se','df','tval','pval')
  LMMresults$beta <- ifelse(LMMresults$beta<.01, 
                            formatC(LMMresults$beta, format='e',digits=2),
                            round(LMMresults$beta, digits=2))
  LMMresults$se <- ifelse(LMMresults$se<.01, 
                            formatC(LMMresults$se, format='e',digits=2),
                            round(LMMresults$se, digits=2))
  LMMresults$df <- round(LMMresults$df, digits=2)
  LMMresults$tval <- round(LMMresults$tval, digits=2)
  LMMresults$pval <- round(LMMresults$pval, digits=2)
  LMMresults$pval <- rd(LMMresults$pval, digits=2)
  LMMresults$pval[LMMresults$pval=='.000000'] <- '<.001'
 # LMMresults$se <- rd(LMMresults$se, digits=2)
  #LMMresults$se[LMMresults$se=='.00'] <- '<0.01'
  #LMMresults$beta <- rd(LMMresults$beta, digits=2)
  #LMMresults$beta[LMMresults$beta=='.00'] <- '<0.01'

  return(LMMresults)
  
}

results1.1.1 <- getFormattedResults(results1.1.1)

# post-hoc models to look at congruent and incongruent trials separately:
cleanData1_RT_cong <- filter(cleanData1_RT, Congruent=='Congruent')
cleanData1_RT_incong <- filter(cleanData1_RT, Congruent=='Incongruent')

model1.1.1a <- lmer(lnRT ~ Trial_Ctr*Blocktype +
                     (1|ID),
                   data=cleanData1_RT_cong,
                   na.action=na.exclude)

model1.1.1b <- lmer(lnRT ~ Trial_Ctr*Blocktype +
                     (1|ID),
                   data=cleanData1_RT_incong,
                   na.action=na.exclude)

results1.1.1a <- as.data.frame(coef(summary(model1.1.1a)))
results1.1.1a <- getFormattedResults(results1.1.1a)
results1.1.1b <- as.data.frame(coef(summary(model1.1.1b)))
results1.1.1b <- getFormattedResults(results1.1.1b)


# Error Rate Analyses
getCleanDataER <- function(allData) {
  # remove trials excluded from RT analyses
  cleanDataER <- filter(allData, Blocktype>2, Trial<5, !(Trial==1 & Set==1))
}

cleanData1_ER <- getCleanDataER(allData1)
cleanData1_ER <- getFactors_Study1(cleanData1_ER)


getCleanSummary_Study1 <- function(cleanData){
  # find mean error rate for each condition
  summaryData <- group_by(cleanData, ID, Trial_Ctr, Blocktype, Congruent) %>%
    summarise(eRate = 100*(mean(Error, na.rm=TRUE)),
              ebr=(mean(ebr, na.rm=TRUE)))
  
  # winsorize summarized data
  meanErate <- mean(summaryData$eRate)
  sdErate <- sd(summaryData$eRate)
  maxErate <- meanErate + winsorizeErrorsSD*sdErate
  findNextLargestErate <- filter(summaryData, eRate<maxErate)
  maxValueErate <- max(findNextLargestErate$eRate)
  summaryDataClean <- summaryData
  summaryDataClean$eRate[summaryDataClean$eRate>maxErate] <- maxValueErate

  return(summaryDataClean)
  
}
summaryData1_ER <- getCleanSummary_Study1(cleanData1_ER)

# null model for error rate
model0.1.2 <- lmer(eRate ~ 1 +
                   (1|ID),
                 data=summaryData1_ER,
                 na.action=na.exclude)

varcom <- as.data.frame(VarCorr(model0.1.2))
L2var <- varcom$vcov[1]
L1var <- varcom$vcov[2]
icc0.1.2 <- L2var/(L2var+L1var)

# prediction model for error rate
model1.1.2 <- lmer(eRate ~ Trial_Ctr*Blocktype*Congruent + 
                   (1|ID),
                 data=summaryData1_ER,
                 na.action=na.exclude)

results1.1.2 <- as.data.frame(coef(summary(model1.1.2)))
results1.1.2 <- getFormattedResults(results1.1.2)


```
**RT.** Behavioral effects of the task conditions on RT were estimated by entering trial-by-trial log-transformed RTs nested within subjects into an LMM. The null model with no predictors had an intra-class correlation of `r icc0.1.1`, indicating a sufficient degree of within-subject clustering to justify the use of mixed models for analysis.  

The full model tested the effects of Trial (1-4), Block Type (Perseveration-Inhibition vs. Pure Updating), and Congruence (Congruent vs. Incongruent) and their interactions on RT. As expected, there was a significant main effect of Trial (*B* = `r results1.1.1$beta[2]`, *SE*=`r results1.1.1$se[2]`, *t*(`r results1.1.1$df[2]`)=`r results1.1.1$tval[2]` *p*=`r results1.1.1$pval[2]`), indicating that participants responded more slowly on earlier trials (i.e. trials closer to a switch) than on later trials. There was additionally a main effect of Block Type (*B* = `r results1.1.1$beta[3]`, *SE*=`r results1.1.1$se[3]`, *t*(`r results1.1.1$df[3]`)=`r results1.1.1$tval[3]` *p*=`r results1.1.1$pval[3]`), with participants responding more slowly on Perseveration-Inhibition blocks. The interaction between Trial and Block Type also reached significance (*B* = `r results1.1.1$beta[5]`, *SE*=`r results1.1.1$se[5]`, *t*(`r results1.1.1$df[5]`)=`r results1.1.1$tval[5]` *p*=`r results1.1.1$pval[5]`). As shown in Figure\ \@ref(fig:figModela), immediately following a switch, RTs are slower for both Block Types; however they decline more quickly over the course of a set compared to Perseveration-Inhibition blocks. This effect appears to be driven by Congruent trials; however the 3-way interaction that also included Congruence did not reach significance (*B* = `r results1.1.1$beta[8]`, *n.s.*). Post-hoc analyses in which Congruent and Incongruent trials were examined separately indicated a significant interaction on Congruent (*B* = `r results1.1.1a$beta[4]`, *SE*=`r results1.1.1a$se[4]`, *t*(`r results1.1.1a$df[4]`)=`r results1.1.1a$tval[4]` *p*=`r results1.1.1a$pval[4]`), but not Incongruent (*B* = `r results1.1.1b$beta[4]`, *SE*=`r results1.1.1b$se[4]`, *t*(`r results1.1.1b$df[4]`)=`r results1.1.1b$tval[4]` *p*=`r results1.1.1b$pval[4]`) trials.

The main effect of Congruence did not approach significance (*B* = `r results1.1.1$beta[4]`, *n.s.*), however there was a marginally significant interaction between Trial and Congruence (*B* = `r results1.1.1$beta[6]`, *SE*=`r results1.1.1$se[6]`, *t*(`r results1.1.1$df[6]`)=`r results1.1.1$tval[6]` *p*=`r results1.1.1$pval[6]`), indicating that incongruence costs increased at later points in a set.  

(ref:capModela) Model estimates of reaction time (RT) across conditions of the attention shifting task in Experiment 1. Error bars represent the 95% confidence interval (CI). There was a significant interaction between Block Type and Trial, indicating that RTs were slower to asymptote following an attention shift on Perseveration-Inhibition blocks compared to Pure Updating blocks.

```{r figModela, echo=FALSE, message=FALSE, out.width='100%', fig.cap='(ref:capModela)'}

getFigDat_RT_Study1 <- function(model) {
  
  figDat <- expand.grid(
    Trial_Ctr=c(-1.5,-0.5,0.5,1.5),
    Blocktype=c('Perseveration-Inhibition','Pure Updating'),
    Congruent=c('Congruent','Incongruent'),
    lnRT=0
  )
  
  figDat$lnRT <- predict(model, figDat, re.form=NA) 
  fd <- model.matrix(terms(model), figDat)
  
  pvar1 <- diag(fd %*% tcrossprod(vcov(model),fd))
  tvar1 <- pvar1+VarCorr(model)$ID[1]
  cmult <- 1.96 ## could use 1.96
  
  figDat <- data.frame(
    figDat
    , plo = figDat$lnRT-cmult*sqrt(pvar1)
    , phi = figDat$lnRT+cmult*sqrt(pvar1)
    , tlo = figDat$lnRT-cmult*sqrt(tvar1)
    , thi = figDat$lnRT+cmult*sqrt(tvar1)
  )
  
  return(figDat)
}

figDat1.1.1 <- getFigDat_RT_Study1(model1.1.1)

convertFigValues_RT <- function(figDat) {
  e <- exp(1)
  figDat$RT <- e^figDat$lnRT
  figDat$ploRT <- e^figDat$plo
  figDat$phiRT <- e^figDat$phi
  figDat$tloRT <- e^figDat$tlo
  figDat$thiRT <- e^figDat$thi
  figDat$Trial <- figDat$Trial_Ctr + (mean(c(1:keepingTrials)))
  
  return(figDat)
}

figDat1.1.1 <- convertFigValues_RT(figDat1.1.1)

p=ggplot(figDat1.1.1, aes(x=Trial, y=RT, shape=Blocktype))+
  geom_line(aes(x=Trial, y=RT, linetype=Blocktype)) +
  facet_grid(.~Congruent) +
  scale_linetype_discrete(name='Block Type') +
  scale_shape_discrete(name='Block Type') +
  labs(x='Trial', y='RT (ms)')
p+theme_apa()+geom_pointrange(aes(ymin = ploRT, ymax = phiRT))
```

**Error Rate.** The null model for error rate had an ICC of `r icc0.1.2`. In the full model, there was a significant effect of Congruence (*B* = `r results1.1.1$beta[4]`, *SE*=`r results1.1.1$se[4]`, *t*(`r results1.1.1$df[4]`)=`r results1.1.1$tval[4]` *p*=`r results1.1.1$pval[4]`), with participants making more errors on Incongruent versus Congruent trials. The only other effect of note was an interaction between Congruence and Block Type (*B* = `r results1.1.1$beta[7]`, *SE*=`r results1.1.1$se[7]`, *t*(`r results1.1.1$df[7]`)=`r results1.1.1$tval[7]` *p*=`r results1.1.1$pval[7]`). As shown in Figure\ \@ref(fig:figModelb), incongruence costs were larger on Perseveration-Inhibition blocks compared to Pure Updating blocks. All other main effects and interactions did not reach significance.

(ref:capModelb) Model estimates for error rate across conditions of the attention shifting task in Experiment 1. Error bars represent the 95% confidence interval (CI). There was a significant interaction between Block Type and Congruence, which indicated that participants were more prone to making errors on Incongruent trials of Perseveration-Inhibition blocks.

```{r figModelb, echo=FALSE, message=FALSE, out.width='100%', fig.cap='(ref:capModelb)'}

getFigDat_ER_Study1 <- function(model) {
  
  figDat <- expand.grid(
    Trial_Ctr=c(-1.5,-0.5,0.5,1.5),
    Blocktype=c('Perseveration-Inhibition','Pure Updating'),
    Congruent=c('Congruent','Incongruent'),
    eRate=0
  )
  
  figDat$eRate <- predict(model, figDat, re.form=NA) 
  fd <- model.matrix(terms(model), figDat)
  
  pvar1 <- diag(fd %*% tcrossprod(vcov(model),fd))
  tvar1 <- pvar1+VarCorr(model)$ID[1]
  cmult <- 1.96 ## could use 1.96
  
  figDat <- data.frame(
    figDat
    , plo = figDat$eRate-cmult*sqrt(pvar1)
    , phi = figDat$eRate+cmult*sqrt(pvar1)
    , tlo = figDat$eRate-cmult*sqrt(tvar1)
    , thi = figDat$eRate+cmult*sqrt(tvar1)
  )
  
  return(figDat)
}

figDat1.1.2 <- getFigDat_ER_Study1(model1.1.2)

convertFigValues_ER <- function(figDat) {
  figDat$Trial <- figDat$Trial_Ctr + (mean(c(1:keepingTrials)))

  return(figDat)
}

figDat1.1.2 <- convertFigValues_ER(figDat1.1.2)

p=ggplot(figDat1.1.2, aes(x=Trial, y=eRate, shape=Congruent))+
  geom_line(aes(x=Trial, y=eRate, linetype=Congruent)) +
  facet_grid(.~Blocktype) +
  scale_linetype_discrete(name='Congruent') +
  scale_shape_discrete(name='Congruent') +
  labs(x='Trial', y='Error Rate (%)')
p+theme_apa()+geom_pointrange(aes(ymin = plo, ymax = phi))

```

## Eyetracking Results (*N*=`r Ngaze1`)
```{r Study 1 eyetracking results, include=FALSE}

getCleanDataGaze_allCorrect <- function(data, gazeInfo, blinkInfo) {
  cleanGazeData_corr <- filter(data, Error==0, Blocktype>2, Trial<5, !(Trial==1 & Set==1),
                               !(ID %in% blinkInfo$excludedSubs),
                               !(ID %in% gazeInfo$excludeTarPct))
  
  return(cleanGazeData_corr)
}

getCleanDataGaze_withErrors <- function(data, gazeInfo, blinkInfo) {
  cleanGazeData_errors <- filter(data, Blocktype>2, Trial<5, !(Trial==1 & Set==1),
                               !(ID %in% blinkInfo$excludedSubs),
                               !(ID %in% gazeInfo$excludeTarPct))
  return(cleanGazeData_errors)
}

gazeData_allCorr1 <- getCleanDataGaze_allCorrect(allData1, gazeInfo1, blinkInfo1)
gazeData_errors1 <- getCleanDataGaze_withErrors(allData1, gazeInfo1, blinkInfo1)

# quality check - does % of target fixations decrease over the course of the experiment?
aggByBlock <- function(data){
  summaryData <- group_by(data, ID, Block) %>%
    summarise(meanTarPct=mean(firstTarFix_tar, na.rm=TRUE))
  
  # center block
  meanBlock <- mean(unique(summaryData$Block), na.rm=TRUE)
  summaryData$Block_Ctr <- summaryData$Block - meanBlock
  
  # winsorize tar fixation values
  gmeanTarPct <- mean(summaryData$meanTarPct, na.rm=TRUE)
  sdTarPct <- sd(summaryData$meanTarPct, na.rm=TRUE)
  minTarPct <- gmeanTarPct - winsorizeErrorsSD*sdTarPct
  findNextLowestTarPct <- filter(summaryData, meanTarPct>minTarPct)
  repTarPct <- min(findNextLowestTarPct$meanTarPct, na.rm=TRUE)
  summaryData$meanTarPct[summaryData$meanTarPct<minTarPct] <- repTarPct
  
  return(summaryData)
}

summaryDataByBlock1 <- aggByBlock(gazeData_allCorr1)

model0.1.3 <- lmer(meanTarPct ~ Block_Ctr +
                     (1|ID),
                   data=summaryDataByBlock1,
                   na.action=na.exclude)
results0.1.3 <- as.data.frame(coef(summary(model0.1.3)))
results0.1.3 <- getFormattedResults(results0.1.3)

# quality check - does % of target fixations relate to performance (RT/Errors)?
aggBySub_RT <- function(data){
    # log transform RTs and find outliers
  data$lnRT <- log(data$RT)
  findOutliers <- group_by(data, ID) %>%
    summarise(meanlnRT=mean(lnRT, na.rm=TRUE),
            sdlnRT=sd(lnRT, na.rm=TRUE))
  findOutliers$exclude <- findOutliers$meanlnRT + excludeRTMaxSDs*findOutliers$sdlnRT
  findOutliers$excludeMin <- findOutliers$meanlnRT - excludeRTMaxSDs*findOutliers$sdlnRT
  data <- merge(data, findOutliers, by=c('ID'), sort=FALSE)
  data$outlierMax <- data$exclude-data$lnRT
  data$outlierMin <- data$excludeMin-data$lnRT

  # remove outliers
  data <- filter(data, RT>=excludeRTMin & RT<=excludeRTMax & outlierMax>0 & outlierMin<0)

  
  summaryData <- group_by(data, ID) %>%
    summarise(meanTarPct=mean(firstTarFix_tar, na.rm=TRUE),
              meanlnRT=mean(lnRT, na.rm=TRUE))
  
  # winsorize tar fixation values
  gmeanTarPct <- mean(summaryData$meanTarPct, na.rm=TRUE)
  sdTarPct <- sd(summaryData$meanTarPct, na.rm=TRUE)
  minTarPct <- gmeanTarPct - winsorizeErrorsSD*sdTarPct
  findNextLowestTarPct <- filter(summaryData, meanTarPct>minTarPct)
  repTarPct <- min(findNextLowestTarPct$meanTarPct, na.rm=TRUE)
  summaryData$meanTarPct[summaryData$meanTarPct<minTarPct] <- repTarPct
  
  return(summaryData)
}

summaryDataBySub1 <- aggBySub_RT(gazeData_allCorr1)

model0.1.4 <- lm(meanTarPct ~ meanlnRT,
                 data=summaryDataBySub1,
                 na.action=na.exclude)


results0.1.4 <- as.data.frame(coef(summary(model0.1.4)))
results0.1.4 <- getFormattedResults_lm(results0.1.4)

aggBySub_errors <- function(data){
    # log transform RTs and find outliers
  
  summaryData <- group_by(data, ID) %>%
    summarise(meanTarPct=mean(firstTarFix_tar, na.rm=TRUE),
              eRate=mean(Error, na.rm=TRUE))
  
  # winsorize tar fixation values
  gmeanTarPct <- mean(summaryData$meanTarPct, na.rm=TRUE)
  sdTarPct <- sd(summaryData$meanTarPct, na.rm=TRUE)
  minTarPct <- gmeanTarPct - winsorizeErrorsSD*sdTarPct
  findNextLowestTarPct <- filter(summaryData, meanTarPct>minTarPct)
  repTarPct <- min(findNextLowestTarPct$meanTarPct, na.rm=TRUE)
  summaryData$meanTarPct[summaryData$meanTarPct<minTarPct] <- repTarPct
  
    # winsorize summarized data
  meanErate <- mean(summaryData$eRate)
  sdErate <- sd(summaryData$eRate)
  maxErate <- meanErate + winsorizeErrorsSD*sdErate
  findNextLargestErate <- filter(summaryData, eRate<maxErate)
  maxValueErate <- max(findNextLargestErate$eRate)
  summaryData$eRate[summaryData$eRate>maxErate] <- maxValueErate
  
  return(summaryData)
}

summaryDataBySub1_errors <- aggBySub_errors(gazeData_errors1)

model0.1.5 <- lm(meanTarPct ~ eRate,
                 data=summaryDataBySub1_errors,
                 na.action=na.exclude)
results0.1.5 <- as.data.frame(coef(summary(model0.1.5)))
results0.1.5 <- getFormattedResults_lm(results0.1.5)


# Distractor Fixation Probability
getDistFixProb_Study1 <- function(data){
  
  data$distFirst <- 0
  data$copyTarFixOnset <- data$firstTarFix_relOnsetTime
  data$copyDistFixOnset <- data$firstDistFix_relOnsetTime
  data$copyTarFixOnset[is.na(data$copyTarFixOnset)] <- 99999
  data$copyDistFixOnset[is.na(data$copyDistFixOnset)] <- 99999
  data$distFirst[data$copyDistFixOnset<data$copyTarFixOnset] <- 1
  
  summaryData <- group_by(data, ID, Trial, Blocktype, Congruent) %>%
      summarise(distFixProb = 100*(mean(distFirst, na.rm=TRUE)))
  
  # winsorize summarized data
  meanDistFix <- mean(summaryData$distFixProb)
  sdDistFix <- sd(summaryData$distFixProb)
  maxDistFix <- meanDistFix + winsorizeErrorsSD*sdDistFix
  findNextLargestDistFix <- filter(summaryData, distFixProb<maxDistFix)
  maxValueDistFix <- max(findNextLargestDistFix$distFixProb)
  summaryData$distFixProb[summaryData$distFixProb>maxDistFix] <- maxValueDistFix
  
  return(summaryData)
}

summaryData_distFix1 <- getDistFixProb_Study1(gazeData_errors1)
summaryData_distFix1 <- getFactors_Study1(summaryData_distFix1)

# null model for distractor fixation probability
model0.1.6 <- lmer(distFixProb ~ 1 +
                   (1|ID),
                 data=summaryData_distFix1,
                 na.action=na.exclude)

varcom <- as.data.frame(VarCorr(model0.1.6))
L2var <- varcom$vcov[1]
L1var <- varcom$vcov[2]
icc0.1.6 <- round(L2var/(L2var+L1var), digits=2)

model3.1.1 <- lmer(distFixProb ~ Trial_Ctr*Blocktype*Congruent +
                     (1|ID),
                   data=summaryData_distFix1,
                   na.action=na.exclude)
results3.1.1 <- as.data.frame(coef(summary(model3.1.1)))
results3.1.1 <- getFormattedResults(results3.1.1)

# Saccade Time
getSaccadeTime_Study1 <- function(data){
  
  data$distFirst <- 0
  data$copyTarFixOnset <- data$firstTarFix_relOnsetTime
  data$copyDistFixOnset <- data$firstDistFix_relOnsetTime
  data$copyTarFixOnset[is.na(data$copyTarFixOnset)] <- 99999
  data$copyDistFixOnset[is.na(data$copyDistFixOnset)] <- 99999
  data$distFirst[data$copyDistFixOnset<data$copyTarFixOnset] <- 1
  
  data <- filter(data, firstTarSacc_tar==1, distFirst==0, firstTarSacc_relOnsetTime<excludeRTMax)
  
  # find outliers
  findOutliers <- group_by(data, ID, Trial, Blocktype, Congruent) %>%
  summarise(meanOnsetTime=mean(firstTarSacc_relOnsetTime, na.rm=TRUE),
            sdOnsetTime=sd(firstTarSacc_relOnsetTime, na.rm=TRUE))
  findOutliers$exclude <- findOutliers$meanOnsetTime + excludeRTMaxSDs*findOutliers$sdOnsetTime
  findOutliers$excludeMin <- findOutliers$meanOnsetTime - excludeRTMaxSDs*findOutliers$sdOnsetTime
  data <- merge(data, findOutliers, by=c('ID', 'Trial','Blocktype','Congruent'), sort=FALSE)
  data$outlierMax <- data$exclude-data$firstTarSacc_relOnsetTime
  data$outlierMin <- data$excludeMin-data$firstTarSacc_relOnsetTime

  # remove outliers
    data <- filter(data, outlierMax>0 & outlierMin<0)
    
    return(data)
    
}

data_saccadeTime1 <- getSaccadeTime_Study1(gazeData_allCorr1)
data_saccadeTime1 <- getFactors_Study1(data_saccadeTime1)

# null model for saccade time
model0.1.7 <- lmer(firstTarSacc_relOnsetTime ~ 1 +
                   (1|ID),
                 data=data_saccadeTime1,
                 na.action=na.exclude)

varcom <- as.data.frame(VarCorr(model0.1.7))
L2var <- varcom$vcov[1]
L1var <- varcom$vcov[2]
icc0.1.7 <- round(L2var/(L2var+L1var), digits=2)


model4.1.1 <- lmer(firstTarSacc_relOnsetTime ~ Trial_Ctr*Blocktype*Congruent +
                     (1|ID),
                   data=data_saccadeTime1,
                   na.action=na.exclude)
results4.1.1 <- as.data.frame(coef(summary(model4.1.1)))
results4.1.1 <- getFormattedResults(results4.1.1)

```
**Quality Checks.** To determine whether the likelihood of fixating the target decreased over the course of the experiment, a model predicting target fixation probability from Block of the task was run. There was indeed a significant reduction in target fixation over the course of the experiment (*B* = `r results0.1.3$beta[2]`, *SE*=`r results0.1.3$se[2]`, *t*(`r results0.1.3$df[2]`)=`r results0.1.3$tval[2]` *p*=`r results0.1.3$pval[2]`). Next, we tested the relationship between target fixation probability and overall task performance, to determine whether high-performing participants used a more efficient covert attention strategy. The relationship between RT and target fixation probability did not reach significance, although it was in the negative direction (*B* = `r results0.1.4$beta[2]`, *SE*=`r results0.1.4$se[2]`, *t*(`r model0.1.4$df.residual`)=`r results0.1.4$tval[2]` *p*=`r results0.1.4$pval[2]`). There was additionally a marginally significant negative relationship between error rate and target fixation probability, indicating that participants who made fewer errors were more likely to fixate the target (*B* = `r results0.1.5$beta[2]`, *SE*=`r results0.1.5$se[2]`, *t*(`r model0.1.5$df.residual`)=`r results0.1.5$tval[2]` *p*=`r results0.1.5$pval[2]`). Taken together, these results suggest that although participants fixated the target less frequently later in the task, the tendency to fixate the target was, if anything, predictive of faster and more accurate performance, rather than poorer performance. 

**Distractor Fixation Probability.** The probability that participants fixated on the distractor prior to the target was used as an explicit index of distractibility. The null model had an ICC of `r icc0.1.6`, indicating the presence of between-subject variability in distractor fixation tendency. In the prediction model, Block Type was a significant predictor of distractor fixation probability (*B* = `r results3.1.1$beta[3]`, *SE*=`r results3.1.1$se[3]`, *t*(`r results3.1.1$df[3]`)=`r results3.1.1$tval[3]` *p*=`r results3.1.1$pval[3]`): participants were more likely to fixate on the distractor before the target on Perseveration-Inhibition blocks. There was additionally a marginally significant main effect of Trial (*B* = `r results3.1.1$beta[2]`, *SE*=`r results3.1.1$se[2]`, *t*(`r results3.1.1$df[2]`)=`r results3.1.1$tval[2]` *p*=`r results3.1.1$pval[2]`), showing a trend towards more distractor fixations on earlier trials in a set. No other main effects or interactions approached significance.

**Saccade Time.** The time that participants initiated their first saccade to the target can be interpreted as an index of hesitation. The null model had an ICC of `r icc0.1.7`. In the prediction model, both Block Type (*B* = `r results4.1.1$beta[3]`, *SE*=`r results4.1.1$se[3]`, *t*(`r results4.1.1$df[3]`)=`r results4.1.1$tval[3]` *p*=`r results4.1.1$pval[3]`) and Trial (*B* = `r results4.1.1$beta[2]`, *SE*=`r results4.1.1$se[2]`, *t*(`r results4.1.1$df[2]`)=`r results4.1.1$tval[2]` *p*=`r results4.1.1$pval[2]`) were significant predictors of the time at which participants initiated their first saccade towards the target. Thus, saccades were slower to begin on earlier trials of a set, and on Perseveration-Inhibition blocks.

## EBR Results (*N*=`r Nebr1`)
```{r Study 1 ebr results, include=FALSE}
# winsorize ebr

cleanData1_RT_EBR <- winsorizeEBR(cleanData1_RT, blinkInfo1)

centerEBR <- function(cleanData, blinkInfo) {
  cleanData$ebr_Ctr <- cleanData$ebr - blinkInfo$meanEBR
  return(cleanData)
}

cleanData1_RT_EBR <- centerEBR(cleanData1_RT_EBR, blinkInfo1)

# ebr RT analysis
model5.1.1 <- lmer(lnRT ~ Trial_Ctr*Blocktype*Congruent*ebr_Ctr + 
                 (1|ID),
               data=cleanData1_RT_EBR,
               na.action=na.exclude)
results5.1.1 <- as.data.frame(coef(summary(model5.1.1)))
results5.1.1 <- getFormattedResults(results5.1.1)


# ebr RT analysis with gender
cleanData1_RT_EBR_gen <- filter(cleanData1_RT_EBR, (gender %in% c('Male','Female')))

# test for difference in EBR between males and females 
# possibility - should I center or z-score by gender?
blinks <- unique(cleanData1_RT_EBR_gen[c('ID', 'ebr','gender')])
blinksByGender <- group_by(blinks, gender) %>%
  summarise(meanEBR=round(mean(ebr, na.rm=TRUE), digits=2),
            sdEBR=round(sd(ebr, na.rm=TRUE), digits=2))
gd <- t.test(blinks$ebr~blinks$gender)


model6.1.1 <- lmer(lnRT ~ Trial_Ctr*Blocktype*Congruent*ebr_Ctr*gender + 
                 (1|ID),
               data=cleanData1_RT_EBR_gen,
               na.action=na.exclude)
results6.1.1 <- as.data.frame(coef(summary(model6.1.1)))
results6.1.1 <- getFormattedResults(results6.1.1)

# are results same for males and females?
cleanData1_RT_EBR_genFem <- filter(cleanData1_RT_EBR_gen, gender=='Female')
cleanData1_RT_EBR_genMale <- filter(cleanData1_RT_EBR_gen, gender=='Male')

model6.1.1fem <- lmer(lnRT ~ Trial_Ctr*Blocktype*Congruent*ebr_Ctr + 
                 (1|ID),
               data=cleanData1_RT_EBR_genFem,
               na.action=na.exclude)
results6.1.1fem <- as.data.frame(coef(summary(model6.1.1fem)))
results6.1.1fem <- getFormattedResults(results6.1.1fem)

model6.1.1male <- lmer(lnRT ~ Trial_Ctr*Blocktype*Congruent*ebr_Ctr + 
                 (1|ID),
               data=cleanData1_RT_EBR_genMale,
               na.action=na.exclude)
results6.1.1male <- as.data.frame(coef(summary(model6.1.1male)))
results6.1.1male <- getFormattedResults(results6.1.1male)


# ebr error rate analysis
cleanData1_ER_EBR <- winsorizeEBR(cleanData1_ER, blinkInfo1)
summaryData1_ER_EBR <- getCleanSummary_Study1(cleanData1_ER_EBR)
summaryData1_ER_EBR <- centerEBR(summaryData1_ER_EBR, blinkInfo1)


model5.1.2 <- lmer(eRate ~ Trial_Ctr*Blocktype*Congruent*ebr_Ctr + 
                   (1|ID),
                 data=summaryData1_ER_EBR,
                 na.action=na.exclude)
results5.1.2 <- as.data.frame(coef(summary(model5.1.2)))
results5.1.2 <- getFormattedResults(results5.1.2)

# ebr error rate analysis with gender
genders <- unique(cleanData1_RT_EBR_gen[c('ID', 'gender')])
summaryData1_ER_EBR_gen <- merge(summaryData1_ER_EBR, genders, by='ID')
summaryData1_ER_EBR_gen <- filter(summaryData1_ER_EBR_gen, (gender %in% c('Male','Female')))

model6.1.2 <- lmer(eRate ~ Trial_Ctr*Blocktype*Congruent*ebr_Ctr*gender + 
                   (1|ID),
                 data=summaryData1_ER_EBR_gen,
                 na.action=na.exclude)
results6.1.2 <- as.data.frame(coef(summary(model6.1.2)))
results6.1.2 <- getFormattedResults(results6.1.2)

## EBR and distractor fixation probability
blinksToMerge <- unique(cleanData1_RT_EBR[c('ID', 'ebr_Ctr', 'gender')])
summaryData_distFix1_ebr <- merge(summaryData_distFix1, blinksToMerge, by='ID')
NebrGaze1 <- length(unique(summaryData_distFix1_ebr$ID[complete.cases(summaryData_distFix1_ebr)]))

model7.1.1 <- lmer(distFixProb ~ Trial_Ctr*Blocktype*Congruent*ebr_Ctr +
                     (1|ID),
                   data=summaryData_distFix1_ebr,
                   na.action=na.exclude)
results7.1.1 <- as.data.frame(coef(summary(model7.1.1)))
results7.1.1 <- getFormattedResults(results7.1.1)

model7.1.1a <- lmer(distFixProb ~ Trial_Ctr*Blocktype*ebr_Ctr +
                     (1|ID),
                   data=summaryData_distFix1_ebr,
                   na.action=na.exclude)
results7.1.1a <- as.data.frame(coef(summary(model7.1.1a)))
results7.1.1a <- getFormattedResults(results7.1.1a)


# with gender
summaryData_distFix1_ebr_gen <- filter(summaryData_distFix1_ebr, (gender %in% c('Male','Female')))

model8.1.1 <- lmer(distFixProb ~ Trial_Ctr*Blocktype*Congruent*ebr_Ctr*gender +
                     (1|ID),
                   data=summaryData_distFix1_ebr_gen,
                   na.action=na.exclude)
results8.1.1 <- as.data.frame(coef(summary(model8.1.1)))
results8.1.1 <- getFormattedResults(results8.1.1)

model8.1.1a <- lmer(distFixProb ~ Trial_Ctr*Blocktype*ebr_Ctr*gender +
                     (1|ID),
                   data=summaryData_distFix1_ebr_gen,
                   na.action=na.exclude)
results8.1.1a <- as.data.frame(coef(summary(model8.1.1a)))
results8.1.1a <- getFormattedResults(results8.1.1a)

## EBR and saccade time
data_saccadeTime1_ebr <- winsorizeEBR(data_saccadeTime1, blinkInfo1)
data_saccadeTime1_ebr <- centerEBR(data_saccadeTime1_ebr, blinkInfo1)

model9.1.1 <- lmer(firstTarSacc_relOnsetTime ~ Trial_Ctr*Blocktype*Congruent*ebr_Ctr +
                     (1|ID),
                   data=data_saccadeTime1_ebr,
                   na.action=na.exclude)
results9.1.1 <- as.data.frame(coef(summary(model9.1.1)))
results9.1.1 <- getFormattedResults(results9.1.1)

# with gender
data_saccadeTime1_ebr_gen <- filter(data_saccadeTime1_ebr, (gender %in% c('Male','Female')))

model10.1.1 <- lmer(firstTarSacc_relOnsetTime ~ Trial_Ctr*Blocktype*Congruent*ebr_Ctr*gender +
                     (1|ID),
                   data=data_saccadeTime1_ebr_gen,
                   na.action=na.exclude)
results10.1.1 <- as.data.frame(coef(summary(model10.1.1)))
results10.1.1 <- getFormattedResults(results10.1.1)

data_saccadeTime1_ebr$lnRT <- log(data_saccadeTime1_ebr$RT)
model11.1.1 <- lmer(lnRT ~ firstTarSacc_relOnsetTime +
                      (1|ID),
                    data=data_saccadeTime1_ebr,
                   na.action=na.exclude)
results11.1.1 <- as.data.frame(coef(summary(model11.1.1)))
results11.1.1 <- getFormattedResults(results11.1.1)


```

(ref:capModelc) Model estimates of reaction time (RT) as a function of EBR across different Block Types in Experiment 1. Error bars represent the 95% confidence interval (CI). The interaction between EBR and Block Type indicates that the RT cost of the Perseveration-Inhibition blocks is greater for subjects with higher EBR.

```{r figModelc, echo=FALSE, message=FALSE, out.width='100%', fig.cap='(ref:capModelc)'}

getFigDat_EBR_Study1 <- function(model) {
  
  figDat <- expand.grid(
    Trial_Ctr=c(-1.5,-0.5,0.5,1.5),
    Blocktype=c('Perseveration-Inhibition','Pure Updating'),
    Congruent=c('Congruent','Incongruent'),
    ebr_Ctr=c(-20,-10,0,10,20,30,40),
    lnRT=0
  )
  
  figDat$lnRT <- predict(model, figDat, re.form=NA) 
  fd <- model.matrix(terms(model), figDat)
  
  pvar1 <- diag(fd %*% tcrossprod(vcov(model),fd))
  tvar1 <- pvar1+VarCorr(model)$ID[1]
  cmult <- 1.96 ## could use 1.96
  
  figDat <- data.frame(
    figDat
    , plo = figDat$lnRT-cmult*sqrt(pvar1)
    , phi = figDat$lnRT+cmult*sqrt(pvar1)
    , tlo = figDat$lnRT-cmult*sqrt(tvar1)
    , thi = figDat$lnRT+cmult*sqrt(tvar1)
  )
  
  return(figDat)
}

figDat5.1.1 <- getFigDat_EBR_Study1(model5.1.1)

convertFigValues_EBR <- function(figDat) {
  e <- exp(1)
  figDat$RT <- e^figDat$lnRT
  figDat$ploRT <- e^figDat$plo
  figDat$phiRT <- e^figDat$phi
  figDat$tloRT <- e^figDat$tlo
  figDat$thiRT <- e^figDat$thi
  figDat$Trial <- figDat$Trial_Ctr + (mean(c(1:keepingTrials)))
  figDat$ebr <- figDat$ebr_Ctr + blinkInfo1$meanEBR
  
  return(figDat)
}

figDat5.1.1 <- convertFigValues_EBR(figDat5.1.1)
figDat5.1.1 <- group_by(figDat5.1.1, Blocktype, ebr) %>%
  summarise(meanRT=mean(RT, na.rm=TRUE),
            meanploRT=mean(ploRT, na.rm=TRUE),
            meanphiRT=mean(phiRT, na.rm=TRUE),
            meantloRT=mean(tloRT, na.rm=TRUE),
            meanthiRT=mean(thiRT, na.rm=TRUE))


p=ggplot(figDat5.1.1, aes(x=ebr, y=meanRT, linetype=Blocktype))+
  geom_line() +
  scale_linetype_discrete(name='Block Type') +
  labs(x='EBR (blinks/min)', y='RT (ms)')
p+theme_apa()+geom_pointrange(aes(ymin = meanploRT, ymax = meanphiRT))
```

**RT.** EBR was examined to determine the potential involvement of striatal DA in updating of WM representations across different contexts. There was no main effect of EBR on RT (*t*(`r results5.1.1$df[5]`)=`r results5.1.1$tval[5]` *p*=*n.s.*); however there was an interaction between EBR and Block Type (*B* = `r results5.1.1$beta[10]`, *SE*=`r results5.1.1$se[10]`, *t*(`r results5.1.1$df[10]`)=`r results5.1.1$tval[10]` *p*=`r results5.1.1$pval[10]`). As shown in Figure\ \@ref(fig:figModelc), higher EBR predicts a greater gap in RT between the slower Perseveration-Inhibition and the relatively faster Pure Updating blocks.  All other effects involving EBR did not reach significance.  

**RT with gender (*N*=`r Nebr1`).** Because the relationship between EBR and cognitive control is often modulated by gender [@JongkeesColzato_2016], we also examined whether the effects differed between males and females. In this sample, females (*M*=`r blinksByGender$meanEBR[1]`, *SD*=`r blinksByGender$sdEBR[1]`) had a significantly higher EBR than males (*M*=`r blinksByGender$meanEBR[2]`, *SD*=`r blinksByGender$sdEBR[2]`; *t*(`r round(gd$parameter, digits=2)`)=`r round(gd$statistic, digits=2)`, *p*=`r round(gd$p.value, digits=3)`). When gender was entered into the prediction model, the EBR by Block Type interaction still reached statistical significance (*B* = `r results6.1.1$beta[11]`, *SE*=`r results6.1.1$se[11]`, *t*(`r results6.1.1$df[11]`)=`r results6.1.1$tval[11]` *p*=`r results6.1.1$pval[11]`), and this effect was not modulated by gender, as evidenced by the lack of a 3-way interaction with gender (*t*(`r results6.1.1$df[25]`)=`r results6.1.1$tval[25]` *p*=*n.s.*). All other effects involving gender did not reach significance.

**Error Rate.** Similar to the RT model, there was no main effect of EBR on error rate (*t*(`r results5.1.2$df[5]`)=`r results5.1.2$tval[5]` *p*=*n.s.*), nor were there other noteworthy effects involving EBR. 

**Error Rate with Gender (*N*=`r Nebr1`).** The model with gender included indicated an interaction between gender and EBR (*B* = `r results6.1.2$beta[16]`, *SE*=`r results6.1.2$se[16]`, *t*(`r results6.1.2$df[16]`)=`r results6.1.2$tval[16]` *p*=`r results6.1.2$pval[16]`), such that higher EBR in males predicted fewer errors, whereas in females high EBR predicted more errors. 

(ref:capModeld) Model estimates of distractor fixation probability as a function of EBR across different Block Types and Trials of a block in Experiment 1. Error bars represent the 95% confidence interval (CI). The interaction between EBR, Block Type and Trial was marginally significant, and suggests although participants tended to make fewer distractor fixations over the course of a set, participants with low EBR did not show this improvement on Perseveration-Inhibition blocks.

```{r figModeld, echo=FALSE, message=FALSE, out.width='100%', fig.cap='(ref:capModeld)'}

getFigDat_EBR_df_Study1 <- function(model, blinkInfo) {
  ebrLow <- 0-blinkInfo$sdEBR
  ebrHigh <- blinkInfo$sdEBR
  
  figDat <- expand.grid(
    Trial_Ctr=c(-1.5,-0.5,0.5,1.5),
    Blocktype=c('Perseveration-Inhibition','Pure Updating'),
    Congruent=c('Congruent','Incongruent'),
    ebr_Ctr=c(ebrLow, 0, ebrHigh),
    distFixProb=0
  )
  
  figDat$distFixProb <- predict(model, figDat, re.form=NA) 
  fd <- model.matrix(terms(model), figDat)
  
  pvar1 <- diag(fd %*% tcrossprod(vcov(model),fd))
  tvar1 <- pvar1+VarCorr(model)$ID[1]
  cmult <- 1.96 ## could use 1.96
  
  figDat <- data.frame(
    figDat
    , plo = figDat$distFixProb-cmult*sqrt(pvar1)
    , phi = figDat$distFixProb+cmult*sqrt(pvar1)
    , tlo = figDat$distFixProb-cmult*sqrt(tvar1)
    , thi = figDat$distFixProb+cmult*sqrt(tvar1)
  )
  
  return(figDat)
}


figDat7.1.1 <- getFigDat_EBR_df_Study1(model7.1.1, blinkInfo1)

convertFigValues_EBR_df <- function(figDat) {
  figDat$Trial <- figDat$Trial_Ctr + (mean(c(1:keepingTrials)))
  figDat$ebr <- figDat$ebr_Ctr + blinkInfo1$meanEBR
  
  return(figDat)
}

figDat7.1.1 <- convertFigValues_EBR_df(figDat7.1.1)
figDat7.1.1$ebr <- as.factor(figDat7.1.1$ebr)
figDat7.1.1 <- group_by(figDat7.1.1, Blocktype, ebr, Trial) %>%
  summarise(meandf=mean(distFixProb, na.rm=TRUE),
            meanplo=mean(plo, na.rm=TRUE),
            meanphi=mean(phi, na.rm=TRUE),
            meantlo=mean(tlo, na.rm=TRUE),
            meanthi=mean(thi, na.rm=TRUE))

p=ggplot(figDat7.1.1, aes(x=Trial, y=meandf, linetype=ebr, shape=ebr))+
  geom_line() +
  geom_point() +
  facet_grid(.~Blocktype) +
  scale_linetype_discrete(name='EBR', labels=c('-1 SD','mean','+1 SD')) +
  scale_shape_discrete(name='EBR', labels=c('-1 SD','mean','+1 SD')) +
  labs(x='Trial', y='Distractor Fixation Probability (%)')
p+theme_apa()+geom_pointrange(aes(ymin = meanplo, ymax = meanphi))
```

**Distractor Fixation Probability (*N*=`r NebrGaze1`)** We next examined how EBR interacted with the eye tracking measures. In both models predicting distractor fixation probability, the interaction between EBR, Trial, and Block Type approached significance (without gender: *B* = `r results7.1.1$beta[13]`, *SE*=`r results7.1.1$se[13]`, *t*(`r results7.1.1$df[13]`)=`r results7.1.1$tval[13]` *p*=`r results7.1.1$pval[13]` with gender: *B* = `r results8.1.1$beta[18]`, *SE*=`r results7.1.1$se[18]`, *t*(`r results8.1.1$df[18]`)=`r results8.1.1$tval[18]` *p*=`r results8.1.1$pval[18]`). As shown in Figure\ \@ref(fig:figModeld), participants with low EBR had, if anything, a numerically greater tendency to fixate on the distractor in both conditions. However, these EBR-linked differences emerged early in a set for Pure Updating blocks and late in a set for Perseveration-Inhibition blocks. There were no other EBR-linked predictors of distractor fixation probability in the full model.  

Given that in the RT analyses, EBR interacted with Block Type, we additionally ran post-hoc models examining the effects of only Block Type, Trial, and EBR on distractor fixation probability (i.e. collapsing across Congruent and Incongruent trials to increase statistical power), in order to determine whether the tendency to fixate on a distractor stimulus might underlie the results. However, no effects of note reached significance in these models.

(ref:capModele) Model estimates of onset time of participants' first saccade to the target as a function of EBR, Block Type, Congruence, and Trial in Experiment 1. Error bars represent the 95% confidence interval (CI). EBR interacted with Block Type: participants with higher EBR made faster saccades to the target on Pure Updating blocks. 

```{r figModele, echo=FALSE, message=FALSE, out.width='100%', fig.cap='(ref:capModele)'}

getFigDat_EBR_st_Study1 <- function(model, blinkInfo) {
  ebrLow <- 0-blinkInfo$sdEBR
  ebrHigh <- blinkInfo$sdEBR
  
  figDat <- expand.grid(
    Trial_Ctr=c(-1.5,-0.5,0.5,1.5),
    Blocktype=c('Perseveration-Inhibition','Pure Updating'),
    Congruent=c('Congruent','Incongruent'),
    ebr_Ctr=c(ebrLow, 0, ebrHigh),
    firstTarSacc_relOnsetTime=0
  )
  
  figDat$firstTarSacc_relOnsetTime <- predict(model, figDat, re.form=NA) 
  fd <- model.matrix(terms(model), figDat)
  
  pvar1 <- diag(fd %*% tcrossprod(vcov(model),fd))
  tvar1 <- pvar1+VarCorr(model)$ID[1]
  cmult <- 1.96 ## could use 1.96
  
  figDat <- data.frame(
    figDat
    , plo = figDat$firstTarSacc_relOnsetTime-cmult*sqrt(pvar1)
    , phi = figDat$firstTarSacc_relOnsetTime+cmult*sqrt(pvar1)
    , tlo = figDat$firstTarSacc_relOnsetTime-cmult*sqrt(tvar1)
    , thi = figDat$firstTarSacc_relOnsetTime+cmult*sqrt(tvar1)
  )
  
  return(figDat)
}


figDat9.1.1 <- getFigDat_EBR_st_Study1(model9.1.1, blinkInfo1)

figDat9.1.1 <- convertFigValues_EBR_df(figDat9.1.1)
figDat9.1.1$ebr <- as.factor(figDat9.1.1$ebr)
figDat9.1.1 <- group_by(figDat9.1.1, Blocktype, ebr, Trial, Congruent) %>%
  summarise(meanst=mean(firstTarSacc_relOnsetTime, na.rm=TRUE),
            meanplo=mean(plo, na.rm=TRUE),
            meanphi=mean(phi, na.rm=TRUE),
            meantlo=mean(tlo, na.rm=TRUE),
            meanthi=mean(thi, na.rm=TRUE))

p=ggplot(figDat9.1.1, aes(x=Trial, y=meanst, linetype=ebr, shape=ebr))+
  geom_line() +
  geom_point() +
  facet_grid(Congruent~Blocktype) +
  scale_linetype_discrete(name='EBR', labels=c('-1 SD','mean','+1 SD')) +
  scale_shape_discrete(name='EBR', labels=c('-1 SD','mean','+1 SD')) +
  labs(x='Trial', y='Saccade Time (ms)')
p+theme_apa()+geom_pointrange(aes(ymin = meanplo, ymax = meanphi))


```

**Saccade Time (*N*=`r NebrGaze1`)** In both models predicting the time of participants' first saccade to the target, there was a significant interaction between EBR and Block Type (without gender: *B* = `r results9.1.1$beta[10]`, *SE*=`r results9.1.1$se[10]`, *t*(`r results9.1.1$df[10]`)=`r results9.1.1$tval[10]` *p*=`r results9.1.1$pval[10]` with gender: *B* = `r results10.1.1$beta[11]`, *SE*=`r results10.1.1$se[11]`, *t*(`r results10.1.1$df[11]`)=`r results10.1.1$tval[11]` *p*=`r results10.1.1$pval[11]`). Here, higher EBR predicted faster saccades to the target on Pure Updating blocks, whereas EBR-linked differences were smaller on Perseveration-Inhibition blocks (Figure\ \@ref(fig:figModele)). There was additionally a marginally significant interaction between EBR and Congruence (without gender: *B* = `r results9.1.1$beta[11]`, *SE*=`r results9.1.1$se[11]`, *t*(`r results9.1.1$df[11]`)=`r results9.1.1$tval[11]` *p*=`r results9.1.1$pval[11]` with gender: *B* = `r results10.1.1$beta[12]`, *SE*=`r results10.1.1$se[12]`, *t*(`r results10.1.1$df[12]`)=`r results10.1.1$tval[12]` *p*=`r results10.1.1$pval[12]`), suggesting that higher EBR predicted later saccades to the target to a greater extent on Incongruent trials. No other EBR-linked effects approached significance.

# Discussion  
The results of this experiment provide further evidence of a divergence between updating in which a previous attentional set can interfere with performance, and updating in which both target and distractor are novel [@RogersMonsell_1995]. In the Pure Updating condition, RTs declined more quickly over the course of each set compared to the Perseveration-Inhibition condition. Incongruence costs in error rate also indicate that participants were more susceptible to attending the distractor on Perseveration-Inhibition blocks. Interestingly, this latter effect did not interact with Trial, suggesting that participants were susceptible to this distraction throughout a set in Perseveration-Inhibition blocks, rather than only immediately following a switch. Taken together, these behavioral findings suggest that in our task, interference from a previous attentional set (either via perseveration on the previously-relevant target or the need to overcome backwards inhibition of what was previously the distractor) slows the process of implementing a new attentional set, underscoring the importance of disengagement from a no-longer-relevant attentional set for effective cognitive control [@ShipsteadEtAl_2016].    

Eye gaze indices indicated that participants were more likely to first fixate on the distractor, and slower to make a saccade to the target on Perseveration-Inhibition blocks. On trials more closely following a Switch, participants were also more hesitant and marginally more likely to attend the distractor. These findings corroborate the main effects of the behavioral data; however it is worth noting that, unlike in the behavioral data, there was no interaction between Trial and Block Type in either eye gaze index.

The relationship between EBR and task performance also varied as a function of Block Type. Here, higher EBR predicted slower responding on Perseveration-Inhibition blocks relative to Pure Updating blocks. Interestingly, this EBR-RT relationship on Perseveration-Inhibition blocks cannot be explained by distractor fixation tendency, which was not greater for participants with high EBR; however it may be related to saccade time, which was also slower on Perseveration-Inhibition blocks for participants with high EBR. This finding is unsurprising given that saccade time is correlated with RT (*r*=.37, *p*<.001); however it may suggest that the behavioral effects of EBR on WM updating are mediated via hesitation, rather than by overt fixations on distractors.

A key limitation of this experiment is that all color cues instructed participants to switch. Thus, it is not possible to determine whether the observed effects of Trial are related to the process of updating one's attentional set, or rather to the process of reading a cue. In all following experiments, half of cues were be Non-Switch cues, in order to disentangle this alternative explanations for our findings. An additional limitation is that the EBR measurement was quite brief (2 minutes), whereas a longer interval is typically advised for EBR data collection [@JongkeesColzato_2016]. Although there is some evidence that EBR recorded early in an interval closely corresponds with EBR later in an interval [e.g., @DangEtAl_2017], a longer recording interval is likely to be more reliable [@JongkeesColzato_2016]. This limitation is addressed later, in Experiment 4.



# Experiment 2
The main goal of Experiment 2 was to address a limitation of Experiment 1 by including Non-Switch cues, which will determine whether observed differences between Perseveration-Inhibition and Pure Upating conditions can be attributed to WM updating processes. This experiment did not have sufficient statistical power to examine between-subjects EBR effects, so only behavioral and eye tracking results are examined here.

# Method
```{r pull info for method of Study 2, include=FALSE}
# Excluded Subjects - have been removed prior to data processing
# couldn't track eye: 607, 609, 613, 614 (these are included in behavioral analyses)
# failure to follow instructions: 617


# demographic info
demog2 <- getDemographicInfo(allData2)

# get error/trial removal info
getOmittedInfo <- function(data){
  omittedInfo <- list()
  #detach(package:plyr)
  # subjects excluded by errors
  errors <- dplyr::group_by(data, ID) %>%
    summarise(errorRate=mean(Error, na.rm=TRUE))
  omittedInfo$meanErrors <- mean(errors$errorRate, na.rm=TRUE)
  omittedInfo$sdErrors <- sd(errors$errorRate, na.rm=TRUE)
  omittedInfo$maxErrors <- omittedInfo$meanErrors + omittedInfo$sdErrors*3
  tooManyErrors <- filter(errors, errorRate>omittedInfo$maxErrors)
  omittedInfo$numExclErrors <- length(unique(tooManyErrors$ID))
  omittedInfo$tooManyErrors <- unique(tooManyErrors$ID)
  
  # trials excluded from RT analyses
  data$lnRT <- log(data$RT)
  dataTrialsOfInterest <- data[!(data$Trial==1 & data$Set==1),]
  dataTrialsOfInterest <- filter(dataTrialsOfInterest, Trial>4)
  findOutliers <- group_by(dataTrialsOfInterest, ID, Trial, Congruent, Blocktype, switchSet) %>%
    summarise(meanlnRT=mean(lnRT, na.rm=TRUE),
              sdlnRT=sd(lnRT, na.rm=TRUE))
  findOutliers$exclude <- findOutliers$meanlnRT + excludeRTMaxSDs*findOutliers$sdlnRT
  findOutliers$excludeMin <- findOutliers$meanlnRT - excludeRTMaxSDs*findOutliers$sdlnRT
  dataTrialsOfInterest <- merge(dataTrialsOfInterest, findOutliers, 
                                by=c('ID', 'Trial','Congruent','Blocktype','switchSet'), sort=FALSE)
  dataTrialsOfInterest$outlierMax <- dataTrialsOfInterest$exclude-dataTrialsOfInterest$lnRT
  dataTrialsOfInterest$outlierMin <- dataTrialsOfInterest$excludeMin-dataTrialsOfInterest$lnRT
  
  cleanData <- filter(dataTrialsOfInterest, RT>=excludeRTMin & RT<=excludeRTMax & outlierMax>0 & outlierMin<0)
  omittedInfo$removedTrials <- 1-(nrow(cleanData)/nrow(dataTrialsOfInterest))
  
  return(omittedInfo)
}

omittedInfo2 <- getOmittedInfo(allData2)

blinkInfo2 <- getBlinkInfo(allData2)

gazeInfo2 <- getGazeInfo(allData2)

# Remove subjects with too many errors
allData2 <- filter(allData2, !(ID %in% omittedInfo2$tooManyErrors))
# get N for behavioral results
Nbeh2 <- length(unique(allData2$ID))
Ngaze2 <- Nbeh2 - length(gazeInfo2$excludeTarPct)
```

## Participants
Thirty-seven students at the University of Oregon participated in this experiment for partial course credit. Eligibility criteria were the same as for Experiment 1. One participant was excluded prior to data processing because of failure to follow task instructions. The remaining participants included `r demog2$numFemales` females and `r demog2$numMales` males, and had a mean age of `r demog2$meanAge` (*SD*=`r demog2$sdAge`).

## Procedure
The procedure was very similar to that of Experiment 1. After providing informed consent, participants completed a brief questionnaire about demographic information, caffeine use, and previous night's sleep. They then completed an EBR baseline period, followed by the attention shifting task, and ending with an additional baseline recording. The eyetracker was calibrated after every 2 blocks, and participants were given the option to take a break at these points. The experiment lasted approximately 2 hours.

## Materials and Apparatus
**Attention Shifting Task.** The experimental task was identical to the task used in Experiment 1 with two exceptions. First, Non-Switch cues were included, so that half of sets began with a color word that was the same as the previous set (Non-Switch Sets) and the other half began with a color word that was different (Switch Sets). Each block still contained 12 sets of 4-6 trials. In order to maintain a sufficient number of trials per condition, the number of blocks was doubled so that there were 6 of each Perseveration-Inhibition and Pure Updating blocks, for a total of approximately 780 trials.  

Additionally, the duration of the stimulus array was standardized, so that it remained on the screen for 1000 ms, regardless of participant RT. Participant responses were still recorded up to 1500 ms after stimulus offset.  

**EBR Baseline.** The duration of EBR baseline recordng was increased to 5 minutes; however, because this experiment was not sufficiently-powered to detect EBR effects, these data are not analyzed here.  

**Apparatus.** Apparatus were the same as for Experiment 1, except that the eyetracking was carried out with an Eyelink DM-890 eyetracker running Eyelink 1000 Plus software (Version 5.01).

## Data analysis
Behavioral and eyetracking data were processed in the same manner as for Experiment 1. Overall, participants had a mean error rate of `r omittedInfo2$meanErrors*100`% (*SD* = `r omittedInfo2$sdErrors*100`%). Prior to data analysis, `r omittedInfo2$numExclErrors` participant was excluded for having an error rate greater than `r excludeMaxErrorRateSDs` standard deviations from the group mean, leaving a sample of `r Nbeh2`. For RT analyses, `r omittedInfo2$removedTrials*100`% of trials were removed as outliers.  

Prior to eye tracking analyses, `r length(blinkInfo2$numExcluded)` participant was excluded because of eyetracking difficulties. An additional `r length(gazeInfo2$excludeTarPct) - length(blinkInfo2$numExcluded)` participants who fixated on the target on fewer than `r targetHitThresh*100`% of trials were also excluded from eye tracking analyses.

Similar to Experiment 1, statistical analyses were carried out using LMMs. To account for the addition of Non-Switch cues, the task was modeled with 4 factors, with a 2 (Cue: Cued vs. Non-Cued) by 2 (Set Type: Switch Set vs. Non-Switch Set) by 2 (Congruence: Congruent vs. Incongruent) by 2 (Block Type: Perseveration-Inhibition vs. Pure Updating) design.

# Results
## Behavioral Results (*N*=`r Nbeh2`)
```{r Study 2 behavioral results, include=FALSE}
# remove trials excluded from RT analyes
getCleanDataRT <- function(allData) {
  # remove trials excluded from RT analyses
  cleanDataRT <- filter(allData, Error==0, Blocktype>2, Trial<5, !(Trial==1 & Set==1))
  
  # log transform RTs and find outliers
cleanDataRT$lnRT <- log(cleanDataRT$RT)
findOutliers <- group_by(cleanDataRT, ID, Trial, Blocktype, Congruent, switchSet) %>%
  summarise(meanlnRT=mean(lnRT, na.rm=TRUE),
            sdlnRT=sd(lnRT, na.rm=TRUE))
findOutliers$exclude <- findOutliers$meanlnRT + excludeRTMaxSDs*findOutliers$sdlnRT
findOutliers$excludeMin <- findOutliers$meanlnRT - excludeRTMaxSDs*findOutliers$sdlnRT
cleanDataRT <- merge(cleanDataRT, findOutliers, by=c('ID', 'Trial','Blocktype','Congruent','switchSet'), sort=FALSE)
cleanDataRT$outlierMax <- cleanDataRT$exclude-cleanDataRT$lnRT
cleanDataRT$outlierMin <- cleanDataRT$excludeMin-cleanDataRT$lnRT

# remove outliers
cleanDataRT <- filter(cleanDataRT, 
                                    RT>=excludeRTMin & RT<=excludeRTMax & outlierMax>0 & outlierMin<0)

}

cleanData2_RT <- getCleanDataRT(allData2)

# create factors and center continuous variables
getFactors <- function(cleanData){
  cleanData$Congruent <- factor(cleanData$Congruent,
                              levels=c(1,2),
                              labels=c('Congruent','Incongruent'))
  cleanData$Blocktype <- factor(cleanData$Blocktype,
                              levels=c(3,4),
                              labels=c('Pure Updating','Perseveration-Inhibition'))
  cleanData$switchSet <- factor(cleanData$switchSet,
                              levels=c(0,1),
                              labels=c('Non-Switch Set','Switch Set'))
  cleanData$ID <- factor(cleanData$ID)
  
  
  trials <- unique(cleanData$Trial)
  meanTrial <- mean(trials)
  cleanData$Trial_Ctr <- cleanData$Trial - meanTrial
  
  return(cleanData)
}

cleanData2_RT <-getFactors(cleanData2_RT)

# legend for naming models:
# first number - number of analysis in experiment
# second number - experiment
# third number - error rate vs. RT as DV (1 for RT, 2 for error rate)

# test null model and compute ICC for RTs:
model0.2.1 <- lmer(lnRT ~ 1 +
                 (1|ID),
               data=cleanData2_RT,
               na.action=na.exclude)

varcom <- as.data.frame(VarCorr(model0.2.1))
L2var <- varcom$vcov[1]
L1var <- varcom$vcov[2]
icc0.2.1 <- round((L2var/(L2var+L1var)), digits=2)

# RT model with predictors:
model1.2.1 <- lmer(lnRT ~ Trial_Ctr*Blocktype*switchSet*Congruent +
                     (1|ID),
                   data=cleanData2_RT,
                   na.action=na.exclude)

results1.2.1 <- as.data.frame(coef(summary(model1.2.1)))
results1.2.1 <- getFormattedResults(results1.2.1)

# Error Rate Analyses
getCleanDataER <- function(allData) {
  # remove trials excluded from RT analyses
  cleanDataER <- filter(allData, Blocktype>2, Trial<5, !(Trial==1 & Set==1))
}

cleanData2_ER <- getCleanDataER(allData2)
cleanData2_ER <- getFactors(cleanData2_ER)


getCleanSummary <- function(cleanData){
  # find mean error rate for each condition
  summaryData <- group_by(cleanData, ID, Trial_Ctr, Blocktype, Congruent, switchSet) %>%
    summarise(eRate = 100*(mean(Error, na.rm=TRUE)),
              ebr=(mean(ebr, na.rm=TRUE)))
  
  # winsorize summarized data
  meanErate <- mean(summaryData$eRate)
  sdErate <- sd(summaryData$eRate)
  maxErate <- meanErate + winsorizeErrorsSD*sdErate
  findNextLargestErate <- filter(summaryData, eRate<maxErate)
  maxValueErate <- max(findNextLargestErate$eRate)
  summaryDataClean <- summaryData
  summaryDataClean$eRate[summaryDataClean$eRate>maxErate] <- maxValueErate

  return(summaryDataClean)
  
}
summaryData2_ER <- getCleanSummary(cleanData2_ER)

# null model for error rate
model0.2.2 <- lmer(eRate ~ 1 +
                   (1|ID),
                 data=summaryData2_ER,
                 na.action=na.exclude)

varcom <- as.data.frame(VarCorr(model0.2.2))
L2var <- varcom$vcov[1]
L1var <- varcom$vcov[2]
icc0.2.2 <- L2var/(L2var+L1var)

# prediction model for error rate
model1.2.2 <- lmer(eRate ~ Trial_Ctr*Blocktype*switchSet*Congruent + 
                   (1|ID),
                 data=summaryData2_ER,
                 na.action=na.exclude)

results1.2.2 <- as.data.frame(coef(summary(model1.2.2)))
results1.2.2 <- getFormattedResults(results1.2.2)

```

(ref:capModelf) Model estimates of reaction time (RT) across conditions of the attention shifting task in Experiment 2. Error bars represent the 95% confidence interval (CI). There was a significant interaction between Block Type, Set Type, and Trial, indicating that on Switch Sets, RTs were slower to asymptote on Perseveration-Inhibition blocks compared to Pure Updating blocks.

```{r figModelf, echo=FALSE, message=FALSE, out.width='100%', fig.cap='(ref:capModelf)'}

getFigDat_RT <- function(model) {
  
  figDat <- expand.grid(
    Trial_Ctr=c(-1.5,-0.5,0.5,1.5),
    Blocktype=c('Perseveration-Inhibition','Pure Updating'),
    Congruent=c('Congruent','Incongruent'),
    switchSet=c('Switch Set','Non-Switch Set'),
    lnRT=0
  )
  
  figDat$lnRT <- predict(model, figDat, re.form=NA) 
  fd <- model.matrix(terms(model), figDat)
  
  pvar1 <- diag(fd %*% tcrossprod(vcov(model),fd))
  tvar1 <- pvar1+VarCorr(model)$ID[1]
  cmult <- 1.96 ## could use 1.96
  
  figDat <- data.frame(
    figDat
    , plo = figDat$lnRT-cmult*sqrt(pvar1)
    , phi = figDat$lnRT+cmult*sqrt(pvar1)
    , tlo = figDat$lnRT-cmult*sqrt(tvar1)
    , thi = figDat$lnRT+cmult*sqrt(tvar1)
  )
  
  return(figDat)
}

figDat1.2.1 <- getFigDat_RT(model1.2.1)
figDat1.2.1 <- convertFigValues_RT(figDat1.2.1)

p=ggplot(figDat1.2.1, aes(x=Trial, y=RT, shape=switchSet))+
  geom_line(aes(x=Trial, y=RT, linetype=switchSet)) +
  facet_grid(Congruent~Blocktype) +
  scale_linetype_discrete(name='Set Type') +
  scale_shape_discrete(name='Set Type') +
  labs(x='Trial', y='RT (ms)')
p+theme_apa()+geom_pointrange(aes(ymin = ploRT, ymax = phiRT))
```
**RT.** As for Experiment 1, RT data were analyzed using mixed models with trials nested within subjects. The null model had an ICC of `r icc0.2.1`.  
  
The prediction model indicated main effects of Trial (*B* = `r results1.2.1$beta[2]`, *SE*=`r results1.2.1$se[2]`, *t*(`r results1.2.1$df[2]`)=`r results1.2.1$tval[2]` *p*=`r results1.2.1$pval[2]`) and Block Type (*B* = `r results1.2.1$beta[3]`, *SE*=`r results1.2.1$se[3]`, *t*(`r results1.2.1$df[3]`)=`r results1.2.1$tval[3]` *p*=`r results1.2.1$pval[3]`) - similar to Experiment 1, RTs were slower on earlier trials and Perseveration-Inhibition blocks. There was additionally a significant main effect of Set Type (*B* = `r results1.2.1$beta[4]`, *SE*=`r results1.2.1$se[4]`, *t*(`r results1.2.1$df[4]`)=`r results1.2.1$tval[4]` *p*=`r results1.2.1$pval[4]`), which indicated, that participants responded more slowly when they had recently switched their attentional set. The main effect of distractor Congruence also reached significance in this experiment (*B* = `r results1.2.1$beta[5]`, *SE*=`r results1.2.1$se[5]`, *t*(`r results1.2.1$df[5]`)=`r results1.2.1$tval[5]` *p*=`r results1.2.1$pval[5]`), in contrast to Experiment 1.  
  
As expected, there was an interaction between Trial and Set Type (*B* = `r results1.2.1$beta[7]`, *SE*=`r results1.2.1$se[7]`, *t*(`r results1.2.1$df[7]`)=`r results1.2.1$tval[7]` *p*=`r results1.2.1$pval[7]`), which reflects a switch cost: RTs were slower on earlier trials of Switch Sets. Critically, the 3-way interaction between Trial, Set Type, and Block Type was also significant (*B* = `r results1.2.1$beta[12]`, *SE*=`r results1.2.1$se[12]`, *t*(`r results1.2.1$df[12]`)=`r results1.2.1$tval[12]` *p*=`r results1.2.1$pval[12]`). As in Experiment 1, RTs in Pure Updating blocks decline sharply over the course of Sets in which participants have recently switched, compared to Perseveration-Inhibition blocks (see Figure\ \@ref(fig:figModelf). Interestingly, here we also observe that RTs immediately following a switch are initially higher on Pure Updating blocks compared to Perseveration-Inhibition blocks. Critically, this pattern was observed only on Switch Sets, indicating that it is driven by switching, rather than seeing the colour cue.
  
(ref:capModelg) Model estimates of error rate across conditions of the attention shifting task in Experiment 2. Error bars represent the 95% confidence interval (CI). There was a significant interaction between Block Type, Set Type, and Congruence, such that participants made more errors on Incongruent trials of Perseveration-Inhibition blocks, on Sets in which the target color has recently switched.

```{r figModelg, echo=FALSE, message=FALSE, out.width='100%', fig.cap='(ref:capModelg)'}

getFigDat_ER <- function(model) {
  
  figDat <- expand.grid(
    Trial_Ctr=c(-1.5,-0.5,0.5,1.5),
    Blocktype=c('Perseveration-Inhibition','Pure Updating'),
    Congruent=c('Congruent','Incongruent'),
    switchSet=c('Switch Set','Non-Switch Set'),
    eRate=0
  )
  
  figDat$eRate <- predict(model, figDat, re.form=NA) 
  fd <- model.matrix(terms(model), figDat)
  
  pvar1 <- diag(fd %*% tcrossprod(vcov(model),fd))
  tvar1 <- pvar1+VarCorr(model)$ID[1]
  cmult <- 1.96 ## could use 1.96
  
  figDat <- data.frame(
    figDat
    , plo = figDat$eRate-cmult*sqrt(pvar1)
    , phi = figDat$eRate+cmult*sqrt(pvar1)
    , tlo = figDat$eRate-cmult*sqrt(tvar1)
    , thi = figDat$eRate+cmult*sqrt(tvar1)
  )
  
  return(figDat)
}

figDat1.2.2 <- getFigDat_ER(model1.2.2)

figDat1.2.2 <- convertFigValues_ER(figDat1.2.2)

p=ggplot(figDat1.2.2, aes(x=Trial, y=eRate, shape=Congruent))+
  geom_line(aes(x=Trial, y=eRate, linetype=Congruent)) +
  facet_grid(switchSet~Blocktype) +
  scale_linetype_discrete(name='Congruence') +
  scale_shape_discrete(name='Congruence') +
  labs(x='Trial', y='Error Rate (%)')
p+theme_apa()+geom_pointrange(aes(ymin = plo, ymax = phi))

```

**Error Rate** The null model for error rate had an ICC of `r icc0.2.2`. As in Experiment 1, there was a main effect of Congruence (*B* = `r results1.2.2$beta[5]`, *SE*=`r results1.2.2$se[5]`, *t*(`r results1.2.2$df[5]`)=`r results1.2.2$tval[5]` *p*=`r results1.2.2$pval[5]`), with participants making more errors on Incongruent trials. The main effect of Set Type also reached significance (*B* = `r results1.2.2$beta[4]`, *SE*=`r results1.2.2$se[4]`, *t*(`r results1.2.2$df[4]`)=`r results1.2.2$tval[4]` *p*=`r results1.2.2$pval[4]`), as participants made more errors on Switch Sets. There was additionally a switch cost in error rate, as indexed by the significant interaction between Trial and Switch Set (*B* = `r results1.2.2$beta[7]`, *SE*=`r results1.2.2$se[7]`, *t*(`r results1.2.2$df[7]`)=`r results1.2.2$tval[7]` *p*=`r results1.2.2$pval[7]`).  

There were also several noteworthy high-level interactions in the model. First, the interaction between Block Type, Set Type, and Congruence (*B* = `r results1.2.2$beta[15]`, *SE*=`r results1.2.2$se[15]`, *t*(`r results1.2.2$df[15]`)=`r results1.2.2$tval[15]` *p*=`r results1.2.2$pval[15]`) reached significance (Figure \@ref(fig:figModelg)). This result is analogous to the findings of Experiment 1. In particular, participants made more errors on Incongruent trials on Perseveration-Inhibition blocks compared to Pure Updating blocks, and this relationship was observable only on Switch Sets. The interaction between Trial, Block Type and Set Type also reached significance (*B* = `r results1.2.2$beta[12]`, *SE*=`r results1.2.2$se[12]`, *t*(`r results1.2.2$df[12]`)=`r results1.2.2$tval[12]` *p*=`r results1.2.2$pval[12]`). Although this finding is not consistent with Experiment 1, it does correspond to the RT finding that performance improves more sharply over the course of Switch Sets in Pure Updating blocks compared to Perseveration-Inhibition blocks, in this case indicated by a declining error rate. Finally, the 3-way interaction between Trial, Set Type and Block Type was significant (*B* = `r results1.2.2$beta[14]`, *SE*=`r results1.2.2$se[14]`, *t*(`r results1.2.2$df[14]`)=`r results1.2.2$tval[14]` *p*=`r results1.2.2$pval[14]`). Here, Switch Set error rates declined more sharply on Congruent, compared to Incongruent trials. 

## Eye Tracking Results  
```{r Study 2 eyetracking results, include=FALSE}

gazeData_allCorr2 <- getCleanDataGaze_allCorrect(allData2, gazeInfo2, blinkInfo2)
gazeData_errors2 <- getCleanDataGaze_withErrors(allData2, gazeInfo2, blinkInfo2)

# quality check - does % of target fixations decrease over the course of the experiment?
summaryDataByBlock2 <- aggByBlock(gazeData_allCorr2)

model0.2.3 <- lmer(meanTarPct ~ Block_Ctr +
                     (1|ID),
                   data=summaryDataByBlock2,
                   na.action=na.exclude)
results0.2.3 <- as.data.frame(coef(summary(model0.2.3)))
results0.2.3 <- getFormattedResults(results0.2.3)

# quality check - does % of target fixations relate to performance (RT/Errors)?
summaryDataBySub2 <- aggBySub_RT(gazeData_allCorr2)

model0.2.4 <- lm(meanTarPct ~ meanlnRT,
                 data=summaryDataBySub2,
                 na.action=na.exclude)

results0.2.4 <- as.data.frame(coef(summary(model0.2.4)))
results0.2.4 <- getFormattedResults_lm(results0.2.4)

summaryDataBySub2_errors <- aggBySub_errors(gazeData_errors2)

model0.2.5 <- lm(meanTarPct ~ eRate,
                 data=summaryDataBySub2_errors,
                 na.action=na.exclude)
results0.2.5 <- as.data.frame(coef(summary(model0.2.5)))
results0.2.5 <- getFormattedResults_lm(results0.2.5)


# Distractor Fixation Probability
getDistFixProb <- function(data){
  
  data$distFirst <- 0
  data$copyTarFixOnset <- data$firstTarFix_relOnsetTime
  data$copyDistFixOnset <- data$firstDistFix_relOnsetTime
  data$copyTarFixOnset[is.na(data$copyTarFixOnset)] <- 99999
  data$copyDistFixOnset[is.na(data$copyDistFixOnset)] <- 99999
  data$distFirst[data$copyDistFixOnset<data$copyTarFixOnset] <- 1
  
  summaryData <- group_by(data, ID, Trial, Blocktype, Congruent, switchSet) %>%
      summarise(distFixProb = 100*(mean(distFirst, na.rm=TRUE)))
  
  # winsorize summarized data
  meanDistFix <- mean(summaryData$distFixProb)
  sdDistFix <- sd(summaryData$distFixProb)
  maxDistFix <- meanDistFix + winsorizeErrorsSD*sdDistFix
  findNextLargestDistFix <- filter(summaryData, distFixProb<maxDistFix)
  maxValueDistFix <- max(findNextLargestDistFix$distFixProb)
  summaryData$distFixProb[summaryData$distFixProb>maxDistFix] <- maxValueDistFix
  
  return(summaryData)
}

summaryData_distFix2 <- getDistFixProb(gazeData_errors2)
summaryData_distFix2 <- getFactors(summaryData_distFix2)

# null model for distractor fixation probability
model0.2.6 <- lmer(distFixProb ~ 1 +
                   (1|ID),
                 data=summaryData_distFix2,
                 na.action=na.exclude)

varcom <- as.data.frame(VarCorr(model0.2.6))
L2var <- varcom$vcov[1]
L1var <- varcom$vcov[2]
icc0.2.6 <- round(L2var/(L2var+L1var), digits=2)

model3.2.1 <- lmer(distFixProb ~ Trial_Ctr*Blocktype*switchSet*Congruent +
                     (1|ID),
                   data=summaryData_distFix2,
                   na.action=na.exclude)
results3.2.1 <- as.data.frame(coef(summary(model3.2.1)))
results3.2.1 <- getFormattedResults(results3.2.1)

# Saccade Time
getSaccadeTime <- function(data){
  
  data$distFirst <- 0
  data$copyTarFixOnset <- data$firstTarFix_relOnsetTime
  data$copyDistFixOnset <- data$firstDistFix_relOnsetTime
  data$copyTarFixOnset[is.na(data$copyTarFixOnset)] <- 99999
  data$copyDistFixOnset[is.na(data$copyDistFixOnset)] <- 99999
  data$distFirst[data$copyDistFixOnset<data$copyTarFixOnset] <- 1
  
  data <- filter(data, firstTarSacc_tar==1, distFirst==0, firstTarSacc_relOnsetTime<excludeRTMax)
  
  # find outliers
  findOutliers <- group_by(data, ID, Trial, Blocktype, Congruent, switchSet) %>%
  summarise(meanOnsetTime=mean(firstTarSacc_relOnsetTime, na.rm=TRUE),
            sdOnsetTime=sd(firstTarSacc_relOnsetTime, na.rm=TRUE))
  findOutliers$exclude <- findOutliers$meanOnsetTime + excludeRTMaxSDs*findOutliers$sdOnsetTime
  findOutliers$excludeMin <- findOutliers$meanOnsetTime - excludeRTMaxSDs*findOutliers$sdOnsetTime
  data <- merge(data, findOutliers, by=c('ID', 'Trial','Blocktype','Congruent', 'switchSet'), sort=FALSE)
  data$outlierMax <- data$exclude-data$firstTarSacc_relOnsetTime
  data$outlierMin <- data$excludeMin-data$firstTarSacc_relOnsetTime

  # remove outliers
    data <- filter(data, outlierMax>0 & outlierMin<0)
    
    return(data)
    
}

data_saccadeTime2 <- getSaccadeTime(gazeData_allCorr2)
data_saccadeTime2 <- getFactors(data_saccadeTime2)

# null model for saccade time
model0.2.7 <- lmer(firstTarSacc_relOnsetTime ~ 1 +
                   (1|ID),
                 data=data_saccadeTime2,
                 na.action=na.exclude)

varcom <- as.data.frame(VarCorr(model0.2.7))
L2var <- varcom$vcov[1]
L1var <- varcom$vcov[2]
icc0.2.7 <- round(L2var/(L2var+L1var), digits=2)


model4.2.1 <- lmer(firstTarSacc_relOnsetTime ~ Trial_Ctr*Blocktype*switchSet*Congruent +
                     (1|ID),
                   data=data_saccadeTime2,
                   na.action=na.exclude)
results4.2.1 <- as.data.frame(coef(summary(model4.2.1)))
results4.2.1 <- getFormattedResults(results4.2.1)

```
**Quality Checks.** Unlike in Experiment 1, target fixation probability did not change as a function of block (*t*(`r results0.1.3$df[2]`)=`r results0.1.3$tval[2]` *p*=*n.s.*). Additionally, there was not a strong link between target fixation probability and task performance, as indexed by RT (*B* = `r results0.2.4$beta[2]`, *SE*=`r results0.2.4$se[2]`, *t*(`r model0.2.4$df.residual`)=`r results0.2.4$tval[2]` *p*=`r results0.2.4$pval[2]`) and error rate (*B* = `r results0.2.5$beta[2]`, *SE*=`r results0.2.5$se[2]`, *t*(`r model0.2.5$df.residual`)=`r results0.2.5$tval[2]` *p*=`r results0.2.5$pval[2]`), although they were still in the negative direction. Thus, in this sample, there is no evidence that participants learned not to fixate on the target over time on the task, nor that high-performing participants were more likely to use a covert attention strategy.

**Distractor Fixation Probability.** The null model had an ICC of `r icc0.2.6`. Participants were more liklely to fixate on the distractor on Perseveration-Inhibition Blocks (*B* = `r results3.2.1$beta[3]`, *SE*=`r results3.2.1$se[3]`, *t*(`r results3.2.1$df[3]`)=`r results3.2.1$tval[3]` *p*=`r results3.2.1$pval[3]`) and on Switch Sets (*B* = `r results3.2.1$beta[4]`, *SE*=`r results3.2.1$se[4]`, *t*(`r results3.2.1$df[4]`)=`r results3.2.1$tval[4]` *p*=`r results3.2.1$pval[4]`). Unlike in Experiment 1, there was no effect of Trial on distractor fixation probability (*t*(`r results3.2.1$df[2]`)=`r results3.2.1$tval[2]` *p*=*n.s.*). No other effects approached significance.

(ref:capModelh) Model estimates of target saccade time across conditions of the attention shifting task in Experiment 2. Error bars represent the 95% confidence interval (CI). The interaction between Congruence and Trial reached margnial significance, suggesting that on Congruent trials, participants make faster saccades to the target as a function of Trial, whereas on Incongruent trials, participants are, in most conditions, slower to make their first saccade to the target.

```{r figModelh, echo=FALSE, message=FALSE, out.width='100%', fig.cap='(ref:capModelh)'}

getFigDat_ST <- function(model) {
  
  figDat <- expand.grid(
    Trial_Ctr=c(-1.5,-0.5,0.5,1.5),
    Blocktype=c('Perseveration-Inhibition','Pure Updating'),
    Congruent=c('Congruent','Incongruent'),
    switchSet=c('Switch Set','Non-Switch Set'),
    firstTarSacc_relOnsetTime=0
  )
  
  figDat$firstTarSacc_relOnsetTime <- predict(model, figDat, re.form=NA) 
  fd <- model.matrix(terms(model), figDat)
  
  pvar1 <- diag(fd %*% tcrossprod(vcov(model),fd))
  tvar1 <- pvar1+VarCorr(model)$ID[1]
  cmult <- 1.96 ## could use 1.96
  
  figDat <- data.frame(
    figDat
    , plo = figDat$firstTarSacc_relOnsetTime-cmult*sqrt(pvar1)
    , phi = figDat$firstTarSacc_relOnsetTime+cmult*sqrt(pvar1)
    , tlo = figDat$firstTarSacc_relOnsetTime-cmult*sqrt(tvar1)
    , thi = figDat$firstTarSacc_relOnsetTime+cmult*sqrt(tvar1)
  )
  
  return(figDat)
}

figDat4.2.1 <- getFigDat_ST(model4.2.1)

convertFigValues_ST <- function(figDat) {

  figDat$Trial <- figDat$Trial_Ctr + (mean(c(1:keepingTrials)))
  
  return(figDat)
}

figDat4.2.1 <- convertFigValues_ST(figDat4.2.1)

p=ggplot(figDat4.2.1, aes(x=Trial, y=firstTarSacc_relOnsetTime, shape=Congruent))+
  geom_line(aes(x=Trial, y=firstTarSacc_relOnsetTime, linetype=Congruent)) +
  facet_grid(switchSet~Blocktype) +
  scale_linetype_discrete(name='Congruence') +
  scale_shape_discrete(name='Congruence') +
  labs(x='Trial', y='Time of First Saccade to Target (ms)')
p+theme_apa()+geom_pointrange(aes(ymin = plo, ymax = phi))
```
**Saccade Time.** The null model had an ICC of `r icc0.2.7`. The time of participants' first saccade to the target was marginally faster on later compared to earlier trials in a set (*B* = `r results4.2.1$beta[2]`, *SE*=`r results4.2.1$se[2]`, *t*(`r results4.2.1$df[2]`)=`r results4.2.1$tval[2]` *p*=`r results4.2.1$pval[2]`). In contrast with the findings of Experiment 1, the effect of Block Type did not approach significance here (*t*(`r results4.2.1$df[3]`)=`r results4.2.1$tval[3]` *p*=*n.s.*). The only other effect of note was a marginally significant interaction between Trial and Congruence (*B* = `r results4.2.1$beta[9]`, *SE*=`r results4.2.1$se[9]`, *t*(`r results4.2.1$df[9]`)=`r results4.2.1$tval[9]` *p*=`r results4.2.1$pval[9]`). As shown in Figure\ \@ref(fig:figModelh), saccade time on Congruent trials decreases as a function of Trial, whereas in most cases saccade time for on Incongruent trials increases across sets. 

# Discussion  
The inclusion of Non-Switch Sets in Experiment 2 yielded results that were largely consistent with those of Experiment 1. With respect to RTs, participants again showed a pattern of steeper decline following a Switch on Pure Updating compared to Perseveration-Inhibition Blocks. This effect was observed only on Switch Sets, indicating that the effect is driven by the act of upating an attentional set, rather than by simply observing an attentional cue. Unlike in Experiment 1, RTs on the trial immediately following a switch were slower in Pure Updating Blocks, indicating a larger immediate switch cost in this condition. Furthermore, this effect was evident on both Congruent and Incongruent trials, unlike in Experiment 1. With respect to errors, as in Experiment 1, participants were more likely to make errors on Perseveration-Inhibition Blocks, and this effect was also specific to Switch Sets. There were additional interactions involving the Switch Set factor which do not clearly correspond with results from Experiment 1, and will be re-examined in follow-up experiments.  

Consistent with Experiment 1, participants were also more likely to fixate the distractor letter on Perseveration-Inhibition blocks, and the lack of an interaction with Trial suggests that this susceptibility persisted over the course of a set. Switch Sets also predicted greater susceptibility to distractor fixation, which is consistent with expectations. Unlike in the prior experiment, participants were no more likely to fixate on the distractor on early versus late trials in a set. Additionally, task effects on saccade time were less noteworthy here. It is possible that the smaller sample size in this experiment can explain these divergences from Experiment 1; thus it was important to re-run these analyses in a study with both Non-Switch cues and a larger sample (Experiment 4). 

Taken together, these findings indicate that on Perseveration-Inhibition blocks, participants are slower to adopt the new attentional set, which results in slower responding and more errors, even several trials following the update.

# Experiment 3
Experiment aimed to address the importance of task timing for the effects observed on the attention shifting task. The experiments described here had an additional aim of determining the pupillary correlates of attentional shifting across task contexts (results to be reported elsewhere). Because the delayed nature of the pupillary response, we included a long inter-trial interval (3500 ms) to allow sufficient time for the pupil to return to baseline following each trial. As a result, the attention shifting task had a slower pace than other tasks that have been used to assess attentional flexibility. For example, @DreisbachGoschke_2004 had a 1500 ms interval between the end of a trial and the stimuli for the following trial. Consequentially, it is possible that slowing the task altered the balance of cognitive processes at work, by introducing the need to remain vigilant across pauses between task stimuli. Thus, Experiment 3 was conducted with a faster ITI in order to determine whether the observed behavioral are still present in a faster-paced task. 

# Method
```{r pull info for method of Study 3, include=FALSE}
# Excluded Subjects - have been removed prior to data processing
# no time to finish task: 708,714

# demographic info
demog3 <- getDemographicInfo(allData3)

omittedInfo3 <- getOmittedInfo(allData3)

# Remove subjects with too many errors
allData3 <- filter(allData3, !(ID %in% omittedInfo3$tooManyErrors))
# get N for behavioral results
Nbeh3 <- length(unique(allData3$ID))
```

## Participants
Participants were 39 University of Oregon students who received partial course credit. Data from 2 participants were not included because of insufficient time to complete the experiment, leaving `r Nbeh3` participants, with a mean age of `r demog3$meanAge` (*SD*=`r demog3$sdAge`; `r demog3$numFemales` Females).

## Procedure
The procedure was identical to that for Experiment 2, except that participants performed the task without eyetracking, and in a separate room from the experimenter. Additionally, because of the shortened ITI, the experiment was shorter, lasting only approximately 1 hour.

## Materials and Apparatus
**Attention Shifting Task.** The task used in this experiment was similar to that used in Experiment 2, except that it was modified to have an ITI of 1500ms, instead of 3500ms. The interval between the color word cues and the first trial of each set remained the same at 4000ms. As in Experiment 2, cues could signal either the need to switch target colors or to continue attending the same target color. Stimulus arrays remained on the screen until participant response, as in Experiment 1.  

**Apparatus.** As in the previous experiments, the task was run with Psychtoolbox in MATLAB. The task was presented using an iMac computer with a 27'' monitor and a resolution of 2560 x 1440 pixels.

## Data analysis
Data processing and analysis procedures were identical to those for the previous two experiments. The mean error rate was `r omittedInfo3$meanErrors*100`% (*SD* = `r omittedInfo3$sdErrors*100`%). RT data were cleaned to remove outliers (*SD* = `r omittedInfo3$removedTrials*100`% of trials)


# Results (*N*=`r Nbeh3`)
```{r Study 3 behavioral results, include=FALSE}

cleanData3_RT <- getCleanDataRT(allData3)

cleanData3_RT <-getFactors(cleanData3_RT)

# legend for naming models:
# first number - number of analysis in experiment
# second number - experiment
# third number - error rate vs. RT as DV (1 for RT, 2 for error rate)

# test null model and compute ICC for RTs:
model0.3.1 <- lmer(lnRT ~ 1 +
                 (1|ID),
               data=cleanData3_RT,
               na.action=na.exclude)

varcom <- as.data.frame(VarCorr(model0.3.1))
L2var <- varcom$vcov[1]
L1var <- varcom$vcov[2]
icc0.3.1 <- round((L2var/(L2var+L1var)), digits=2)

# RT model with predictors:
model1.3.1 <- lmer(lnRT ~ Trial_Ctr*Blocktype*switchSet*Congruent +
                     (1|ID),
                   data=cleanData3_RT,
                   na.action=na.exclude)

results1.3.1 <- as.data.frame(coef(summary(model1.3.1)))
results1.3.1 <- getFormattedResults(results1.3.1)

# Error Rate Analyses
cleanData3_ER <- getCleanDataER(allData3)
cleanData3_ER <- getFactors(cleanData3_ER)

getCleanSummary_Study3 <- function(cleanData){
  # find mean error rate for each condition
  summaryData <- group_by(cleanData, ID, Trial_Ctr, Blocktype, Congruent, switchSet) %>%
    summarise(eRate = 100*(mean(Error, na.rm=TRUE)))
  
  # winsorize summarized data
  meanErate <- mean(summaryData$eRate)
  sdErate <- sd(summaryData$eRate)
  maxErate <- meanErate + winsorizeErrorsSD*sdErate
  findNextLargestErate <- filter(summaryData, eRate<maxErate)
  maxValueErate <- max(findNextLargestErate$eRate)
  summaryDataClean <- summaryData
  summaryDataClean$eRate[summaryDataClean$eRate>maxErate] <- maxValueErate

  return(summaryDataClean)
  
}

summaryData3_ER <- getCleanSummary_Study3(cleanData3_ER)

# null model for error rate
model0.3.2 <- lmer(eRate ~ 1 +
                   (1|ID),
                 data=summaryData3_ER,
                 na.action=na.exclude)

varcom <- as.data.frame(VarCorr(model0.3.2))
L2var <- varcom$vcov[1]
L1var <- varcom$vcov[2]
icc0.3.2 <- round(L2var/(L2var+L1var), digits=2)

# prediction model for error rate
model1.3.2 <- lmer(eRate ~ Trial_Ctr*Blocktype*switchSet*Congruent + 
                   (1|ID),
                 data=summaryData3_ER,
                 na.action=na.exclude)

results1.3.2 <- as.data.frame(coef(summary(model1.3.2)))
results1.3.2 <- getFormattedResults(results1.3.2)
```

(ref:capModeli) Model estimates of (RT) across conditions of the attention shifting task in Experiment 3. Error bars represent the 95% confidence interval (CI). Even with a faster ITI, the interaction between Block Type, Set Type, and Trial replicated here: On Switch Sets, RTs were slower to asymptote on Perseveration-Inhibition blocks compared to Pure Updating blocks.

```{r figModeli, echo=FALSE, message=FALSE, out.width='100%', fig.cap='(ref:capModeli)'}

figDat1.3.1 <- getFigDat_RT(model1.3.1)
figDat1.3.1 <- convertFigValues_RT(figDat1.3.1)

p=ggplot(figDat1.3.1, aes(x=Trial, y=RT, shape=switchSet))+
  geom_line(aes(x=Trial, y=RT, linetype=switchSet)) +
  facet_grid(Congruent~Blocktype) +
  scale_linetype_discrete(name='Set Type') +
  scale_shape_discrete(name='Set Type') +
  labs(x='Trial', y='RT (ms)')
p+theme_apa()+geom_pointrange(aes(ymin = ploRT, ymax = phiRT))
```

**RT.** The null model had an ICC of `r icc0.3.1`. In the prediction model, there were main effects of Trial (*B* = `r results1.3.1$beta[2]`, *SE*=`r results1.3.1$se[2]`, *t*(`r results1.3.1$df[2]`)=`r results1.3.1$tval[2]` *p*=`r results1.3.1$pval[2]`) and Set Type (*B* = `r results1.3.1$beta[4]`, *SE*=`r results1.3.1$se[4]`, *t*(`r results1.3.1$df[4]`)=`r results1.3.1$tval[4]` *p*=`r results1.3.1$pval[4]`), qualified by a Trial x Set Type interaction (*B* = `r results1.3.1$beta[7]`, *SE*=`r results1.3.1$se[7]`, *t*(`r results1.3.1$df[7]`)=`r results1.3.1$tval[7]` *p*=`r results1.3.1$pval[7]`), which indicates a switch cost: participants were slower on trials that occur soon after an attentional shift. Interestingly, in this experiment there was no main effect of Block Type (*t*(`r results1.3.1$df[3]`)=`r results1.3.1$tval[3]` *n.s.*), nor of Congruence (*t*(`r results1.3.1$df[5]`)=`r results1.3.1$tval[5]` *n.s.*).  

The 3-way interaction between Trial, Set Type and Block Type from thee previous two experiments was replicated (*B* = `r results1.3.1$beta[12]`, *SE*=`r results1.3.1$se[12]`, *t*(`r results1.3.1$df[12]`)=`r results1.3.1$tval[12]` *p*=`r results1.3.1$pval[12]`). As shown in Figure\ \@ref(fig:figModeli), following an attention shift, RTs are initially slower but decline more steeply on Pure Updating blocks compared to Perseveration-Inhibition blocks. No other effects reached significance.

(ref:capModelj) Model estimates of error rate across conditions of the attention shifting task in Experiment 3. Error bars represent the 95% confidence interval (CI). Replicating the previous two experiments, the interaction between Block Type, Set Type, and Congruence indicates that participants were more error-prone on Incongruent trials in Perseveration-Inhibition blocks when they have recently switched (i.e. on Switch Sets).

```{r figModelj, echo=FALSE, message=FALSE, out.width='100%', fig.cap='(ref:capModelj)'}

figDat1.3.2 <- getFigDat_ER(model1.3.2)

figDat1.3.2 <- convertFigValues_ER(figDat1.3.2)

p=ggplot(figDat1.3.2, aes(x=Trial, y=eRate, linetype=Congruent, shape=Congruent))+
  geom_line() +
  geom_point () +
  facet_grid(switchSet~Blocktype) +
  scale_linetype_discrete(name='Congruence') +
  scale_shape_discrete(name='Congruence') +
  labs(x='Trial', y='Error Rate (%)')
p+theme_apa()+geom_pointrange(aes(ymin = plo, ymax = phi))

```

**Error Rate.** The null model had an ICC of `r icc0.3.2`. In the prediction model, unlike in the previous experiments, the main effect of Congruence did not reach significance (*B* = `r results1.3.2$beta[5]`, *SE*=`r results1.3.2$se[5]`, *t*(`r results1.3.2$df[5]`)=`r results1.3.2$tval[5]` *p*=`r results1.3.2$pval[5]`), however it was in a consistent direction. The only other effect of note was the 3-way interaction between Block Type, Set Type, and Congruence (*B* = `r results1.3.2$beta[15]`, *SE*=`r results1.3.2$se[15]`, *t*(`r results1.3.2$df[15]`)=`r results1.3.2$tval[15]` *p*=`r results1.3.2$pval[15]`). This effect (Figure\ \@ref(fig:figModelj)) is consistent with the other experiments, and indicates that on Switch Sets in Perseveration-Inhibition blocks, there was a larger error cost of Incongruent trials, compared to Switch Sets in Pure Updating blocks.

# Discussion
Increasing the pace of the task in Experiment 3 led to results that were largely consistent with those of the previous experiments, with a few exceptions. In particular, participants did not respond more slowly overall on Perseveration-Inhibition blocks, nor did they make more errors overall on Incongruent trials, both of which have been observed in the other experiments. Thus, it is possible that these effects are dependent on a slower-paced task in which participants may be more prone to attentional lapses. On the other hand, the key 3-way observed in the prior experiments were also present here: In the context of Switch Sets within Perseveration-Inhibition blocks, participants still showed a slower reduction in RTs across trials, and had higher incongruence costs in error rate. Thus, these latter effects are unlikely to be the result of the slower task pace in the prior experiments.

# Experiment 4


# Method
```{r pull info for method of Study 4, include=FALSE}
# Excluded Subjects - have been removed prior to data processing
# couldn't track eye: 434 (these are included in behavioral analyses)
# tried not to blink during pupil baseline: 409, 411

# demographic info
demog4 <- getDemographicInfo(allData4)

# get error/trial removal info
omittedInfo4 <- getOmittedInfo(allData4)

blinkInfo4 <- getBlinkInfo(allData4)

gazeInfo4 <- getGazeInfo(allData4)

# Remove subjects with too many errors
allData4 <- filter(allData4, !(ID %in% omittedInfo4$tooManyErrors))
# get N for behavioral results
Nbeh4 <- length(unique(allData4$ID))
Nblinks4 <- Nbeh4 - blinkInfo4$numExcluded
Ngaze4 <- Nbeh4 - length(gazeInfo4$excludeTarPct)
```

## Participants
The experiment was conducted as the first session of a larger study on cognitive control and academic goal pursuit. To reach a target sample of 100 subjects for adequate statistical power, 117 University of Oregon students took part in the session. Two participants withdrew partway through the session, leaving a sample of 115. All participants were between the ages of 18-30, had normal or corrected-to-normal vision, no history of significant psychological or neurological disorders, and were not taking medications that affect cognitive functioning. Participants received compensation of \$10 per hour, with most receiving \$20 for the session reported here and $60 in total for the entire experiment.

```{r check caffeine and sleep - Study 4, include=FALSE}
cleanData4_EBR <- winsorizeEBR(allData4, blinkInfo4)
cleanData4_EBR$sleep <- as.numeric(cleanData4_EBR$sleep)
cleanData4_EBR <- filter(cleanData4_EBR, caffeine %in% c('Yes','No'))

cleanData4_EBR <- group_by(cleanData4_EBR, ID, caffeine) %>%
  summarise(meanSleep=mean(sleep, na.rm=TRUE),
            ebr=mean(ebr, na.rm=TRUE))


model0.4.6 <- lm(ebr ~ caffeine,
                 data=cleanData4_EBR,
                 na.action=na.exclude)

model0.4.7 <- lm(ebr ~ meanSleep,
                 data=cleanData4_EBR,
                 na.action=na.exclude)

results0.4.6 <- as.data.frame(coef(summary(model0.4.6)))
results0.4.6 <- getFormattedResults_lm(results0.4.6)

results0.4.7 <- as.data.frame(coef(summary(model0.4.7)))
results0.4.7 <- getFormattedResults_lm(results0.4.7)
```

## Procedure, Materials, and Data Analysis
The procedure of the first session was identical to that of Experiment 2, and lasted approximately 2 hours.  The attentional shifting task was identical to the task in Experiment 2, except that the stimulus array remained on the screen until response, rather than for a standardized duration. As in Experiment 2, EBR baseline measurements required participants to look at a fixation cross in the center of the screen for 5 minutes. Participants were instructed to relax and do their best to continue to look straight ahead. After 38 sessions had been run, it came to our attention that 2 participants had actively tried not to blink during this period, and following that point, participants were explicitly told that they could blink naturally during this period. The relationships among caffeine, sleep, and EBR were different to those observed in experiment 1: Caffeine consumption predicted reduced EBR (*B* = `r results0.4.6$beta[2]`, *SE*=`r results0.4.6$se[2]`, *t*(`r model0.4.6$df[2]`)=`r results0.4.6$tval[2]` *p*=`r results0.4.6$pval[2]`), whereas hours of sleep was not related to EBR (*B* = `r results0.4.7$beta[2]`, *SE*=`r results0.4.7$se[2]`, *t*(`r model0.4.7$df[2]`)=`r results0.4.7$tval[2]` *p*=`r results0.4.7$pval[2]`)

All data processing and analysis was the same as for the prior experiments. Participants performed the task with a mean error rate of `r omittedInfo4$meanErrors*100`% (*SD* = `r omittedInfo4$sdErrors*100`%), and `r omittedInfo4$numExclErrors` were removed for having an error rate greater than `r excludeMaxErrorRateSDs` standard deviations from the group mean. Trials with outlying RTs were also removed (*SD* = `r omittedInfo4$removedTrials*100`% of trials)

# Results
## Behavioral Results (*N*=`r Nbeh4`)
```{r Study 4 behavioral results, include=FALSE}
# remove trials excluded from RT analyes
cleanData4_RT <- getCleanDataRT(allData4)

cleanData4_RT <-getFactors(cleanData4_RT)

# legend for naming models:
# first number - number of analysis in experiment
# second number - experiment
# third number - error rate vs. RT as DV (1 for RT, 2 for error rate)

# test null model and compute ICC for RTs:
model0.4.1 <- lmer(lnRT ~ 1 +
                 (1|ID),
               data=cleanData4_RT,
               na.action=na.exclude)

varcom <- as.data.frame(VarCorr(model0.4.1))
L2var <- varcom$vcov[1]
L1var <- varcom$vcov[2]
icc0.4.1 <- round((L2var/(L2var+L1var)), digits=2)

# RT model with predictors:
model1.4.1 <- lmer(lnRT ~ Trial_Ctr*Blocktype*switchSet*Congruent +
                     (1|ID),
                   data=cleanData4_RT,
                   na.action=na.exclude)

results1.4.1 <- as.data.frame(coef(summary(model1.4.1)))
results1.4.1 <- getFormattedResults(results1.4.1)

# Error Rate Analyses

cleanData4_ER <- getCleanDataER(allData4)
cleanData4_ER <- getFactors(cleanData4_ER)

summaryData4_ER <- getCleanSummary(cleanData4_ER)

# null model for error rate
model0.4.2 <- lmer(eRate ~ 1 +
                   (1|ID),
                 data=summaryData4_ER,
                 na.action=na.exclude)

varcom <- as.data.frame(VarCorr(model0.4.2))
L2var <- varcom$vcov[1]
L1var <- varcom$vcov[2]
icc0.4.2 <- L2var/(L2var+L1var)

# prediction model for error rate
model1.4.2 <- lmer(eRate ~ Trial_Ctr*Blocktype*switchSet*Congruent + 
                   (1|ID),
                 data=summaryData4_ER,
                 na.action=na.exclude)

results1.4.2 <- as.data.frame(coef(summary(model1.4.2)))
results1.4.2 <- getFormattedResults(results1.4.2)


```

(ref:capModelk) Model estimates of RT across conditionss of the attention shifting task in Experiment 4. Error bars represent the 95% confidence interval (CI). The main behavioral finding was again replicated: RTs asymptote more gradually over the course of a set on Perseveration-Inhibition blocks, on sets in which participants have recently switched (i.e. Switch Sets).

```{r figModelk, echo=FALSE, message=FALSE, out.width='100%', fig.cap='(ref:capModelk)'}

figDat1.4.1 <- getFigDat_RT(model1.4.1)
figDat1.4.1 <- convertFigValues_RT(figDat1.4.1)

p=ggplot(figDat1.4.1, aes(x=Trial, y=RT, shape=switchSet))+
  geom_line(aes(x=Trial, y=RT, linetype=switchSet)) +
  facet_grid(Congruent~Blocktype) +
  scale_linetype_discrete(name='Set Type') +
  scale_shape_discrete(name='Set Type') +
  labs(x='Trial', y='RT (ms)')
p+theme_apa()+geom_pointrange(aes(ymin = ploRT, ymax = phiRT))
```
**RT.** The null model had an ICC of `r icc0.4.1`. From the prediction model, the main effects were largely as expected, with participants responding more quickly on later trials (*B* = `r results1.4.1$beta[2]`, *SE*=`r results1.4.1$se[2]`, *t*(`r results1.4.1$df[2]`)=`r results1.4.1$tval[2]` *p*=`r results1.4.1$pval[2]`), Non-Switch Sets (*B* = `r results1.4.1$beta[4]`, *SE*=`r results1.4.1$se[4]`, *t*(`r results1.4.1$df[4]`)=`r results1.4.1$tval[4]` *p*=`r results1.4.1$pval[4]`), Pure Updating blocks (*B* = `r results1.4.1$beta[3]`, *SE*=`r results1.4.1$se[3]`, *t*(`r results1.4.1$df[3]`)=`r results1.4.1$tval[3]` *p*=`r results1.4.1$pval[3]`), and Congruent trials (*B* = `r results1.4.1$beta[5]`, *SE*=`r results1.4.1$se[5]`, *t*(`r results1.4.1$df[5]`)=`r results1.4.1$tval[5]` *p*=`r results1.4.1$pval[5]`). The 2-way interaction between Trial and Set Type (*B* = `r results1.4.1$beta[7]`, *SE*=`r results1.4.1$se[7]`, *t*(`r results1.4.1$df[7]`)=`r results1.4.1$tval[7]` *p*=`r results1.4.1$pval[7]`) again indicated switch cost, with participants responding more slowly on early trials of Non-Switch Sets. Finally, the consistent effect from the previous experiments was replicated here (Figure\ \@ref(fig:figModelk)), as indicated by the 3-way interaction between between Trial, Block Type, and Set Type reached (*B* = `r results1.4.1$beta[12]`, *SE*=`r results1.4.1$se[12]`, *t*(`r results1.4.1$df[12]`)=`r results1.4.1$tval[12]` *p*=`r results1.4.1$pval[12]`).

(ref:capModell) Model estimates of error rate across conditions of the attention shifting task in Experiment 4. Error bars represent the 95% confidence interval (CI). The interaction between Block Type, Set Type, and Congruence was again replicated, indicating that participants were most susceptible to making errors on Incongruent trials in Perseveration-Blocks on sets in which they have recently switched.

```{r figModell, echo=FALSE, message=FALSE, out.width='100%', fig.cap='(ref:capModell)'}

figDat1.4.2 <- getFigDat_ER(model1.4.2)

figDat1.4.2 <- convertFigValues_ER(figDat1.4.2)

p=ggplot(figDat1.4.2, aes(x=Trial, y=eRate, linetype=Congruent, shape=Congruent))+
  geom_line() +
  geom_point () +
  facet_grid(switchSet~Blocktype) +
  scale_linetype_discrete(name='Congruence') +
  scale_shape_discrete(name='Congruence') +
  labs(x='Trial', y='Error Rate (%)')
p+theme_apa()+geom_pointrange(aes(ymin = plo, ymax = phi))

```

**Error Rate.** Between-subject variability in error rate was `r icc0.4.1`%. In the prediction model, there were main effects of Set Type (*B* = `r results1.4.2$beta[4]`, *SE*=`r results1.4.2$se[4]`, *t*(`r results1.4.2$df[4]`)=`r results1.4.2$tval[4]` *p*=`r results1.4.2$pval[4]`) and Congruence (*B* = `r results1.4.2$beta[5]`, *SE*=`r results1.4.2$se[5]`, *t*(`r results1.4.2$df[5]`)=`r results1.4.2$tval[5]` *p*=`r results1.4.2$pval[5]`). There was additionally a 2-way interaction between Set Type and Congruence (*B* = `r results1.4.2$beta[11]`, *SE*=`r results1.4.2$se[11]`, *t*(`r results1.4.2$df[11]`)=`r results1.4.2$tval[11]` *p*=`r results1.4.2$pval[11]`), within the context of the consistent 3-way interaction between Set Type, Block Type, and Congruence from the prior studies was again replicated here (*B* = `r results1.4.2$beta[15]`, *SE*=`r results1.4.2$se[15]`, *t*(`r results1.4.2$df[15]`)=`r results1.4.2$tval[15]` *p*=`r results1.4.2$pval[15]`). Incongruence costs in error rates were greater on Switch Sets, and this effect is driven largely by Perseveration-Inhibition blocks (Figure\ \@ref(fig:figModell)).

## Eyetracking Results (*N*=`r Ngaze4`)
```{r Study 4 eyetracking results, include=FALSE}

gazeData_allCorr4 <- getCleanDataGaze_allCorrect(allData4, gazeInfo4, blinkInfo4)
gazeData_errors4 <- getCleanDataGaze_withErrors(allData4, gazeInfo4, blinkInfo4)

# quality check - does % of target fixations decrease over the course of the experiment?
summaryDataByBlock4 <- aggByBlock(gazeData_allCorr4)

model0.4.3 <- lmer(meanTarPct ~ Block_Ctr +
                     (1|ID),
                   data=summaryDataByBlock4,
                   na.action=na.exclude)
results0.4.3 <- as.data.frame(coef(summary(model0.4.3)))
results0.4.3 <- getFormattedResults(results0.4.3)

# quality check - does % of target fixations relate to performance (RT/Errors)?
summaryDataBySub4 <- aggBySub_RT(gazeData_allCorr4)

model0.4.4 <- lm(meanTarPct ~ meanlnRT,
                 data=summaryDataBySub4,
                 na.action=na.exclude)

results0.4.4 <- as.data.frame(coef(summary(model0.4.4)))
results0.4.4 <- getFormattedResults_lm(results0.4.4)

summaryDataBySub4_errors <- aggBySub_errors(gazeData_errors4)

model0.4.5 <- lm(meanTarPct ~ eRate,
                 data=summaryDataBySub4_errors,
                 na.action=na.exclude)
results0.4.5 <- as.data.frame(coef(summary(model0.4.5)))
results0.4.5 <- getFormattedResults_lm(results0.4.5)


# Distractor Fixation Probability
summaryData_distFix4 <- getDistFixProb(gazeData_errors4)
summaryData_distFix4 <- getFactors(summaryData_distFix4)

# null model for distractor fixation probability
model0.4.6 <- lmer(distFixProb ~ 1 +
                   (1|ID),
                 data=summaryData_distFix4,
                 na.action=na.exclude)

varcom <- as.data.frame(VarCorr(model0.4.6))
L2var <- varcom$vcov[1]
L1var <- varcom$vcov[2]
icc0.4.6 <- round(L2var/(L2var+L1var), digits=2)

model3.4.1 <- lmer(distFixProb ~ Trial_Ctr*Blocktype*switchSet*Congruent +
                     (1|ID),
                   data=summaryData_distFix4,
                   na.action=na.exclude)
results3.4.1 <- as.data.frame(coef(summary(model3.4.1)))
results3.4.1 <- getFormattedResults(results3.4.1)

# test without long times
gazeData_errors4_shortTimes <- filter(gazeData_errors4, firstDistFix_relOnsetTime<1000|is.na(firstDistFix_relOnsetTime))
summaryData_distFix4_shortTimes <- getDistFixProb(gazeData_errors4_shortTimes)
summaryData_distFix4_shortTimes <- getFactors(summaryData_distFix4_shortTimes)

model3.4.1a <- lmer(distFixProb ~ Trial_Ctr*Blocktype*switchSet*Congruent +
                     (1|ID),
                   data=summaryData_distFix4_shortTimes,
                   na.action=na.exclude)
results3.4.1a <- as.data.frame(coef(summary(model3.4.1a)))
results3.4.1a <- getFormattedResults(results3.4.1a)



# Saccade Time
data_saccadeTime4 <- getSaccadeTime(gazeData_allCorr4)
data_saccadeTime4 <- getFactors(data_saccadeTime4)

# null model for saccade time
model0.4.7 <- lmer(firstTarSacc_relOnsetTime ~ 1 +
                   (1|ID),
                 data=data_saccadeTime4,
                 na.action=na.exclude)

varcom <- as.data.frame(VarCorr(model0.4.7))
L2var <- varcom$vcov[1]
L1var <- varcom$vcov[2]
icc0.4.7 <- round(L2var/(L2var+L1var), digits=2)


model4.4.1 <- lmer(firstTarSacc_relOnsetTime ~ Trial_Ctr*Blocktype*switchSet*Congruent +
                     (1|ID),
                   data=data_saccadeTime4,
                   na.action=na.exclude)
results4.4.1 <- as.data.frame(coef(summary(model4.4.1)))
results4.4.1 <- getFormattedResults(results4.4.1)

# test without long times
data_saccadeTime4_shortRTs <- filter(data_saccadeTime4, firstTarSacc_relOnsetTime<1000)
model4.4.1a <- lmer(firstTarSacc_relOnsetTime ~ Trial_Ctr*Blocktype*switchSet*Congruent +
                     (1|ID),
                   data=data_saccadeTime4_shortRTs,
                   na.action=na.exclude)
results4.4.1a <- as.data.frame(coef(summary(model4.4.1a)))
results4.4.1a <- getFormattedResults(results4.4.1a)

```

**Quality Checks.** In this experiment, the likelihood of fixating the target did not change as a function of time on task (*t*(`r results0.4.3$df[2]`)=`r results0.4.3$tval[2]` *p*=*n.s.*). Similar to Experiment 1, greater target fixation probability predicted significantly fewer errors (*B* = `r results0.4.5$beta[2]`, *SE*=`r results0.4.5$se[2]`, *t*(`r model0.4.4$df.residual`)=`r results0.4.5$tval[2]` *p*=`r results0.4.5$pval[2]`) and marginally faster RTs (*B* = `r results0.4.5$beta[2]`, *SE*=`r results0.4.5$se[2]`, *t*(`r model0.4.5$df.residual`)=`r results0.4.5$tval[2]` *p*=`r results0.4.5$pval[2]`). This finding supports the validity of our assumption that higher target fixation probability is predictive of better, not worse or less efficient, performance.

(ref:capModelm) Model estimates of distractor fixation probability on the attention shifting task in Experiment 4. Error bars represent the 95% confidence interval (CI). The interaction between Block Type and Set Type reached significance, indicating that participants were more likely to fixate on the distractor on Switch Sets of Perseveration-Inhibition blocks.

```{r figModelm, echo=FALSE, message=FALSE, out.width='100%', fig.cap='(ref:capModelm)'}

getFigDat_DF <- function(model) {
  
  figDat <- expand.grid(
    Trial_Ctr=c(-1.5,-0.5,0.5,1.5),
    Blocktype=c('Perseveration-Inhibition','Pure Updating'),
    Congruent=c('Congruent','Incongruent'),
    switchSet=c('Switch Set','Non-Switch Set'),
    distFixProb=0
  )
  
  figDat$distFixProb <- predict(model, figDat, re.form=NA) 
  fd <- model.matrix(terms(model), figDat)
  
  pvar1 <- diag(fd %*% tcrossprod(vcov(model),fd))
  tvar1 <- pvar1+VarCorr(model)$ID[1]
  cmult <- 1.96 ## could use 1.96
  
  figDat <- data.frame(
    figDat
    , plo = figDat$distFixProb-cmult*sqrt(pvar1)
    , phi = figDat$distFixProb+cmult*sqrt(pvar1)
    , tlo = figDat$distFixProb-cmult*sqrt(tvar1)
    , thi = figDat$distFixProb+cmult*sqrt(tvar1)
  )
  
  return(figDat)
}

figDat3.4.1 <- getFigDat_DF(model3.4.1)

convertFigValues_DF <- function(figDat) {

  figDat$Trial <- figDat$Trial_Ctr + (mean(c(1:keepingTrials)))
  
  return(figDat)
}

figDat3.4.1 <- convertFigValues_DF(figDat3.4.1)

p=ggplot(figDat3.4.1, aes(x=Trial, y=distFixProb, shape=switchSet))+
  geom_line(aes(x=Trial, y=distFixProb, linetype=switchSet)) +
  facet_grid(Congruent~Blocktype) +
  scale_linetype_discrete(name='Set Type') +
  scale_shape_discrete(name='Set Type') +
  labs(x='Trial', y='Distractor Fixation Probability')
p+theme_apa()+geom_pointrange(aes(ymin = plo, ymax = phi))
```

**Distractor Fixation Probability.** The null model indicated that `r icc0.4.6*100`% of the variance in distractor fixation probability could be attributed to between-subject differences. In the prediction model, there was a main effect of Set Type (*B* = `r results3.4.1$beta[4]`, *SE*=`r results3.4.1$se[4]`, *t*(`r results3.4.1$df[4]`)=`r results3.4.1$tval[4]` *p*=`r results3.4.1$pval[4]`), and a marginally significant effect of Block Type (*B* = `r results3.4.1$beta[3]`, *SE*=`r results3.4.1$se[3]`, *t*(`r results3.4.1$df[3]`)=`r results3.4.1$tval[3]` *p*=`r results3.4.1$pval[3]`), indicating that participants were more likely to fixate on the distractor on Perseveration-Inhibition blocks and Switch Sets. These main effects were qualified by an interaction between Block Type and Set Type (*B* = `r results3.4.1$beta[8]`, *SE*=`r results3.4.1$se[8]`, *t*(`r results3.4.1$df[8]`)=`r results3.4.1$tval[8]` *p*=`r results3.4.1$pval[8]`). As shown in Figure\ \@ref(fig:figModelm), the likelihood of distractor fixation was greater for Switch compared to Non-Switch Sets, and this effect was larger on Perseveration-Inhibition blocks. Finally, there was a marginally significant 3-way interaction that also included Trial (*B* = `r results3.4.1$beta[12]`, *SE*=`r results3.4.1$se[12]`, *t*(`r results3.4.1$df[12]`)=`r results3.4.1$tval[12]` *p*=`r results3.4.1$pval[12]`). On Perseveration-Inhibition blocks, there was a tendency for distractor fixation to become less likely over the course of Switch Sets, but more likely over the course of Non-Switch sets, whereas this pattern was less pronounced on Pure Updating blocks.  

(ref:capModeln) Model estimates of saccade onset time across conditions of the attention shifting task in Experiment 4. Error bars represent the 95% confidence interval (CI). The interaction between Block Type, Set Type, and Trial suggests that saccade time on Switch Sets grew faster as a function of Trial on Pure Updating blocks, but not on Perseveration-Inhibition blocks.

```{r figModeln, echo=FALSE, message=FALSE, out.width='100%', fig.cap='(ref:capModeln)'}

figDat4.4.1 <- getFigDat_ST(model4.4.1)
figDat4.4.1 <- convertFigValues_ST(figDat4.4.1)

p=ggplot(figDat4.4.1, aes(x=Trial, y=firstTarSacc_relOnsetTime, shape=switchSet))+
  geom_line(aes(x=Trial, y=firstTarSacc_relOnsetTime, linetype=switchSet)) +
  facet_grid(Congruent~Blocktype) +
  scale_linetype_discrete(name='Set Type') +
  scale_shape_discrete(name='Set Type') +
  labs(x='Trial', y='Time of First Saccade to Target (ms)')
p+theme_apa()+geom_pointrange(aes(ymin = plo, ymax = phi))
```

**Saccade Time.** Similar to the previous experiments, the null model indicated a relatively small proportion of the variance in target saccade time was attributable to Subject (ICC=`r icc0.4.7`). In the prediction model, there was a marginally significant main effect of Set Type (*B* = `r results4.4.1$beta[4]`, *SE*=`r results4.4.1$se[4]`, *t*(`r results4.4.1$df[4]`)=`r results4.4.1$tval[4]` *p*=`r results4.4.1$pval[4]`). Additionally, there was a 2-way interaction between Set Type and Trial (*B* = `r results4.4.1$beta[7]`, *SE*=`r results4.4.1$se[7]`, *t*(`r results4.4.1$df[7]`)=`r results4.4.1$tval[7]` *p*=`r results4.4.1$pval[7]`), nested within a 3-way interaction that also included Block Type (*B* = `r results4.4.1$beta[12]`, *SE*=`r results4.4.1$se[12]`, *t*(`r results4.4.1$df[12]`)=`r results4.4.1$tval[12]` *p*=`r results4.4.1$pval[12]`). As shown in Figure\ \@ref(fig:figModeln), on Switch Sets of Pure Updating blocks, saccades to target occur increasingly earlier at later points in the set, whereas on Perseveration-Inhibition blocks, the timing of saccades to target does not change across a set.

## EBR Results (*N*=`r Nblinks4`)
```{r Study 4 ebr results, include=FALSE}
# winsorize ebr
cleanData4_RT_EBR <- winsorizeEBR(cleanData4_RT, blinkInfo4)
cleanData4_RT_EBR <- centerEBR(cleanData4_RT_EBR, blinkInfo4)

# ebr RT analysis
model5.4.1 <- lmer(lnRT ~ Trial_Ctr*Blocktype*switchSet*Congruent*ebr_Ctr + 
                 (1|ID),
               data=cleanData4_RT_EBR,
               na.action=na.exclude)
results5.4.1 <- as.data.frame(coef(summary(model5.4.1)))
results5.4.1 <- getFormattedResults(results5.4.1)


model5.4.1a <- lmer(lnRT ~ Trial_Ctr*Blocktype*switchSet*ebr_Ctr + 
                 (1|ID),
               data=cleanData4_RT_EBR,
               na.action=na.exclude)
results5.4.1a <- as.data.frame(coef(summary(model5.4.1a)))
results5.4.1a <- getFormattedResults(results5.4.1a)

# look at two block types separately
cleanData4_RT_EBR_persInhib <- filter(cleanData4_RT_EBR, Blocktype=='Perseveration-Inhibition')
cleanData4_RT_EBR_pureUpd <- filter(cleanData4_RT_EBR, Blocktype=='Pure Updating')

model5.4.1aPI <- lmer(lnRT ~ Trial_Ctr*switchSet*ebr_Ctr + 
                 (1|ID),
               data=cleanData4_RT_EBR_persInhib,
               na.action=na.exclude)
results5.4.1aPI <- as.data.frame(coef(summary(model5.4.1aPI)))
results5.4.1aPI <- getFormattedResults(results5.4.1aPI)

model5.4.1aPU <- lmer(lnRT ~ Trial_Ctr*switchSet*ebr_Ctr + 
                 (1|ID),
               data=cleanData4_RT_EBR_pureUpd,
               na.action=na.exclude)
results5.4.1aPU <- as.data.frame(coef(summary(model5.4.1aPU)))
results5.4.1aPU <- getFormattedResults(results5.4.1aPU)

# look at two set types separately:
cleanData4_RT_EBR_Sw <- filter(cleanData4_RT_EBR, switchSet=='Switch Set')
cleanData4_RT_EBR_Ns <- filter(cleanData4_RT_EBR, switchSet=='Non-Switch Set')

model5.4.1aSw <- lmer(lnRT ~ Trial_Ctr*Blocktype*ebr_Ctr + 
                 (1|ID),
               data=cleanData4_RT_EBR_Sw,
               na.action=na.exclude)
results5.4.1aSw <- as.data.frame(coef(summary(model5.4.1aSw)))
results5.4.1aSw <- getFormattedResults(results5.4.1aSw)

model5.4.1aNs <- lmer(lnRT ~ Trial_Ctr*Blocktype*ebr_Ctr + 
                 (1|ID),
               data=cleanData4_RT_EBR_Ns,
               na.action=na.exclude)
results5.4.1aNs <- as.data.frame(coef(summary(model5.4.1aNs)))
results5.4.1aNs <- getFormattedResults(results5.4.1aNs)

# ebr RT analysis with gender
cleanData4_RT_EBR_gen <- filter(cleanData4_RT_EBR, (gender %in% c('Male','Female')))

# test for difference in EBR between males and females 
# possibility - should I center or z-score by gender?
blinks4 <- unique(cleanData4_RT_EBR_gen[c('ID', 'ebr','gender')])
blinksByGender4 <- group_by(blinks4, gender) %>%
  summarise(meanEBR=round(mean(ebr, na.rm=TRUE), digits=2),
            sdEBR=round(sd(ebr, na.rm=TRUE), digits=2))
gd4 <- t.test(blinks4$ebr~blinks4$gender)


model6.4.1 <- lmer(lnRT ~ Trial_Ctr*Blocktype*switchSet*Congruent*ebr_Ctr*gender + 
                 (1|ID),
               data=cleanData4_RT_EBR_gen,
               na.action=na.exclude)
results6.4.1 <- as.data.frame(coef(summary(model6.4.1)))
results6.4.1 <- getFormattedResults(results6.4.1)

model6.4.1a <- lmer(lnRT ~ Trial_Ctr*Blocktype*switchSet*ebr_Ctr*gender + 
                 (1|ID),
               data=cleanData4_RT_EBR_gen,
               na.action=na.exclude)
results6.4.1a <- as.data.frame(coef(summary(model6.4.1a)))
results6.4.1a <- getFormattedResults(results6.4.1a)

# try with females/males only
cleanData4_RT_EBR_genf <- filter(cleanData4_RT_EBR_gen, gender=='Female')
model6.4.1bfem <- lmer(lnRT ~ Trial_Ctr*Blocktype*switchSet*ebr_Ctr + 
                 (1|ID),
               data=cleanData4_RT_EBR_genf,
               na.action=na.exclude)
results6.4.1bfem <- as.data.frame(coef(summary(model6.4.1bfem)))
results6.4.1bfem <- getFormattedResults(results6.4.1bfem)

cleanData4_RT_EBR_genm <- filter(cleanData4_RT_EBR_gen, gender=='Male')
model6.4.1bmale <- lmer(lnRT ~ Trial_Ctr*Blocktype*switchSet*ebr_Ctr + 
                 (1|ID),
               data=cleanData4_RT_EBR_genm,
               na.action=na.exclude)
results6.4.1bmale <- as.data.frame(coef(summary(model6.4.1bmale)))
results6.4.1bmale <- getFormattedResults(results6.4.1bmale)


# ebr error rate analysis
cleanData4_ER_EBR <- winsorizeEBR(cleanData4_ER, blinkInfo4)
summaryData4_ER_EBR <- getCleanSummary(cleanData4_ER_EBR)
summaryData4_ER_EBR <- centerEBR(summaryData4_ER_EBR, blinkInfo4)


model5.4.2 <- lmer(eRate ~ Trial_Ctr*Blocktype*Congruent*switchSet*ebr_Ctr + 
                   (1|ID),
                 data=summaryData4_ER_EBR,
                 na.action=na.exclude)
results5.4.2 <- as.data.frame(coef(summary(model5.4.2)))
results5.4.2 <- getFormattedResults(results5.4.2)

# ebr error rate analysis with gender
genders <- unique(cleanData4_RT_EBR_gen[c('ID', 'gender')])
summaryData4_ER_EBR_gen <- merge(summaryData4_ER_EBR, genders, by='ID')
summaryData4_ER_EBR_gen <- filter(summaryData4_ER_EBR_gen, (gender %in% c('Male','Female')))

model6.4.2 <- lmer(eRate ~ Trial_Ctr*Blocktype*Congruent*switchSet*ebr_Ctr*gender + 
                   (1|ID),
                 data=summaryData4_ER_EBR_gen,
                 na.action=na.exclude)
results6.4.2 <- as.data.frame(coef(summary(model6.4.2)))
results6.4.2 <- getFormattedResults(results6.4.2)

## EBR and distractor fixation probability
blinksToMerge4 <- unique(cleanData4_RT_EBR[c('ID', 'ebr_Ctr', 'gender')])
summaryData_distFix4_ebr <- merge(summaryData_distFix4, blinksToMerge4, by='ID')
NebrGaze4 <- length(unique(summaryData_distFix4_ebr$ID[complete.cases(summaryData_distFix4_ebr)]))

model7.4.1 <- lmer(distFixProb ~ Trial_Ctr*Blocktype*Congruent*switchSet*ebr_Ctr +
                     (1|ID),
                   data=summaryData_distFix4_ebr,
                   na.action=na.exclude)
results7.4.1 <- as.data.frame(coef(summary(model7.4.1)))
results7.4.1 <- getFormattedResults(results7.4.1)

# with gender
summaryData_distFix4_ebr_gen <- filter(summaryData_distFix4_ebr, (gender %in% c('Male','Female')))

model8.4.1 <- lmer(distFixProb ~ Trial_Ctr*Blocktype*Congruent*switchSet*ebr_Ctr*gender +
                     (1|ID),
                   data=summaryData_distFix4_ebr_gen,
                   na.action=na.exclude)
results8.4.1 <- as.data.frame(coef(summary(model8.4.1)))
results8.4.1 <- getFormattedResults(results8.4.1)

## EBR and saccade time
data_saccadeTime4_ebr <- winsorizeEBR(data_saccadeTime4, blinkInfo4)
data_saccadeTime4_ebr <- centerEBR(data_saccadeTime4_ebr, blinkInfo4)

model9.4.1 <- lmer(firstTarSacc_relOnsetTime ~ Trial_Ctr*Blocktype*switchSet*Congruent*ebr_Ctr +
                     (1|ID),
                   data=data_saccadeTime4_ebr,
                   na.action=na.exclude)
results9.4.1 <- as.data.frame(coef(summary(model9.4.1)))
results9.4.1 <- getFormattedResults(results9.4.1)


# with gender
data_saccadeTime4_ebr_gen <- filter(data_saccadeTime4_ebr, (gender %in% c('Male','Female')))

model10.4.1 <- lmer(firstTarSacc_relOnsetTime ~ Trial_Ctr*Blocktype*switchSet*Congruent*ebr_Ctr*gender +
                     (1|ID),
                   data=data_saccadeTime4_ebr_gen,
                   na.action=na.exclude)
results10.4.1 <- as.data.frame(coef(summary(model10.4.1)))
results10.4.1 <- getFormattedResults(results10.4.1)



```

(ref:capModelo) Model estimates of RT as a function of EBR, Block Type, and Set Type in Experiment 4.  Error bars represent the 95% confidence interval (CI). Similar to Experiment 1, on Switch Sets, participants with higher EBR showed an increased RT cost on Perseveration-Inhibition blocks relative to Pure Updating blocks.

```{r figModelo, echo=FALSE, message=FALSE, out.width='100%', fig.cap='(ref:capModelo)'}

getFigDat_EBR <- function(model) {
  
  figDat <- expand.grid(
    Trial_Ctr=c(-1.5,-0.5,0.5,1.5),
    Blocktype=c('Perseveration-Inhibition','Pure Updating'),
    Congruent=c('Congruent','Incongruent'),
    switchSet=c('Non-Switch Set','Switch Set'),
    ebr_Ctr=c(-20,-10,0,10,20,30,40),
    lnRT=0
  )
  
  figDat$lnRT <- predict(model, figDat, re.form=NA) 
  fd <- model.matrix(terms(model), figDat)
  
  pvar1 <- diag(fd %*% tcrossprod(vcov(model),fd))
  tvar1 <- pvar1+VarCorr(model)$ID[1]
  cmult <- 1.96 ## could use 1.96
  
  figDat <- data.frame(
    figDat
    , plo = figDat$lnRT-cmult*sqrt(pvar1)
    , phi = figDat$lnRT+cmult*sqrt(pvar1)
    , tlo = figDat$lnRT-cmult*sqrt(tvar1)
    , thi = figDat$lnRT+cmult*sqrt(tvar1)
  )
  
  return(figDat)
}

figDat5.4.1 <- getFigDat_EBR(model5.4.1a)

convertFigValues_EBR <- function(figDat) {
  e <- exp(1)
  figDat$RT <- e^figDat$lnRT
  figDat$ploRT <- e^figDat$plo
  figDat$phiRT <- e^figDat$phi
  figDat$tloRT <- e^figDat$tlo
  figDat$thiRT <- e^figDat$thi
  figDat$Trial <- figDat$Trial_Ctr + (mean(c(1:keepingTrials)))
  figDat$ebr <- figDat$ebr_Ctr + blinkInfo1$meanEBR
  
  return(figDat)
}

figDat5.4.1 <- convertFigValues_EBR(figDat5.4.1)
figDat5.4.1 <- group_by(figDat5.4.1, Blocktype, switchSet, ebr) %>%
  summarise(meanRT=mean(RT, na.rm=TRUE),
            meanploRT=mean(ploRT, na.rm=TRUE),
            meanphiRT=mean(phiRT, na.rm=TRUE),
            meantloRT=mean(tloRT, na.rm=TRUE),
            meanthiRT=mean(thiRT, na.rm=TRUE))


p=ggplot(figDat5.4.1, aes(x=ebr, y=meanRT, linetype=Blocktype)) +
  geom_line() +
  facet_grid(.~switchSet) +
  scale_linetype_discrete(name='Set Type') +
  labs(x='EBR (blinks/min)', y='RT (ms)')
p+theme_apa()+geom_pointrange(aes(ymin = meanploRT, ymax = meanphiRT))
```

(ref:capModelp) Model estimates of RT as a function of EBR, Set Type, Congruence, and Trial in Experiment 4. Error bars represent the 95% confidence interval (CI). There was a marginally significant interaction among these factors.

```{r figModelp, echo=FALSE, message=FALSE, out.width='100%', fig.cap='(ref:capModelp)'}

getFigDat_EBR <- function(model, blinkInfo) {
  ebrLow <- 0-blinkInfo$sdEBR
  ebrHigh <- blinkInfo$sdEBR
  
  figDat <- expand.grid(
    Trial_Ctr=c(-1.5,-0.5,0.5,1.5),
    Blocktype=c('Perseveration-Inhibition','Pure Updating'),
    Congruent=c('Congruent','Incongruent'),
    switchSet=c('Non-Switch Set','Switch Set'),
    ebr_Ctr=c(ebrLow, 0, ebrHigh),
    lnRT=0
  )
  
  figDat$lnRT <- predict(model, figDat, re.form=NA) 
  fd <- model.matrix(terms(model), figDat)
  
  pvar1 <- diag(fd %*% tcrossprod(vcov(model),fd))
  tvar1 <- pvar1+VarCorr(model)$ID[1]
  cmult <- 1.96 ## could use 1.96
  
  figDat <- data.frame(
    figDat
    , plo = figDat$lnRT-cmult*sqrt(pvar1)
    , phi = figDat$lnRT+cmult*sqrt(pvar1)
    , tlo = figDat$lnRT-cmult*sqrt(tvar1)
    , thi = figDat$lnRT+cmult*sqrt(tvar1)
  )
  
  return(figDat)
}


figDat5.4.1b <- getFigDat_EBR(model5.4.1, blinkInfo4)

figDat5.4.1b <- convertFigValues_EBR(figDat5.4.1b)
figDat5.4.1b$ebr <- as.factor(figDat5.4.1b$ebr)

figDat5.4.1b <- group_by(figDat5.4.1b,  ebr, switchSet, Congruent, Trial) %>%
  summarise(meanRT=mean(RT, na.rm=TRUE),
            meanplo=mean(ploRT, na.rm=TRUE),
            meanphi=mean(phiRT, na.rm=TRUE),
            meantlo=mean(tloRT, na.rm=TRUE),
            meanthi=mean(thiRT, na.rm=TRUE))

p=ggplot(figDat5.4.1b, aes(x=Trial, y=meanRT, shape=ebr, linetype=ebr))+
  geom_line() +
  geom_point() +
  facet_grid(Congruent~switchSet) +
  scale_linetype_discrete(name='EBR', labels=c('-1 SD','mean','+1 SD')) +
  scale_shape_discrete(name='EBR', labels=c('-1 SD','mean','+1 SD')) +
  labs(x='Trial', y='RT (ms)')
p+theme_apa()+geom_pointrange(aes(ymin = meanplo, ymax = meanphi))
```
All EBR analyses were run both with and without a Gender factor. In the current sample, there were no gender differences in EBR (Females: *M*=`r blinksByGender4$meanEBR[1]`, *SD*=`r blinksByGender4$sdEBR[1]`; Males: *M*=`r blinksByGender4$meanEBR[2]`, *SD*=`r blinksByGender4$sdEBR[2]`; *t*(`r round(gd4$parameter, digits=2)`)=`r round(gd4$statistic, digits=2)`, *p*=`r round(gd$p.value, digits=3)`). It is important to note, however, that the proportion of males in the sample was very small (`r (demog4$numMales/(demog4$numMales+demog4$numFemales+demog4$numOther))*100`%).

**RT.** EBR had no main effect on RT (without Gender: *B*=`r results5.4.1$beta[6]`, *SE*=`r results5.4.1$se[6]`, *t*(`r results5.4.1$df[6]`)=`r results5.4.1$tval[6]` *p*=`r results5.4.1$pval[6]` with Gender:*B*=`r results6.4.1$beta[6]`, *SE*=`r results6.4.1$se[6]`, *t*(`r results6.4.1$df[6]`)=`r results6.4.1$tval[6]` *p*=`r results6.4.1$pval[6]`). The interaction between EBR and Blocktype, which was observed in Experiment 1, was also non-significant here (without Gender: *t*(`r results5.4.1$df[14]`)=`r results5.4.1$tval[14]` *p*=`r results5.4.1$pval[14]`; with Gender: *t*(`r results6.4.1$df[15]`)=`r results6.4.1$tval[15]` *p*=`r results6.4.1$pval[15]`). However, given that Experiment 1 did not have a Set Type factor, the interaction between Block Type, Set Type, and EBR was also of interest here. While this effect was in the predicted direction, it reached only marginal significance, and that only in the model without Gender (without Gender: *B*=`r results5.4.1$beta[23]`, *SE*=`r results5.4.1$se[23]`, *t*(`r results5.4.1$df[23]`)=`r results5.4.1$tval[23]` *p*=`r results5.4.1$pval[23]` with Gender:*B*=`r results6.4.1$beta[29]`, *SE*=`r results6.4.1$se[29]`, *t*(`r results6.4.1$df[29]`)=`r results6.4.1$tval[29]` *p*=`r results6.4.1$pval[29]`). When a post-hoc model was run to examine specifically the effects of EBR, Block Type, Set Type, and Trial on RT, the effect did reach significance in both models (without Gender: *B*=`r results5.4.1a$beta[8]`, *SE*=`r results5.4.1a$se[8]`, *t*(`r results5.4.1a$df[8]`)=`r results5.4.1a$tval[8]` *p*=`r results5.4.1a$pval[8]` with Gender:*B*=`r results6.4.1a$beta[12]`, *SE*=`r results6.4.1a$se[12]`, *t*(`r results6.4.1a$df[12]`)=`r results6.4.1a$tval[12]` *p*=`r results6.4.1a$pval[29]`). As shown in Figure\ \@ref(fig:figModelo), higher EBR predicts greater divergence between Perseveration-Inhibition and Pure Updating blocks, specifically on Switch Sets. This result is broadly consistent with the findings of Experiment 1, in which there were no Non-Switch Sets.  

In the initial model, the only other effect of note was a marginally significant interaction between Trial, Set Type, Congruence, and EBR (without Gender: *B*=`r results5.4.1$beta[30]`, *SE*=`r results5.4.1$se[30]`, *t*(`r results5.4.1$df[30]`)=`r results5.4.1$tval[30]` *p*=`r results5.4.1$pval[30]` with Gender:*B*=`r results6.4.1$beta[46]`, *SE*=`r results6.4.1$se[46]`, *t*(`r results6.4.1$df[46]`)=`r results6.4.1$tval[46]` *p*=`r results6.4.1$pval[46]`). As shown in Figure\ \@ref(fig:figModelp), higher EBR appears to predict slightly slower RTs overall; however on Switch Sets, the effect of EBR on RT is greatest at the beginning of sets for Incongruent trials, but at the end of sets for Congruent trials.

(ref:capModelq) Model estimates of error rate as a function of EBR, Block Type, Congruence, and Trial in Experiment 4. Error bars represent the 95% confidence interval (CI). There was a marginally significant interaction among these factors, indicating that EBR modulates errors to a greatest extent on early trials of Perseveration-Inhibition blocks, and that the direction of this modulation depends on the Congruence between target and distractor.

```{r figModelq, echo=FALSE, message=FALSE, out.width='100%', fig.cap='(ref:capModelq)'}
getFigDat_EBR_ER <- function(model, blinkInfo) {
  ebrLow <- 0-blinkInfo$sdEBR
  ebrHigh <- blinkInfo$sdEBR
  
  figDat <- expand.grid(
    Trial_Ctr=c(-1.5,-0.5,0.5,1.5),
    Blocktype=c('Perseveration-Inhibition','Pure Updating'),
    Congruent=c('Congruent','Incongruent'),
    switchSet=c('Non-Switch Set','Switch Set'),
    ebr_Ctr=c(ebrLow, 0, ebrHigh),
    eRate=0
  )
  
  figDat$eRate <- predict(model, figDat, re.form=NA) 
  fd <- model.matrix(terms(model), figDat)
  
  pvar1 <- diag(fd %*% tcrossprod(vcov(model),fd))
  tvar1 <- pvar1+VarCorr(model)$ID[1]
  cmult <- 1.96 ## could use 1.96
  
  figDat <- data.frame(
    figDat
    , plo = figDat$eRate-cmult*sqrt(pvar1)
    , phi = figDat$eRate+cmult*sqrt(pvar1)
    , tlo = figDat$eRate-cmult*sqrt(tvar1)
    , thi = figDat$eRate+cmult*sqrt(tvar1)
  )
  
  return(figDat)
}


figDat5.4.2 <- getFigDat_EBR_ER(model5.4.2, blinkInfo4)

convertFigValues_EBR_ER <- function(figDat) {
  figDat$Trial <- figDat$Trial_Ctr + (mean(c(1:keepingTrials)))
  figDat$ebr <- figDat$ebr_Ctr + blinkInfo1$meanEBR
  
  return(figDat)
}

figDat5.4.2 <- convertFigValues_EBR_df(figDat5.4.2)
figDat5.4.2$ebr <- as.factor(figDat5.4.2$ebr)
figDat5.4.2 <- group_by(figDat5.4.2, Blocktype, ebr, Trial, Congruent) %>%
  summarise(meaneRate=mean(eRate, na.rm=TRUE),
            meanplo=mean(plo, na.rm=TRUE),
            meanphi=mean(phi, na.rm=TRUE),
            meantlo=mean(tlo, na.rm=TRUE),
            meanthi=mean(thi, na.rm=TRUE))

p=ggplot(figDat5.4.2, aes(x=Trial, y=meaneRate, linetype=ebr, shape=ebr))+
  geom_line() +
  geom_point() +
  facet_grid(Congruent~Blocktype) +
  scale_linetype_discrete(name='EBR', labels=c('-1 SD','mean','+1 SD')) +
  scale_shape_discrete(name='EBR', labels=c('-1 SD','mean','+1 SD')) +
  labs(x='Trial', y='Error Rate (%)')
p+theme_apa()+geom_pointrange(aes(ymin = meanplo, ymax = meanphi))
```

**Error Rate.** In the model predicting error rate, the only EBR-linked effect to approach significance was an interaction between Trial, Block Type, Congruence, and EBR (without Gender: *B*=`r results5.4.2$beta[28]`, *SE*=`r results5.4.2$se[28]`, *t*(`r results5.4.2$df[28]`)=`r results5.4.2$tval[28]` *p*=`r results5.4.2$pval[28]` with Gender:*B*=`r results6.4.2$beta[44]`, *SE*=`r results6.4.2$se[44]`, *t*(`r results6.4.2$df[44]`)=`r results6.4.2$tval[44]` *p*=`r results6.4.2$pval[44]`). As shown in Figure\ \@ref(fig:figModelq), EBR appears to be most relevant for errors on Incongruent trials of Perseveration-Inhibition blocks that come earlier in a set. On such trials, higher EBR predicts a higher error rate.

(ref:capModelr) Model estimates of distractor fixation probability as a function of EBR, Block Type, Set Type, and Trial. Error bars represent the 95% confidence interval (CI). The interaction between these factors reached marginal significance, and suggests that EBR modulates distractor fixation on later trials of Switch Sets in Perseveration-Inhibition blocks, such that individuals with high EBR show a steeper improvement across trials.

```{r figModelr, echo=FALSE, message=FALSE, out.width='100%', fig.cap='(ref:capModelr)'}

getFigDat_EBR_df <- function(model, blinkInfo) {
  ebrLow <- 0-blinkInfo$sdEBR
  ebrHigh <- blinkInfo$sdEBR
  
  figDat <- expand.grid(
    Trial_Ctr=c(-1.5,-0.5,0.5,1.5),
    Blocktype=c('Perseveration-Inhibition','Pure Updating'),
    Congruent=c('Congruent','Incongruent'),
    switchSet=c('Non-Switch Set','Switch Set'),
    ebr_Ctr=c(ebrLow, 0, ebrHigh),
    distFixProb=0
  )
  
  figDat$distFixProb <- predict(model, figDat, re.form=NA) 
  fd <- model.matrix(terms(model), figDat)
  
  pvar1 <- diag(fd %*% tcrossprod(vcov(model),fd))
  tvar1 <- pvar1+VarCorr(model)$ID[1]
  cmult <- 1.96 ## could use 1.96
  
  figDat <- data.frame(
    figDat
    , plo = figDat$distFixProb-cmult*sqrt(pvar1)
    , phi = figDat$distFixProb+cmult*sqrt(pvar1)
    , tlo = figDat$distFixProb-cmult*sqrt(tvar1)
    , thi = figDat$distFixProb+cmult*sqrt(tvar1)
  )
  
  return(figDat)
}


figDat7.4.1 <- getFigDat_EBR_df(model7.4.1, blinkInfo4)


figDat7.4.1 <- convertFigValues_EBR_df(figDat7.4.1)
figDat7.4.1$ebr <- as.factor(figDat7.4.1$ebr)

figDat7.4.1 <- group_by(figDat7.4.1, Blocktype, ebr, Trial, switchSet) %>%
  summarise(meandf=mean(distFixProb, na.rm=TRUE),
           meanplo=mean(plo, na.rm=TRUE),
           meanphi=mean(phi, na.rm=TRUE),
            meantlo=mean(tlo, na.rm=TRUE),
            meanthi=mean(thi, na.rm=TRUE))

p=ggplot(figDat7.4.1, aes(x=Trial, y=meandf, linetype=ebr, shape=ebr))+
  geom_line() +
  geom_point() +
  facet_grid(switchSet~Blocktype) +
  scale_linetype_discrete(name='EBR', labels=c('-1 SD','mean','+1 SD')) +
  scale_shape_discrete(name='EBR', labels=c('-1 SD','mean','+1 SD')) +
  labs(x='Trial', y='Distractor Fixation Probability (%)')
p+theme_apa()+geom_pointrange(aes(ymin = meanplo, ymax = meanphi))

```

**Distractor Fixation Probability (*N*=`r NebrGaze4`).** Next, we examined whether EBR modulates the relationship between task conditions and eye gaze measures. In the models predicting distractor fixations, the only effect of note was a marginally significant interaction between Trial, Set Type, Block Type, and EBR (without Gender: *B*=`r results7.4.1$beta[29]`, *SE*=`r results7.4.1$se[29]`, *t*(`r results7.4.1$df[29]`)=`r results7.4.1$tval[29]` *p*=`r results7.4.1$pval[29]` with Gender:*B*=`r results8.4.1$beta[46]`, *SE*=`r results8.4.1$se[46]`, *t*(`r results8.4.1$df[46]`)=`r results8.4.1$tval[46]` *p*=`r results8.4.1$pval[46]`). As shown in Figure\ \@ref(fig:figModelr), relative to low EBR, high EBR appears to be the most costly for distractor fixation on early trials of Perseveration-Inhibition blocks. 

**Saccade Time (*N*=`r NebrGaze1`).** The final models examined whether EBR modulated the effects of task on the timing of participants' first saccade to the target; however no EBR-linked effects reached significance. 

# Discussion
Behaviorally, the results of Experiment 4 closely replicate those of the prior experiments. On Pure Updating blocks, participants respond more slowly immediately following a switch, but their RTs decline quickly over the course of a set. On the other hand, on Perseveration-Inhibition blocks, participants did not slow down as much immediately following a Switch; however their RTs decreased much more slowly over the course of a set, and showed a consistently high error rate on Incongruent trials throughout Switch Sets. These behavioral observations are supported by eye tracking data, which indicate that on Switch Sets of Perseveration-Inhibition blocks in particular, participants are more likely to initially fixate on the distractor. Furthermore, following a switch, saccades to target become faster over the course of a set in Pure Updating blocks, but not on Perseveration-Inhibition blocks.

The EBR findings showed some continuity from Experiment 1. In particular, having a higher EBR predicted slower responding on Switch Sets of Perseveration-Inhibition blocks relative to Pure Updating blocks. Relatedly, participants with high EBR tended to be more likely to fixate on distractors early in Switch Sets of Perseveration-Inhibition Blocks, but they showed the most improvement over the course of a set. On the other hand, the specific relationships between EBR and error rate and saccade time were not consistent between the experiments. The fact that there were very few EBR-linked effects that reached traditional thresholds of statistical significance also call for caution in the interpretation of these data.

# General Discussion
```{r summary table - behavioral, include=FALSE}
# find all results that were significant in at least two experiments 
effects_RT <- c('Trial','Set Type','Block Type','Congruence','Trial x Set Type','Trial x Block Type','Trial x Block Type x Set Type')

Exp1_beta <- c(results1.1.1$beta[2], 'n.a.', results1.1.1$beta[3], results1.1.1$beta[4],'n.a.', results1.1.1$beta[5], 'n.a.')
Exp1_sig <- c(results1.1.1$pval[2], 'n.a.', results1.1.1$pval[3], results1.1.1$pval[4],'n.a.', results1.1.1$pval[5], 'n.a.')

Exp2_beta <- c(results1.2.1$beta[2], results1.2.1$beta[4], results1.2.1$beta[3], results1.1.1$beta[5],results1.2.1$beta[7], 'n.a.', results1.2.1$beta[12])
Exp2_sig <- c(results1.2.1$pval[2], results1.2.1$pval[4], results1.2.1$pval[3], results1.1.1$pval[5],results1.2.1$pval[7], 'n.a.', results1.2.1$pval[12])

Exp3_beta <- c(results1.3.1$beta[2], results1.3.1$beta[4], results1.3.1$beta[3], results1.3.1$beta[5],results1.3.1$beta[7], 'n.a.', results1.3.1$beta[12])
Exp3_sig <- c(results1.3.1$pval[2], results1.3.1$pval[4], results1.3.1$pval[3], results1.3.1$pval[5],results1.3.1$pval[7], 'n.a.', results1.3.1$pval[12])

Exp4_beta <- c(results1.4.1$beta[2], results1.4.1$beta[4], results1.4.1$beta[3], results1.4.1$beta[5],results1.4.1$beta[7], 'n.a.', results1.4.1$beta[12])
Exp4_sig <- c(results1.4.1$pval[2], results1.4.1$pval[4], results1.4.1$pval[3], results1.4.1$pval[5],results1.4.1$pval[7], 'n.a.', results1.4.1$pval[12])

behSummary_RT <- data.frame(effects_RT, Exp1_beta, Exp1_sig, Exp2_beta, Exp2_sig, Exp3_beta, Exp3_sig, Exp4_beta, Exp4_sig)
colnames(behSummary_RT) <- c('Effect','E1 Beta', 'E1 p-value','E2 Beta','E2 p-value','E3 Beta','E3 p-value','E4 Beta','E4 p-value')

effects_ER <- c('Set Type','Congruence','Block Type x Congruence','Set Type x Block Type x Congruence')
Exp1_beta <- c('n.a.',results1.1.2$beta[4], results1.1.2$beta[7], 'n.a.')
Exp1_sig <- c('n.a.',results1.1.2$pval[4], results1.1.2$pval[7], 'n.a.')

Exp2_beta <- c(results1.2.2$beta[4],results1.2.2$beta[5],'n.a.',results1.2.2$beta[15])
Exp2_sig <- c(results1.2.2$pval[4],results1.2.2$pval[5],'n.a.',results1.2.2$pval[15])

Exp3_beta <- c(results1.3.2$beta[4],results1.3.2$beta[5],'n.a.',results1.3.2$beta[15])
Exp3_sig <- c(results1.3.2$pval[4],results1.3.2$pval[5],'n.a.',results1.3.2$pval[15])

Exp4_beta <- c(results1.4.2$beta[4],results1.4.2$beta[5],'n.a.',results1.4.2$beta[15])
Exp4_sig <- c(results1.4.2$pval[4],results1.4.2$pval[5],'n.a.',results1.4.2$pval[15])

behSummary_ER <- data.frame(effects_ER, Exp1_beta, Exp1_sig, Exp2_beta, Exp2_sig, Exp3_beta, Exp3_sig, Exp4_beta, Exp4_sig)
colnames(behSummary_ER) <- c('Effect','E1 Beta', 'E1 p-value','E2 Beta','E2 p-value','E3 Beta','E3 p-value','E4 Beta','E4 p-value')
```

```{r follow-up analysis, include=FALSE}
# Does interference (slow RTs) immediately following a switch predict better switching on Perseveration-inhibition blocks, as would be expected if faster initial RTs in this condition were driven by less efficient inhibition?

getTrialMatchedData_Study1 <- function(data){
  data <- data[order(data$ID, data$Ttrial),]
  data <- filter(data, Trial==1 | Trial==4)
  dataSelect <- select(data, ID, Trial, Block, Set, lnRT, Blocktype)
  dataSelect <- group_by(dataSelect, ID, Block)
  dataSelect$leadSet <- lead(dataSelect$Set)
  dataSelect$leadTrial <- lead(dataSelect$Trial)
  dataSelect$leadBlock <- lead(dataSelect$Block)
  # select 4s with match
  dataSelect <- filter(dataSelect, Trial==1 | (Trial==4 & leadTrial==1 & leadSet==Set+1 & leadBlock==Block))
  
  dataSelect$lagSet <- lag(dataSelect$Set)
  dataSelect$lagTrial <- lag(dataSelect$Trial)
  dataSelect$lagBlock <- lag(dataSelect$Block)
  
  dataSelect <- filter(dataSelect, Trial==4 | (Trial==1 & lagTrial==4 & lagSet==Set-1 & lagBlock==Block))
  
  # create an index for each pair
  indexNum <- nrow(dataSelect)/2
  dataSelect$index <- rep(c(1:indexNum), each=2)
  
  dataSelect_wide <- dcast(dataSelect, ID + index + Blocktype ~ Trial, value.var='lnRT')
  colnames(dataSelect_wide) <- c('ID','index','Blocktype','T1','T4')
  return(dataSelect_wide)

}

getTrialMatchedData <- function(data){
  data <- data[order(data$ID, data$Ttrial),]
  data <- filter(data, Trial==1 | Trial==4)
  dataSelect <- select(data, ID, Trial, Block, Set, lnRT, Blocktype, switchSet)
  dataSelect <- group_by(dataSelect, ID, Block)
  dataSelect$leadSet <- lead(dataSelect$Set)
  dataSelect$leadTrial <- lead(dataSelect$Trial)
  dataSelect$leadBlock <- lead(dataSelect$Block)
  # select 4s with match
  dataSelect <- filter(dataSelect, Trial==1 | (Trial==4 & leadTrial==1 & leadSet==Set+1 & leadBlock==Block))
  
  dataSelect$lagSet <- lag(dataSelect$Set)
  dataSelect$lagTrial <- lag(dataSelect$Trial)
  dataSelect$lagBlock <- lag(dataSelect$Block)
  
  dataSelect <- filter(dataSelect, Trial==4 | (Trial==1 & lagTrial==4 & lagSet==Set-1 & lagBlock==Block))
  
  # create an index for each pair
  indexNum <- nrow(dataSelect)/2
  dataSelect$index <- rep(c(1:indexNum), each=2)
  
  dataSelect_wide <- dcast(dataSelect, ID + index + Blocktype + switchSet ~ Trial, value.var='lnRT')
  colnames(dataSelect_wide) <- c('ID','index','Blocktype','switchSet','T1','T4')
  return(dataSelect_wide)

}

dataSelect_wide1 <- getTrialMatchedData_Study1(cleanData1_RT)
dataSelect_wide2 <- getTrialMatchedData(cleanData2_RT)
dataSelect_wide3 <- getTrialMatchedData(cleanData3_RT)
dataSelect_wide4 <- getTrialMatchedData(cleanData4_RT)


modelt1 <- lmer(T1 ~ T4*Blocktype +
                 (1|ID),
               data=dataSelect_wide1,
               na.action=na.exclude)

modelt2 <- lmer(T1 ~ T4*Blocktype*switchSet +
                 (1|ID),
               data=dataSelect_wide2,
               na.action=na.exclude)

modelt3 <- lmer(T1 ~ T4*Blocktype*switchSet +
                 (1|ID),
               data=dataSelect_wide3,
               na.action=na.exclude)

modelt4 <- lmer(T1 ~ T4*Blocktype*switchSet +
                 (1|ID),
               data=dataSelect_wide4,
               na.action=na.exclude)
```

In a series of experiments, we examined WM updating performance on a novel variant of the attention shifting task, in which the updating context varied as a function of the familiarity of target and distractor stimuli (both familiar in Perseveration-Inhibition; both novel in Pure Updating). Additionally, we tested the relationship between EBR, an index of striatal DA, and WM updating ability across these contexts.  
The behavioral findings were highly consistent across experiments. As expected, participants were slower and more error-prone on Perseveration-Inhibition blocks overall. In this condition, RTs asymptoted more slowly following updating, indicating that participants required more trials to adjust to the new attentional set. Participants were also more susceptible to interference by distraction throughout a set in which they had recently switched, as indexed by an overall higher error rate on Incongruent trials in the Perseveration-Inhibition condition. Taken together, these findings suggest that on Perseveration-Inhibition blocks, an inability to completely disengage from the previous attentional set interfered with performance, and that this interference persisted for at least 4 trials following WM updating. Performance in the Perseveration-Inhibition condition thus reflects both the extent to which an individual has disengaged from the previous attentional set, as well as their engagement with the new attentional set. In the Pure Updating condition, on the other hand, disengagement from a previous attentional set is not relevant to performance, and thus it is a purer index of engagement with a new attentional set. 

Interestingly, in spite of overall better performance on Pure Updating blocks, in 3 of 4 experiments participants responded more slowly on the first trial following an update in this condition. One potential explanation for this finding is that incomplete disengagement from previous task sets in the Perseveration-Inhibition condition may also confer an RT advantage immediately following an update. In particular, re-activation of an attentional set may be faster when it becomes relevant again if it has not been completely disengaged from. In the Pure Updating condition, on the other hand, previously-relevant attentional sets are unlikely to become relevant again, and thus there would be no such advantage. If this were the case, we might expect that following sets on which participants showed high levels of interference, as indexed by slower RTs at the end of a set, they would have faster RTs the first trial following an update, compared with sets on which they showed less interference. We tested this possibility in post-hoc analyses that assessed whether the first RT of a set was predicted by Block Type and the RT of the fourth trial of the previous set. Although RT on the fourth trial consistently predicted RT on the first trial of the following set, this relationship was in the positive direction and did not vary as a function of block. An alternative explanation is that because participants had not recently seen the new target and distractor colors in the Pure Updating condition, perceptual processing of the novel colors was slower in this condition. This explanation is consistent with other work showing colored target detection is faster following recent priming with a visual representation the specific target colour, but that this difference is driven by perceptual, rather than selective attention processes [@WilschutEtAl_2014]. Future work will be needed to more directly test this explanation for the initially slower RTs following updating on Pure Updating blocks in these experiments.  

Participants' eye gaze patterns index behavior independent of response processes, and were thus of interest for better understanding the processes underlying the observed behavioral differences across conditions. Eyetracking results were largely complementary to the RT and error rate findings, although not entirely consistent across experiments. Distractor fixation probability, an overt index of distractibility, was greater on Perseveration-Inhibition blocks, confirming that in this condition, participants were not only slower and more error-prone, but also more likely to look at the to-be-ignored distractor. In Experiment 4, this relationship was strongest on Switch sets. 

The time of participants' first saccade to the target was used as an index of (perhaps) implicit, hesitation to approach the target, on trials in which participants did not first overtly look at the distractor. The results of Experiment 4 closely mirror the main RT finding, indicating that saccades to target on Pure Updating blocks were initially slower following a recent update, but improved over the course of a set, whereas saccade time changed little with each subsequent trial on Perseveration-Inhibition blocks. Based on the results of Experiment 4, the slower adaptation to a new attentional set in Perseveration-Inhibition blocks appears to be driven by both increased tendency to look at the distractor, and a hesitation to look at the target.  

It is important to note, however, that the eye tracking results from Experiment 2 are inconsistent with the above findings. Given its relatively small sample size (*N* Exp. 2=`r Ngaze2`; *N* Exp. 4=`r Ngaze4`), it is possible that Experiment 2 was underpowered to detect these effects. An additional potential explanation is that in Experiment 2, stimuli were presented for only 1000ms, whereas in Experiment 4 stimuli remained on the screen until response. It is possible that this manipulation changed how participants responded to the task, although we note that the RT and Error Rate results were quite similar. Additionally, when trials in which the critical gaze measures (i.e. distractor fixation, saccade to target) occurred after 1000ms were removed, the results of Experiment 4 remained the same.  

An additional goal of these experiments was to determine how EBR, an index of striatal DA, is related to WM updating across the different switching contexts. Across experiments, higher EBR consistently predicted slower performance on Perseveration-Inhibition relative to Pure Updating blocks on sets in which participants had recently switched. This finding indicates that poorer updating performance in individuals with high EBR is attributable to increased susceptibility to interference from previously-relevant attentional sets, rather than to poorer activation of a new attentional set. This interference could come in the form of perseveration on the old target color or backwards inhibition of the new target color. Eyetracking measures were of interest for their potential to adjudicate between these two potential sources of interference. Across both experiments, there was no evidence that high EBR was linked with overt attentional capture (i.e. fixation) by distractors. With respect to saccade initiation time, our index of hesitation, the results were not consistent across experiments. 

A few additional inconsistencies in the EBR results between Experiments 1 and 4 are notable. With respect to error rate, Experiment 4 indicated that high EBR predicted more errors on early, incongruent trials of Perseveration-Inhibition blocks. This finding fits well with the proposal that high EBR is associated with poorer disengagement from now-irrelevant attentional sets; however there was no evidence of this relationship in Experiment 1. Error rates on this attention shifting task were generally low, and thus it is possible that it is a less reliable measure than RT. Additionally, in Experiment 1, higher EBR predicted faster saccade initiation on Pure Updating blocks; however this effect was not replicated in Experiment 4.   

Despite these inconsistencies, the RT findings are broadly consistent with other work in this area, which has shown that the relationship between EBR and WM updating depends on the switch context [e.g. @DreisbachEtAl_2005]. When effective switching requires disengagement from a previously-relevant attentional set, having a higher EBR predicts poorer performance. On the other hand, when switching requires only the activation of a new attentional set, higher EBR may predict better performance. Taken alongside the findings of @DreisbachEtAl_2005 and @MuellerEtAl_2007, which indicate that high EBR predicts less Perseveration on a no-longer-relevant target but poorer performance when needing to attend a previously-irrelevant target, our results suggest that the poorer performance observed in the Perseveration-Inhibition condition may come from difficulty overcoming backwards inhibition, rather than perseveration on a previously-relevant target. The fact that participants with high EBR were not more likely to fixate on the distractor stimulus on Perseveration-Inhibition blocks is consistent with this conclusion; however we note that it is not possible to draw conclusions from a null result, and also that a lack of overt attentional capture does not preclude covert attentional capture, which we did not explicitly measure.   

The meaning of these results for our knowledge about WM updating and striatal DA hinges on a more precise understanding of what exactly EBR indexes. Although this understanding remains elusive [@JongkeesColzato_2016; @SescousseEtAl_2017; @DangEtAl_2017], we will outline here some possible points of relevance.

In the attentional shifting task, poorer performance in the presence of distractors indicates that the task-irrelevant stimuli were, at least to some extent, not effectively prevented from being gated into WM.  When tonic striatal DA is high, D2 pathway activity should be reduced, and thus there should be a reduced threshold required for a phasic signal to gate an item into WM [@MaiaFrank_2011]. The result is facilitated updating, which may also come at the cost of increased distractibility when task-irrelevant stimuli are gated into WM. If EBR is reflective of tonic striatal DA levels, we would expect to see that participants with high EBR are more susceptible to distraction. Critically, however, greater distractibility alone does not explain why participants with high EBR were selectively more distracted in the Perseveration-Inhibition condition compared to the Pure Updating condition, both of which contained distractor stimuli.  

There are two potential explanations for this selectively greater distractibility on Perseveration-Inhibition blocks in subjects with higher EBR. First, it is possible that the Perseveration-Inhibition condition is simply more difficult than the Pure Updating condition, and under these circumstances, EBR-linked effects are more likely to emerge. A second possibility is that EBR is also related to learning processes, which modulates the synaptic weights of target and distractor colors throughout the experiment. The Perseveration-Inhibition condition of this task is analogous to a reversal learning paradigm. Tonic DA at the time of learning can modulate the relative weighting of punishments and rewards in the learning process, with high DA facilitating reward learning and low DA improving punishment learning [@CollinsFrank_2014; @CoolsEtAl_2009]. In our experiment, participants performed the task without explicit rewards, punishment, or feedback; however given that errors and conflict among competing stimuli are intrinsically aversive [@DreisbachFischer_2012], successful learning of task sets would allow participants to avoid these more subtle punishments. If this were the case, we might expect that EBR effects would be modulated by their sensitivity to punishment. This finding is also consistent with other studies showing that participants with low EBR learned more effectively from punishment than those with high EBR [@SlagterEtAl_2015]. In the Pure Updating condition, poorer learning is less likely to result in performance decrements, because previously-relevant stimuli will never be shown at the same time as the target. In future work, it will be important to explicitly account for the potential effect of tonic DA on learning processes, in addition to its role in the implementation of the learned attentional sets.  

Even while acknowledging the uncertainty about the precise neurocognitive processes underlying the observed EBR effects, an important outcome of the present investigation is the result that EBR-linked effects depend on the context of the switch. Rather than modulating the effectiveness of updating processes per se, EBR appears to be linked to the effectiveness with which one is able to disengage from a previous attentional set. Interestingly, many of these EBR-linked effects do not interact with the time since the switch: high EBR participants continued to be slower on Perseveration-Inhibition blocks several trials following updating.  

In addition to questions about the precise mapping of EBR to neural state, the present studies had some limitations in how EBR data were collected, that can be addressed in future studies examining the role of striatal DA in WM updating across contexts. In order to obtain accurate blink measurements with an eye tracker, participants kept their head fixed in a chin rest and looked at a fixation cross during the EBR measurement, whereas current recent recommendations are for more relaxed, naturalistic conditions [@JongkeesColzato_2016]. Additionally, in Experiment 4 we told participants to blink naturally, because of concerns that some participants were actively trying not to blink, and this direction of participants' attention towards their blinking may have affected their tendency to blink. Although these issues are unlikely to have had a systematic effect on results, they may have introduced additional noise into the dataset. Addressing these limitations and also running experiments with complementary methods for assessing and/or manipulating DA (e.g. PET, pharmacological manipulation) will be necessary to compile a more complete picture of DA's role in cognitive control.  

Overall, the experiments described here underscore the importance of the updating context on behavioral performance, and in particular, whether one must disengage from a previously-relevant attentional set. When performance depends on disengagement from an old attentional set, participants require a greater number of trials to adapt to the new attentional set. Furthermore, this need for disengagement modulates the relationship between EBR, an index of striatal DA, and WM updating performance. Moving forward, it will be important to explicitly account for the the effects of disengagement in neural models of DA and cognitive control. 

```{r summary table - eye tracking, include=FALSE}
# find all results that were significant in at least two experiments 
effects_distFix <- c('Set Type','Block Type','Block Type x Set Type')

Exp1_beta <- c('n.a.', results3.1.1$beta[3], 'n.a.')
Exp1_sig <- c('n.a.', results3.1.1$pval[3],'n.a.')

Exp2_beta <- c(results3.2.1$beta[4], results3.2.1$beta[3], results3.2.1$beta[8])
Exp2_sig <- c(results3.2.1$pval[4], results3.2.1$pval[3], results3.2.1$pval[8])

Exp4_beta <- c(results3.4.1$beta[4], results3.4.1$beta[3], results3.4.1$beta[8])
Exp4_sig <- c(results3.4.1$pval[4], results3.4.1$pval[3], results3.4.1$pval[8])

eyeSummary_distFix <- data.frame(effects_distFix, Exp1_beta, Exp1_sig, Exp2_beta, Exp2_sig, Exp4_beta, Exp4_sig)
colnames(eyeSummary_distFix) <- c('Effect','E1 Beta', 'E1 p-value','E2 Beta','E2 p-value','E4 Beta','E4 p-value')

effects_saccadeTime <- c('Trial','Trial x Set Type','Trial x Set Type x Block Type')
Exp1_beta <- c(results4.1.1$beta[2], 'n.a.','n.a.')
Exp1_sig <- c(results4.1.1$pval[2], 'n.a.','n.a.')

Exp2_beta <- c(results4.2.1$beta[2],results4.2.1$beta[7],results4.2.1$beta[12])
Exp2_sig <- c(results4.2.1$pval[2],results4.2.1$pval[7],results4.2.1$pval[12])

Exp4_beta <- c(results4.4.1$beta[2],results4.4.1$beta[7],results4.4.1$beta[12])
Exp4_sig <- c(results4.4.1$pval[2],results4.4.1$pval[7],results4.4.1$pval[12])

eyeSummary_saccadeTime <- data.frame(effects_saccadeTime, Exp1_beta, Exp1_sig, Exp2_beta, Exp2_sig, Exp4_beta, Exp4_sig)
colnames(eyeSummary_saccadeTime) <- c('Effect','E1 Beta', 'E1 p-value','E2 Beta','E2 p-value','E4 Beta','E4 p-value')
```
\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

\endgroup
